~~strikethrough text~~## Введение

### Используемая литература: основная

L. Peterson and B.Davie, Computer Networks: A Systems Approach: https://book.systemapproach.org/ --- используется как основной учебник по сетям в западных университетах

James F. Kurose and Keith W. Ros, Computer Networking: A Top-Down Approach (нестандартный подход)

Олифер В.Г., Олифер Н.А.. Компьютерные сети. Принципы, технологии, протоколы. ~1000 страниц. 

Таненбаум и Уизирел (Tanenbaum and Wetherell). Компьютерные сети. -- традиционный учебник по сетям.

### RFC -- Request For Comments

По изучаемым протоколам --  ietf.org/blog/how-read-rfc/
 

### Дополнительная литература

Wireshark and Ethereal Network Protocol Analyzer Toolkit, Syngress - ~550 страниц на английском или их аналоги -- какая-нибудь книжка по Wireshark -- основному анализатору протоколов на лабораторных работах.

Что-то про программирование сетевых приложений (про сокеты и прочие радости)

Литература для подготовки к сертификационным экзаменам по сетевым технологиям основных производителей ПО и оборудования. Лучше читать на английском



## Задачи современных сетей

### Зачем нужны сети

Одна из основных проблем -- обеспечение *надёжной* передачи данных между абонентами. Чтобы это сделать, у нас будет работать ряд механизмов -- коды обнаружения или коррекции ошибок, специальные протоколы, алгоритмы построения альтернативных маршрутов передачи данных и так далее.


### Интерактивные сервисы

IP-телефония, видео конференции, обмен мгновенными сообщениями, социальные взаимодействия (в т.ч. игровое) требуют обеспечение *минимальных* задержек в передаче данных.
 
Однако часть протоколов, которыми мы пользуемся на сегодняшний день, не сильно под это заточены. Да, при помощи определённых механизмов мы можем это обеспечить, однако то, чем мы сейчас пользуемся, можно было бы сделать намного лучше (привет легаси из семидесятых, когда взгляд людей на устройство сетей и архитектурные решения, которые казались вполне разумными, были совершенно иными и сегодня не сильно выдерживают критику). Предложены современные решения, которые позволяют всё делать намного быстрее, однако из-за необходимости обратной совместимости с уже существующим ПО и оборудованием эти изменения внедряются очень медленно.

### Использование ресурсов

Можно пользоваться файловыми хранилищами и прочими системами, которыми пользуются одновременно большое количество людей. Возникает вопрос: а как обеспечить приемлемую пропускную способность сети?

Понятно, если каждый из нас, находясь в некоторой сетевой инфраструктуре, захочет скачать кино в HD-качестве, мы это кино по идее  будем качать очень долго, но на самом деле всё происходит быстрее, -- и не из-за того, что к каждому дому подключен терабитный канал для обмена информацией, а за счёт того, что мы не одновременно все пользуемся нашей сетью с максимальной нагрузкой на эту инфраструктуру.

Здесь работает принцип **статистического мультиплексирования**: да, нам нужна высокая пропускная способность от сети, но нас спасает то, что она нужна не всем одновременно. Поэтому мы проектируем часто сеть не на максимальную нагрузку, которая будет требоваться в пике -- если все одновременно начнут обмениваться гигантскими объёмами информации, а за счёт того, что существенная часть пользователей в конкретный момент времени простаивает и ничем не обменивается. Исходя из этого подхода мы можем проектировать сеть с несколько ослабленными требованиями.

Есть, однако и особенные истории, например, проектирования внутренней сети суперкомпьютеров для организации быстрой коммуникации и пересылки данных. Тут мы проектируем сетевые инфраструктуры исходя из других предположений.

### Доставка контента

Есть даже такое понятие -- *CDN*: *Content Delivery Network*, когда у нас есть сервисы, отдающие статический (видео по требованию) или динамический (онлайн-трансляции) контент.

Тут есть разные интересные механизмы, связанные с системами хранения реплик и географическим кэшированием данных: если условный ролик из Австралии распространяется по миру и его начинают смотреть в других странах, то он закэшируется на серверах по всему миру, чтобы при каждом запросе к этом ролику не обращаться к далёким серверам.

### Компоненты сетевой инфраструктуры

<a href="https://imgbb.com/"><img src="https://i.ibb.co/vkDS7Fh/image.png" alt="image" border="0"></a>

На этой картинке видим 4 важных компонента: приложения (app) работают на базе некоторых вычислительных систем (host), которые обмениваются данными посредством некоторого сетевого оборудования (здесь использовано слово router, но это лишь один из подклассов сетевого оборудования), которое связывает конечные системы и другое коммуникационное оборудование посредством некоторых каналов связи (link).

### Что надо знать к концу курса

Что происходит, когда на каком-то узле сети инициируется некоторый обмен сообщениями с удалённым узлом?

Нарисуем простенькую сетевую инфраструктуру. Пусть в сети будет какой-нибудь Ethernet-коммутатор (Ethernet -- основной использующийся сегодня в локальных сетях протокол), который мы назовём *switch*. Это устройство, у которого есть несколько портов, к которым по кабельной инфраструктуре можно подключить какие-то конечные системы -- компьютеры host1 и host2, на которых стоит сетевая карта (NIC - Network Interface Card, но в разных сетях эти сетевые карты могут называться по-разному: например, в сетях хранения данных это может быть HBA -- Host Bus Adapter, в сетях типа Infiniband, предназначенных для быстрого обмена трафика большого объёма, -- HCA -- Host Channel Adapter и так далее).

Кроме этого, пусть у нас будет ещё один хост в сети -- DNS-сервер.

Также в сети есть промежуточное сетевое оборудование -- маршрутизатор Router.

Сетевые карты хостов образуют локальную сеть Ethernet. Маршрутизатор тоже подключается к этой сети одним из своих интерфейсов.

<a href="https://ibb.co/vZzzk5f"><img src="https://i.ibb.co/QrmmMBh/image.png" alt="image" border="0"></a>

У каждой сетевой карты есть адрес в сети Ethernet -- MAC (Media-Access Control)-адрес, который из себя представляет 6 *октетов*. Обычно первые три октета соответствуют производителю сетевого оборудования, а вторая часть назначается на заводе, либо при желании меняется операционной системой, хотя обычно это не требуется.

На уровне выше -- на уровне *межсетевых* коммуникаций: не между конкретными физическими устройствами, такими как сетевые карты, а для коммуникации на уровне хостов, используются IP-адреса. Каждый хост может иметь и несколько IP-адресов (у него может быть и несколько сетевых карт, и на одной карте может быть несколько IP), и в нормальной ситуации эти IP уникальны (хотя бывает и иначе).

IP-адрес может быть разных версий -- IPv4 или IPv6. IPv4 состоит из 4 восьмиразрядных чисел (октетов) вида 192.168.17.25.

Здесь надо обратить внимание, что в сетях используется термин *октет*, а не байт, потому что у байта на самом деле нет стандарта, и, строго говоря, байтом может быть и не 8 бит, а 7, и 13, и 29, если нам очень хочется -- это зависит от архитектуры. Поэтому грамотнее называть восьмиразрядные числа октетами.

DNS-серверы позволяют сопоставить IP-адресам более понятные человеку символьные доменные имена. У нас может быть запись типа 

```dns
A: 	ya.ru	123.53.87.9
```

Если MAC-адрес у нас имеет смысл в локальном сегменте -- то есть в пределах локальной сети до маршрутизатора, то IP-адрес позволяет общаться за пределами маршрутизатора между сегментами сети. 

Пусть у хостов следующие IP-адреса:

|host|IP|
|--|--|
|host1| 192.168.17.25
host2| 192.168.17.12

Тогда этим IP-адресам могут быть сопоставлены имена host2.local и host1.local соответственно.

На хостах согласно устройству сетевой инфраструктуры работают какие-то приложения, и чтобы адресовать конкретные приложения на хосте, мы поднимаемся на один уровень выше в стеке протоколов и начинаем задействовать транспортные протоколы (TCP, UDP, PGM, SCTP и так далее). Каждое приложение, которое открывает сетевое соединение при помощи транспортных протоколов, адресуется с помощью некоторого числового идентификатора -- 16-разрядного числа от 0 до 65535 -- порта. Дл каждого приложения, запущенного на хосте и взаимодействующего с сетью, также в соответствие ставится и номер порта.

Есть некоторые стандартные порты: например, 80 порт традиционно используют HTTP-сервисы, 53 порт -- DNS и так далее.

Чтобы идентифицировать конкретное приложение, которое работает на конкретном хосте в глобальном сегменте сети, нужна связка IP-адрес + номер порта. Часть этих портов назначается статически и хорошо известна; клиентские системы зачастую используют *динамические* порты.

Рассмотрим, как у нас будут работать не или иные механизмы в сети, когда мы посылаем некоторое простейшее сообщение от одного хоста к другому, например, командой `ping`.

Команда `ping` использует специальный протокол ICMP (Internet Control Message Protocol), который работает поверх IP и одна из функций которого  -- посылка эхо-запросов.

Попытаемся выполнить на хосте1 команду

```powershell
ping host2.local
```

Написав какое-то имя в виде буквенного идентификатора, подразумевается, что мы не знаем IP-адрес хоста для того, чтобы взаимодействовать с ним на сетевом уровне. Чтобы этот IP адрес, у нас потенциально есть несколько возможностей.

Например, у нас где-то на компьютере локально может находиться файл `hosts` в ОС, в котором можно прописать статические взаимодействия имён адресам.

Плюс если мы заранее взаимодействовали с этим хостом по этому имени, на нашем компьютере может быть закеширована информация о том, что с соответствующим доменным именем связан тот или иной IP-адрес -- DNS кэш. Его можно посмотреть командой

```powershell
ipconfig /displaydns
```
<div align="center"><a href="https://imgbb.com/"><img src="https://i.ibb.co/T0pCwpL/image.png" alt="image" border="0"></a></div>

Эта информация в кеше берётся из DNS-сервера. В настройках сетевой карты прописаны IP-адреса предпочтительных DNS-серверов, к которым надо обращаться за разрешением доменных имён.

Зная адрес DNS-сервера, мы должны сформировать запрос на него с указанием того доменного имени, IP-адрес которого мы хотим получить. Но чтобы взаимодействовать в этим хостом на канальном уровне, нам нужен не только его IP-адрес, но и MAC-адрес той сетевой карты, с которой мы взаимодействуем.

MAC-адрес нам нужен, потому что хост1 знает, что хост2 находится в том же сегменте сети. Иначе надо было бы обращаться к серверу вне локальной сети через маршрутизатор, и запрашивать MAC-адрес маршрутизатора, который находится в нашем сегменте сети.

По IP-адресу DNS-сервера мы поняли, что этот сервер находится в нашем сегменте локальной сети, а поэтому для взаимодействия с ним нам нужен его MAC-адрес. Для этого тоже есть несколько возможностей: во-первых, если мы раньше уже взаимодействовали с этим хостом, то информация о соответствии MAC-адресов и IP-адресов может быть закеширована -- такое понятие называется ARP (Address Resolution Protocol)-кеш. Этот протокол ARP используется для того, чтобы мы могли узнать MAC-адрес узла по его IP-адресу в локальном сегменте сети.
 
 Допустим, IP DNS-сервера --  192.168.17.42. Тогда в ARP-кеше должно быть соответствие вида 
192.168.17.42 -> MAC3. Эта запись может находиться там статически (например, мы можем записать это соответствие с помощью команды `arp -s`), но на практике она узнаётся динамически. Для этого мы посылаем в сеть специальный ARP-пакет в виде широковещательного запроса. Его получат все хосты в нашем локальном сегменте сети, а сам запрос будет спрашивать, какой MAC-адрес у данного (...42) IP.

Поэтому первое, что мы сделаем, введя команду `ping`,  -- пошлём ARP-запрос. Этот пакет попадёт на коммутатор, который, в свою очередь, перешлёт его всем хостам в локальной сети. И если бы в сети был бы ещё один коммутатор Switch2, то и на Switch2 был бы отправлен этот пакет, а он, в свою очередь, переслал бы его хостам, которые подключены к нему и так далее.

Все хосты, получив этот пакет, смотрят, не про них ли IP-адрес там спрашивается. Если нет, они этот пакет игнорируют, а если да, то этот хост должен сформировать соответствующий ARP-ответ. Это будет ответ от DNS-сервера нашему хосту1 с адресом MAC3.

При этом коммутатор тоже будет обучаться: при указании конкретного адресата пакета он пересылает этот пакет на конкретный хост, и поэтому он запомнит, что на какой-то конкретный порт коммутатора пришёл пакет от отправителя с адресом MAC1, поэтому в *таблице продвижения (forwarding database*) появится некая запись, что через порт номер 1 доступен МАС1.  Аналогичная вещь появится и на втором коммутаторе Switch2 (например, на его порте 10 доступен хост с MAC-адресом MAC1). Таким образом, коммутаторы эту информацию запоминают. Поэтому в случае адресного ответа от MAC3, пакеты. предназначенные хосту с адресом MAC1, будут посылаться не на все порты, а только на те, которые с ним связаны. Поэтому конкретный ответ от DNS-сервера дойдёт напрямую до хоста 1.

Зная IP-адрес и MAC-адрес DNS-сервера, мы готовы с ним взаимодействовать. Мы посылаем DNS-запрос на этот сервер по протоколу UDP, который представляет собой слоёный пирог из Ethernet, IPv4, UPD и DNS-протоколов. Мы в этом запросе будем спрашивать, какой IP-адрес у хоста с именем host2.local? 

Это сообщение будет доставлено непосредственно DNS-серверу, потому что коммутатор уже зарегистрировал два пакета MAC1 -> MAC3 через условный порт 1 и MAC3 -> MAC1 через условный порт 2, поэтому при передаче DNS-запроса маршрутизатор будет передавать пакеты только через эти порты напрямую.

DNS-сервер смотрит в свой каталог, находит там запись, соответствующую имени host2.local, и формирует нам ответ. Но опять же, чтобы отправить нам ответ, он должен узнать наш MAC-адрес: для этого он, скорее всего, выполнит ARP-запрос и получит ARP-ответ с нашим MAC1 (если DNS-сервер про наш MAC1 не знал). 

В результате мы получим DNS-ответ о том, что хосту host2.local соответствует адрес 192.168.17.12. Эту информацию мы помещаем в наш DNS-кеш.

Теперь мы должны узнать MAC-адрес второго хоста (MAC2). Для этого снова формируется ARP-запрос про IP второго хоста, и на него принимается ARP-ответ. В это же время в таблице продвижения на коммутаторе появится запись о том, что через условный третий порт на коммутаторе был получен пакет от хоста с адресом MAС2.

После этого всё готово, чтобы сформировать очередной пакет на второй хост (Ethernet + IPv4 + ICMP), на который тот может ответить, в свою очередь, разрешив наш IP-адрес в MAC-адрес при помощи протокола ARP.

## Классификация сетей

### По географическому принципу

- PAN -- Personal Area Network: сети, предназначенные для обслуживания одного человека. Самый типичный пример -- Bluetooth
- LAN -- Local Area Network -- сеть хостов внутри здания
- CAN -- Campus Area Network -- сеть хостов внутри кампуса
- MAN -- Metropolitan Area Network -- городские сети
- WAN -- Wide Area Network -- глобальные сети, например, интернет.

Эти разделения по сути условные, хотя есть некоторые типичные технологии и протоколы, которые в больше степени ориентируются на сетевую инфраструктуру того или иного масштаба. При этом часть протоколов и технологий являются универсальными и используются в сетях любого масштаба.

<a href="https://ibb.co/d4gZKch"><img src="https://i.ibb.co/VYm6BNK/image.png" alt="image" border="0"></a>

Обеспечить высокоскоростное соединение без потерь данных в рамках локальной сети просто, но при переходе к глобальным сетям скорость передачи данных между узлами падает, и надёжность тоже, потому что чем больше сеть, тем через большее количество промежуточных устройств нужно передать эти данные.

То, что скорость и надёжность передачи данных падает при переходе в глобальный масштаб, накладывает некоторые ограничения на то, как проектировались и что было заложено в те или иные сетевые протоколы.

### По средам передачи данных
 
Проводные:
- Оптические кабели
- Коаксиальные кабели -- в современных локальных сетях практически не используются, хотя они могут применяться в некоторых специализированных сетевых инфраструктурах
- **Витая пара**

Беспроводные

### По принципам адресации абонентов

#### Unicast

У конкретного абонента есть свой уникальный адрес как на сетевом (IP), так и на канальном (MAC) уровне. Сообщения посылаются персонально данному конкретному абоненту.

#### Multicast

Мы посылаем данные по какому-то одному (групповому) адресу, но их получит целая группа абонентов, заинтересованная в этом трафике. 

#### Broadcast

Широковещательные адреса: посылая сообщения на них, его получают все абоненты.

Он работает только в рамках локального сегмента -- до маршрутизатора, и у нас нет возможности послать широковещательное сообщение всем хостам в интернете.

Возможность широковещательных запросов есть как на канальном уровне, так и на сетевом. Пример широковещательного адреса на канальном уровне (MAC) -- ff:ff:ff:ff:ff:ff. Например, посылая широковещательный ARP-запрос, в качестве адресата указывается именно этот широковещательный MAC-адрес.

С широковещательными адресами в IP ситуация интереснее: во-первых, в IPv4 есть два вида broadcast-запросов, а во-вторых, в IPv6 была попытка отказаться от широковещательной адресации, поэтому формально его там нет (хотя по сути это не так).

#### Anycast

Сообщение будет доставлено какому-то конкретному хосту из группы, в отличие от multicast, где сообщение будет доставлено всем хостам.

Классический пример, где это может быть полезно -- кластер серверов с общим групповым адресом, которые взаимодействуют с клиентом. Клиент посылает запрос на обслуживание, и ему всё равно, с каким конкретно сервером он будет взаимодействовать -- поэтому его запрос посылается на групповой адрес всего кластера, но доставлен он будет только какому-то одному серверу.

#### Числовые идентификаторы

IP-адреса, MAC-адреса, номера портов и так далее. Их легко закодировать, они занимают мало места, с ними могут эффективно работать какие-то аппаратные системы.

#### Символьные идентификаторы

Доменные имена типа ya.ru. Более гибкие и легче воспринимаются человеком.

#### Плоская адресация

Когда все адреса равноценны, и по адресу мы не можем получить никакую дополнительную информацию о том, где потенциально расположен тот или иной хост. 

Например, MAC-адреса плоские, по ним нельзя построить никакую иерархию, и сам MAC-адрес ничего не говорит о том, где примерно находится тот или иной хост.

#### Иерархическая адресация


Когда из адресов строится некоторая иерархия, базируясь на которой, по адресу можно сказать, где потенциально расположен тот или иной хост.

Например, доменные имена (с национальными доменами) типа samos.dozen.mephi.ru могут рассматриваться как иерархические адреса: 
- .ru говорит о том, что это как-то относится к России
- mephi указывает на организацию
- dozen указывает на подразделение в этой организации
- samos указывает на конкретный сервер

Другой иерархический принцип -- выдача адресов IPv6. Адреса выдаются некоторыми блоками: блок национального регистратора, блок провайдера, адрес конкретной организации и так далее.

### По принципу коммутации

#### Коммутация каналов

<a href="https://ibb.co/4Vgk6Pb"><img src="https://i.ibb.co/6WJQ3gK/image.png" alt="image" border="0"></a>

У нас есть какие-то абоненты, которые хотят друг с другом взаимодействовать. Прежде чем эти абоненты смогут это сделать, надо настроить всё промежуточное оборудование в плане того, что этим абонентам будут выделены некоторые физические ресурсы для организации коммуникации между ними.

Таким образом, прежде чем абонент 1 пошлёт какое-то сообщение абоненту 4, в рамках промежуточных коммуникационных устройств надо установить соответствующий канал связи -- некоторую полосу пропускания, выделенную жёстко за ними. 

Классический пример -- старые телефонные сети с аналоговыми коммутаторами.

Два абонента, которые получили доступ к этому каналу связи, могут монопольно его использовать, потому что он предназначается только им. При этом общаться они могут достаточно эффективно, и с их точки зрения всё очень круто.

С другой стороны, другие абоненты, которым таких ресурсов не досталось, вынуждены ждать, пока эти ресурсы не освободятся.

#### Коммутация пакетов

<a href="https://ibb.co/JqvNJBD"><img src="https://i.ibb.co/cw6Png4/image.png" alt="image" border="0"></a>

Мы хотим послать некоторое сообщение, которое может быть достаточно объёмным: например, фильм в HD качестве в несколько гигабайт. Понятно, что такой массив данных одним куском мы передать не можем, поэтому если бы мы даже потенциально могли это сделать, то мы бы потенциально монополизировали какую-то линию связи на достаточно долгое время.

Поэтому на практике мы разбиваем большое сообщение на несколько частей --  *пакетов*. Естественно, когда мы их получаем на абоненте, их надо собрать воедино, и для этого надо как-то маркировать пакеты заголовками. В современных сетях эти пакеты могут приходить в разном порядке, поэтому их надо где-то буферизовать, потом слепить вместе и доставить приложению.

Плюс -- так как мы передаём данные маленькими порциями, мы можем использовать линию связи в режиме разделения времени между большим количеством абонентов -- все получают вроде как равный доступ к сетевой инфраструктуре и все вроде бы довольны.

При этом в современных сетях мы можем приоритезировать трафик:  для каких-то приложений и абонентов мы можем задать более высокий приоритет по обслуживанию трафика, я для каких-то меньше. Всякие QoS (Quality of Service) позволяют оптимизировать эти приоритеты, или, например, каким-то абонентам выделить отдельную полосу пропускания, которая,  если эти абоненты молчат, отдаётся другим, а как только они заговорят, все пакеты других приложений приостанавливаются, задерживаясь в какой-нибудь очереди, а более высокие приоритетные пакеты, для которых мы и зарезервировали полосу пропускания, будут обслужены в первую очередь.

<a href="https://ibb.co/FJSrf2N"><img src="https://i.ibb.co/rMCjLYT/image.png" alt="image" border="0"></a>

Например, так может работать коммутация пакетов на уровне коммутатора (switch). Это упрощённая схема.

У нас есть некоторая коммутационная фабрика или коммутационная матрица, реализованная по тому или иному принципу, и есть порты (interface), через которые можно с этой фабрикой взаимодействовать, и с этими интерфейсами связаны ещё некоторые очереди на вход и на выход.

Когда пакет приходит в некоторый интерфейс, он попадает в очередь на вход, которая обрабатывается в соответствии с некоторой идеологии облуживания (FIFO или очередь с приоритетом), будет передан через коммутационную матрицу в выходную очередь на некотором другом интерфейсе, и когда дойдёт его очередь, он будет выкинут и продвинут на следующее сетевое устройство.

При этом коммутационные фабрики могут быть построены по разным принципам. Например, в сетях есть понятие *блокирующие* и *неблокирующие* устройства.

Неблокирующее устройство может передавать пакеты одновременно между всеми парами абонентов, при этом коммутационных способностей матрицы будет хватать на то, чтобы пакеты, идущие в разные стороны, не блокировали друг друга.

Блокирующие устройства имеют некоторые ограничения, например, на количество абонентов, которые одновременно передают сообщения.

Продвижение пакетов может быть реализована в двух режимах -- store/forward и cut-through.

В **store/forward** мы сначала должны пакет полностью получить и складировать в соответствующую очередь. Мы не можем начать передавать его дальше, пока не получили его до конца -- то есть сначала получили и записали в буфер (store), а потом передали дальше (forward).

В режиме **cut-through**, как только мы получили заголовок сообщения -- первые несколько бит данных, мы уже можем понять адресата -- куда это сообщение передавать. Поэтому само сообщение можно уже начать передавать на соответствующий порт сообщение, которое ещё до конца не получено. Это организуется сложнее, но в ряде случаев позволяет сократить задержки передачи данных.

Классы устройства | Домен коллизий | Широковещательный домен | Уровень устройства | Примечание 
|--|--|--|--|--
Repeater/Hub|Да: одновременно нельзя передавать несколько сообщений | Да | Физический (L1)|Repeater (повторитель) просто усиливает сигнал и передаёт его дальше. Оно не использует хитрую высокоуровневую логику, поэтому классический повторитель -- двухпортовое устройство. Развивая идею, можно сделать *многопортовый* повторитель -- концентратор (hub). Он позволяет соединить несколько устройств, фактически усиливает сигнал, передаваемый через один какой-то порт, но сам hub формально представляет собой некоторую общую среду, то есть можно представить себе мнемонически, что эти порты соединены воедино, и это устройство представляет некоторую шинную топологию -- то же самое, что взять какой-то проводник и подключить к нему какие-то хосты. В данной среде может быть активным только одно устройство, посылающее сигнал. Этот сигнал, хоть он и предназначен конкретному получателю, поступает на все порты -- его получают все, кроме отправителя -- то же самое, что происходит и в шине. Если одновременно два отправителя начинают отправлять сигналы, эти сигналы сталкиваются -- возникает *коллизия*, и данные искажаются. Такие устройства небезопасные (любому устройству доступен весь трафик в сети) и медленные. 
Bridge / Switch (коммутатор) | Нет: устройства могут одновременно передавать данные в рамках существующей инфраструктуры. Любые абоненты общаются друг с другом, не отвлекаясь на другие устройства|Да |Канальный (L2) | Мост передаёт данные между сегментами сети только в случае, если есть получатель. У него есть таблица продвижения: мост знает, какие хосты с МАС-адресами находятся в одном сегменте по отношению к мосту, а какие в другом. При передаче сообщения между хостами в одном сегменте сети оно не попадёт в другие. Это устройство работает на канальном уровне. Эволюция моста -- коммутаторы -- "многопортовые мосты". Коммутатор знает, через какой порт с каким МАС адресом к нему обращаются хосты. Таблица FDB соответствия портов и МАС заполняется в динамике, поэтому есть несколько случаев, при которых сообщение попадает на все порты: broadcast, multicast (не сильно умные коммутаторы), destination location unknown (когда не знаем, куда доставлять). При этом внутренняя организация -- коммутационная матрица, а не шина, и эта матрица в динамике может позволять данные между портами в неблокируемом режиме.
Маршрутизатор (router)/ Switch L3 |Нет|Нет|Сетевой (L3)| Роутер соединяет сети друг с другом. Работает, опираясь на логику уровня выше -- в качестве адресов устройств работают сетевые адреса. На устройствах есть таблица маршрутизации (Routing Table), на основании которой маршрутизатор принимает решение, куда дальше передавать соответствующий пакет. Маршрутизатор, как правило, оповещён о соседних маршрутизирующих устройствах. Базируясь на этой таблице маршрутизации, которая заполняется как статически, так и динамически, есть понятие сети назначения, куда мы хотим передать данные и адрес соседнего маршрутизатора, на который мы это сообщение скидываем (спихивают задачу передачи данных на соседнее устройство, если это сообщение предназначено не в ту сеть, к которой мы непосредственно подключены). Соседа, на который мы спихиваем задачу, обычно называют шлюзом (Gateway). Есть метрика, которая говорит о том, насколько данный маршрут выгоден. Поэтому Routing Table состоит из столбцов Net, Gateway и Metric. При этом маршрутизаторы не передают через себя широковещательный трафик: broadcast сообщения блокируются. Сегодня почти нет отличий между маршрутизаторами и коммутаторами третьего уровня.
Шлюз (Gateway, NAT, NAPT) | -|- |Транспортный (L4) | Это устройства "для дома, для семьи", которые преобразуют номера портов
Gateway (proxy) |- |- | Прикладной (L4+) | Прокси-сервера, могут быть даже на прикладном уровне (в зависимости от конкретной сетевой модели это либо L5, либо L7)

### Топологии сетей

Раз сети связывают некоторые вычислительные системы друг с другом, используя какое-то промежуточное сетевое оборудование, то по сути сетевая инфраструктура представляет собой некоторый *граф*. Поэтому нам важно для обеспечения надёжного, быстрого и высокопроизводительного обмена данными между соответствующими устройствами сети используются различные конфигурации связи устройств.

При этом мы можем рассматривать как *физические* соединения между устройствами (первый уровень рассмотрения) или *логические* топологии, когда мы рассматриваем, какие устройства могут взаимодействовать непосредственно друг с другом.

- полносвязная
- ячеистая
- кольцевая
- звездообразная
- иерархическая
- шина

#### Метрики (характеристики топологий)
- **Диаметр $D$** -- расстояние между максимально удалёнными узлами
- **Связность** $C$ -- рёберная связность: сколько соединений нужно удалить, чтобы сеть развалилась
- **Ширина бинарного деления** $BW$: сколько связей нужно разорвать в сети, чтобы получилось две примерно равноценных топологии. Например, в суперкомпьютерных интерсетях эта метрика используется для того, чтобы определить, как можно сделать разбиение на несколько мини-вычислительных узлов для параллельного решения задачи
- **Стоимость** $Cst$ -- количество связей в графе: показывает затраты на оборудование.

### Характеристики некоторых топологий

#### Диаметр

Топология | Диаметр $D$ 
--|--
Полносвязная | $1$
Двоичное дерево | $2\log_2\frac{p-1}{2}$
1-мерная решётка | $p-1$
2-мерная решётка | $2\sqrt{p-1}$
2D-тор | $\sqrt{\frac p2}$
Гиперкуб | $\log_2 p$


#### Связность

Топология | Связность $C$
--|--
Полносвязная | $p-1$
Двоичное дерево | $1$
1-мерная решётка | $1$
2-мерная решётка | $2$
2D-тор | $4$
Гиперкуб | $\log_2 p$

#### Бисекция

Топология | Ширина бинарного деления $BW$
--|--
Полносвязная | $\frac{p^2}{4}$
Двоичное дерево | $1$
1-мерная решётка | $1$
2-мерная решётка | $\sqrt{p}$
2D-тор | $\sqrt{\frac p2}$
Гиперкуб | $\frac p2$

#### Стоимость

Топология | Стоимость $Cst$
--|--
Полносвязная | $\frac{p(p-1)}{2}$
Двоичное дерево | $p-1$
1-мерная решётка | $p-1$
2-мерная решётка | $2(p-\sqrt{p})$
2D-тор | $2p$
Гиперкуб | $\frac{p\log_2 p}{2}$

### Современные топологии локальных корпоративных сетей (иерархическая сетевая модель)

<a href="https://ibb.co/ZBhLzQc"><img src="https://i.ibb.co/StKswkV/image.png" alt="image" border="0"></a>

У нас имеется три класса устройств в сети:
- устройства **уровня доступа** (access): устройства, к которым подключаются конечные клиенты сети
- устройства **уровня распределения** (distribution)
- устройства **уровня ядра** (core)

#### Уровень доступа

Основная его цель -- обеспечение подключения конечных устройств. При этом надо предоставить большое количество портов для подключения абонентов. Здесь могут решаться иногда и задачи, связанные с безопасностью: например, идентификация пользователей или фильтрация трафика; или задачи, связанные с QoS (Quality of Service): например, приоритезировать трафик для некоторых устройств.

При этом эти устройства представляют собой обычные коммутаторы, просто предоставляющие возможность подключения к сети для конечных устройств.

#### Уровень распределения

Важный момент: устройства уровня доступа -- коммутаторы -- подключаются к устройствам уровня распределения как минимум **двумя** интерфейсами для обеспечения надёжности.

На этом уровне основная решаемая задача -- *Policy-Based Connectivity*: обеспечение соединений в рамках сетевой инфраструктуры, базируясь на некоторых правилах. Под этим мы понимаем всякий хитрый функционал, который у нас есть в сети: агрегирование каналов, применение каких-то правил, управление потоками данных и балансировки -- в том числе, здесь мы можем уже говорить и о задачах маршрутизации. 

Здесь мы обеспечиваем масштабируемость и наращиваемость инфраструктуры: навешивая на устройства уровня распределения дополнительные коммутаторы, мы можем сильно увеличивать масштаб сети, то есть количество потенциально возможных конечных устройств.

Ещё один важный момент -- быстрое восстановление сети в случае аварийных ситуаций. За счёт этого уровня возникновение какой-то аварии на некотором интерфейсе не приведёт к развалу сети, потому что на этом уровне обеспечиваются резервные пути передачи данных.

Устройства уровня распределения подключаются к устройствам уровня ядра несколькими интерфейсами к каждому. Здесь работает технология *агрегирования* каналов, когда несколько физических соединений мы воспринимаем как одно логическое для повышения надёжности и производительности.

#### Уровень ядра

Основная цель -- обеспечение высокоскоростного соединения. Так как через ядро идут очень большие объёмы трафика, этот трафик надо перекидывать на соответствующие устройства ниже по иерархии. Поэтому здесь почти не применяются какие-то хитрые технологии: нам нужны коммуникации с минимально возможной задержкой и максимально возможной пропускной способностью при сохранении высокой стабильности и надёжности.

### Взаимодействие сети организации с сетью Интернет

Существует несколько подходов к организации сети предприятия (интранет):
- интранет является частью интернета. Это плохо, потому что небезопасно
- интранет изолирован от интернета. Это для современных организаций плохо, хотя для каких-то критичных инфраструктур (военные или АЭС) это вполне используется
- часть хостов организации доступны в интранете, недоступном из сети напрямую. Однако при инициации соединения изнутри организации при использовании брандмауэра мы можем предоставить доступ к внешним ресурсам. При этом часть хостов организации находятся в *экстранете*, то есть извне, и являются частью интернета. Интранет отделён от экстранета брандмауэром -- корпоративным фаерволом.

### Основные понятия

**Интерфейс** -- формально определённая логическая и/или физическая граница между взаимодействующими независимыми объектами. Задаёт параметры, процедуры и характеристики взаимодействия объектов.

В сетях разделяют **физический** и **логический** интерфейсы.

**Физический интерфейс (порт)** определяется набором электрических связей и характеристиками сигналов. Представляется в виде совокупности разъёма и набора контактов с определённым назначением.

**Логический интерфейс (протокол)** -- набор информационных сообщений определённого формата, а также набор правил, определяющих логику работы с этими сообщениями.

### Предпосылки многоуровневой организации сетевого взаимодействия

Сетями решается множество задач:
- надёжная передача данных
- передача блоков данных произвольной длины
- разделение среды передачи данных между множеством пользователей
- пересылка данных с максимально возможной скоростью
- поиск пути для передачи данных
- разрыв и установление соединения при передаче данных
- обеспечение защиты данных в процессе передачи
- и так далее

Поэтому слишком накладно реализовывать набор данных функций для каждого сетевого приложения с нуля.

### Принцип сетевого взаимодействия двух узлов
1. Виртуально каждый экземпляр протокола взаимодействует с аналогичным экземпляром на удалённом узле.
2. Каждый экземпляр протокола использует сервисы непосредственно нижележащего протокола, и ничего не знает о протоколах на более глубоких уровнях

### Принцип инкапсуляции

Протоколы более низких уровней "оборачивают" более высокоуровневые протоколы, добавляя некоторую дополнительную информацию, которая обеспечивает некоторый сетевой функционал для доставки сообщения по сети.

### Достоинства многоуровневой организации
- Используется принцип "Разделяй и властвуй":
	- более простое решение конкретной задачи
	- простота отладки
	- надёжность решения
	- ...
- сокрытие деталей реализации механизмов от более высоких уровней
- повторное использование протоколов

### Недостатки многоуровневой организации

- Дополнительные затраты: увеличивается количество передаваемых данных, а, следовательно, и время их обработки
- Сокрытие некоторых механизмов не всегда оптимально для приложений

### SDN и SDDC

Программно определяемые сети и программно определяемый ЦОД.
- конфигурацию сети определяют потребности приложений
- динамическое изменение конфигурации
- разделение сети на Control plane и Forwarding plane

### Референсные сетевые модели

Предоставляют некоторый шаблон, описывающий функционал каждого уровня при многоуровневом сетевом взаимодействии.

Существуют две основных модели: 7-уровневая модель ISO/OSI и Internet Model (DoD) из 4 уровней

<a href="https://ibb.co/SxDtjQH"><img src="https://i.ibb.co/4fw8qsC/image.png" alt="image" border="0"></a>

### Единицы измерения передаваемых порций данных

Единица | Уровень 
--|--
Бит | Физический
Кадр | Канальный
Пакет / дейтаграмма | Сетевой
Сегмент / Пользовательская дейтаграмма | Транспортный
Сообщение | Прикладной

# Физический уровень

## Модуляция

**Цифровая модуляция** -- процесс преобразования цифровых данных в аналоговые сигналы, которые эти данные представляют.
### Виды кодирования
#### NRZ: Non-Return to Zero

Самая простая форма цифровой модуляции

![../_images/f02-04-9780123850591.png](https://book.systemsapproach.org/_images/f02-04-9780123850591.png)

Однако проблема такого сигнала заключается в том, что при большом количестве подряд идущих одинаковых бит теряется **синхронизация** между приёмником и передатчиком. 

#### NRZI: Non-Return to Zero Inverted

При таком способе модуляции 1 обозначается изменением состояния, а 0 -- отсутствием изменения. Это решает проблему подряд идущих единиц, но не решает проблему подряд идущих нулей.

#### Манчестерское кодирование

В данном способе бит данных складывается с часами по модулю два. Однако в таком случае требуется вдвое большая полоса пропускания, так как частота сигнала увеличивается в два раза.

![../_images/f02-05-9780123850591.png](https://book.systemsapproach.org/_images/f02-05-9780123850591.png)

#### 4B/5B

Каждая комбинация 4 бит кодируется специальной последовательностью 5 бит, в которой никогда не бывает больше одного лидирующего нуля и больше двух нулей в конце. Данная последовательность кодируется с помощью NRZI, так что решается проблема большого количества подряд идущих нулей и единиц.

Так как всего пятиразрядных кодов 32, а из них для кодирования 4-битных комбинаций используется 16 + есть несколько запрещённых комбинаций (например, 11111 или 00000), то оставшиеся коды могут использоваться для подачи служебных сигналов.

В таком случае эффективность кодирования равна 80% (4/5).

#### Скремблирование

В данном случае данные перед передачей объединяются с помощью исключающего ИЛИ с некоторой псевдослучайной числовой последовательностью. Это смешение делает данные столь же случайными, как и сама псевдослучайная последовательность, что также должно решить проблему последовательных нулей и единиц.

Приёмник проделывает аналогичные действия с поступающими данными. Для этого ему надо знать исходную псевдослучайную последовательность.

Однако можно специально подобрать такие данные, которые будут походи на эту последовательность, так что в результате применения XOR у нас получатся много нулей, и всё сломается.

### Виды модуляции

#### ASK: Amplitude Shift Keying

Чтобы представить 0 и 1, используются две различные амплитуды сигнала.

#### FSK: Frequency Shift Keying
Используются две или несколько различных частот.

#### BFSK: Binary Phase Shift Keying

Бинарная ("два символа") фазовая модуляция.

<a href="https://ibb.co/z4xwL3F"><img src="https://i.ibb.co/jrfFxCz/image.png" alt="image" border="0"></a>

Можно расширить идею и использовать большее количество сдвигов: например, с шагом в 90$\degree$, и получить **QPSK** -- Quadrature PSK -- квадратурную фазовую модуляцию.

#### Диаграммы созвездий

Все вышеперечисленные типы модуляций можно комбинировать и представлять их в виде диаграмм. Обычно комбинируются амплитудная и фазовая модуляция.

Точки на диаграммах представлены в полярных координатах. $(\rho, \varphi)$, где $\rho$ -- амплитуда, $\varphi$ -- фаза.

<a href="https://ibb.co/1Mj8KVW"><img src="https://i.ibb.co/W0jgF9J/image.png" alt="image" border="0"></a>

### Мультиплексирование

#### FDM: Frequency Division Multiplexing

Использует передачу в полосе пропускания, чтобы совместно использовать канал. Спектр делится на диапазоны частот, каждый пользователь получает исключительное владение некоторой полосой, в которой он может послать свой сигнал.

<a href="https://ibb.co/349dMTZ"><img src="https://i.ibb.co/hLJ9Zgz/image.png" alt="image" border="0"></a>

#### OFDM: Orthogonal FDM

Полоса канала разделена на многие поднесущие, которые независимо передают данные (например, с квадратурной амплитудной модуляцией). Поднесущие плотно упакованы вместе в частотной области. Таким образом, сигналы от каждой поднесущей простираются в смежные. Однако частотная характеристика каждой поднесущей разработана так, чтобы в центре смежных поднесущих это был ноль.

<a href="https://ibb.co/BfNtWDt"><img src="https://i.ibb.co/rQsm8Pm/image.png" alt="image" border="0"></a>

#### TDM: Time Division Multiplexing

<a href="https://imgbb.com/"><img src="https://i.ibb.co/dp34BL8/image.png" alt="image" border="0"></a>

#### STDM: Statistical TDM

Статистическое мультиплексирование

#### CDMA: Code Division Multiple Access

Каждый передатчик кодирует данные в виде прямого или инвертированного числового вектора. Все векторы, соответствующие каждым приёмникам, ортогональны и образуют базис.

<a href="https://ibb.co/mqK2Wdz"><img src="https://i.ibb.co/T8G73Jh/image.png" alt="image" border="0"></a>

Приёмник раскладывает полученную комбинацию сигналов по этому базису и находит, какое сообщение передаёт каждый из передатчиков.

## Защита от ошибок при передаче данных

Поскольку мы передаём данные через изначально неидеальную физическую среду, то возможно появление одиночных или множественных ошибок на уровне кадра. Эти ошибки необходимо уметь обнаруживать, и желательно исправлять. Для этого, понятное дело, необходимо применять специальные коды.

Будем считать, что ошибки носят случайный характер: от целенаправленного искажения данных при передаче защищают другие методы, например, криптографическое хеширование.

### Характеристики защитных кодов

- количество обнаруживаемых ошибок в защищаемой последовательности $d$ -- detection;
- количество исправляемых ошибок в защищаемой последовательности $c$ -- correction;
- минимальное количество ошибок, приводящих к отказу механизма защиты
- накладные расходы на реализацию механизма защиты

### Идея помехозащищённого кодирования

У нас есть отправитель, который отправляет исходные данные $D$ и добавляет к ним некоторый проверочный код $R$, который вычисляется применением некоторой функции $f$ к исходным данным: $$R = f(D)$$

Далее у нас есть некоторый ненадёжный канал $F$, который может исказить как исходные данные, так и проверочный код: $$F(D, R)=D', R'$$Получатель, в свою очередь, получает *потенциально искажённые* данные $D'$ и *потенциально искажённый* проверочный код $R'$. Он у себя вычисляет проверочный код: $$R''=f(D')$$И если $R' = R''$, то мы считаем данные верными.

Однако идеального решения нет. Существует вероятность того, что при $D\neq D'$ будет выполнено $R'=f(D')$, особенно, если искажение данных носит целенаправленный характер.

Однако при *случайном* характере изменений можно построить коды, определяющие и исправляющие искажение данных *с заданной вероятностью*.

### Базовые положения теории кодирования

**Расстояние** для последовательностей $a$ и $b$ равно количеству бит, которые нужно поменять, чтобы из $a$ получить $b$.

**Расстояние Хемминга** для кода -- минимальное расстояние между любой парой кодовых слов.

Известны следующие утверждения из теории кодирования:

**Утверждение 1**. *Для кода с расстоянием Хемминга $h$ всегда можно обнаружить $h-1$ ошибку:* $$c\geq h-1$$**Утверждение 2**. *Для кода с расстоянием Хемминга $h$ всегда можно исправить $\left[\frac{h-1}{2}\right]$ ошибок*: $$d\geq\left[\frac{h-1}{2}\right]$$


Например, для простого повтора: $$\begin{cases}0\to00\\1\to11\end{cases}:\begin{cases}h=2\\d=1\\c=0\end{cases}$$А для мажоритарного кода: $$\begin{cases}0\to000\\1\to111\end{cases}:\begin{cases}h=3\\d=2\\c=1\end{cases}$$

### Основные методы обнаружения ошибок (EDC: Error Detection and Correction)

#### Бит чётности

Сложение по модулю 2 всех битов исходной последовательности.  

|$h$|$d$|$c$|$e$
|--|--|--|--|
$2$ | $1$|$0$|$\frac{\vert D\vert}{\vert D\vert + 1}$

Позволяет обнаружить *нечётное* количество ошибок.

#### Контрольная сумма

Существует множество подходов к тому, как считать контрольную сумму. Основная идея -- сформировать проверочную последовательность *меньшей* длины, чем исходная, используя сравнительно простой набор операций.

При этом бит чётности по сути тоже контрольная сумма.

Контрольная сумма также применяется как общее понятие для всех EDC (Error Detection Codes) и ECC (Error Correction Codes)

Контрольная сумма применяется в протоколах IP, TCP, UDP и других.

Например, рассмотрим алгоритм контрольной суммы для заголовка IPv4:

**Генерация**

1. Разбиваем сообщение на блоки по 16 бит, при необходимости дополняем нулями
2. Блок контрольной суммы заполняем нулями
3. Выполняем суммирование 16-битных слов
4. Если получаем переполнение, то суммируем результат с переполнением
5. Инвертируем результат
6. Помещаем результат на место контрольной суммы в сообщении

**Проверка**

1. Разбиваем сообщение на блоки по 16 бит
2. Выполняем суммирование всех 16-битных слов сообщения, в том числе контрольной суммы
3. Если получаем переполнение, то суммируем результат с переполнением
4. Инвертируем результат
5. Если получили 0, то считаем, что получили корректное сообщение

|$h$|$d$|$c$|$e$
|--|--|--|--|
$2$ | $1$|$0$|$\frac{\vert D\vert}{\vert D\vert + 16}$


Контрольная сумма для заголовка IPv4 позволяет обнаруживать до 16 подряд идущих ошибок.

### CRC: Cyclic Redundancy Check: Циклический избыточный код

Использует вычисление в конечном поле, определяемом некоторым порождающим многочленом (генератором).

Это так называемый **полиномиальный код**. В основе полиномиальных кодов лежит представление битовых строк в виде многочленов с коэффициентами, равными только 0 или 1. Кадр из $k$ бит рассматривается как список коэффициентов многочлена степени $k-1$, состоящего из $k$ членов от $x^{k-1}$ до $x^0$. Старший (самый левый) бит кадра соответствует коэффициенту при $x^{k-1}$, следующий бит -- коэффициенту при $x^{k-2}$ и т.д.

С данными многочленами осуществляются арифметические действия по модулю 2 в соответствии с алгебраической теорией поля. При этом перенос при сложении и заём при вычитании не производится. И сложение, и вычитание эквивалентны исключающему ИЛИ (XOR).

Деление чисел осуществляется в точности так же, как и деление обычных двоичных чисел, с той разницей, что вычитание производится снова по модулю 2. 

При использовании циклического кода отправитель и получатель должны сначала договориться насчёт **образующего многочлена** $G(x)$. К этому многочлену предъявляются следующие требования по обнаружению ошибок:
- одиночные ошибки, поэтому $x^k$ и $x^0$ должны иметь ненулевые коэффициенты
- ошибки с двумя битами, поэтому многочлен должен быть как минимум степени 3
- нечётное количество ошибок, так что многочлен должен содержать множитель $(x+1)$
- "взрывные" (burst) ошибки -- ошибки в некоторой последовательности бит

Для вычисления CRC для некоторого кадра из $m$ юит, соответствующего полиному $M(x)$, необходимо, чтобы этот кадр был длиннее образующего многочлена. Идея состоит в добавлении CRC в конец кадра таким образом, чтобы получившийся многочлен белился на образующий многочлен $G(x)$ без остатка. Получатель, приняв кадр, содержащий контрольную сумму, пытается разделить его на $G(x)$. Ненулевой остаток от деления означает ошибку.

Алгоритм вычисления CRC при этом может быть следующим: 

1. Пусть $r$ --  степень многочлена $G(x)$. Добавим $r$ нулевых бит в конец кадра так, чтобы он содержал $m+r$ бит и соответствовал многочлену $x^r M(x)$.
2. Разделим по модулю 2 битовую строку, соответствующую многочлену $x^r M(x)$, на битовую строку, соответствующую образующему многочлену $G(x)$
3. Вычтен по модулю 2 остаток от деления (он должен быть не более $r$ бит) из битовой строки, соответствующей многочлену $x^r M(x)$. Результат и будет передаваемым кадром, который мы будем называть многочленом $T(x)$.

Должно быть очевидно, что многочлен $T(x)$ делится по модулю 2 на $G(x)$ без остатка.

# Ethernet


### Задачи 802-2001
- Определяются основные понятия (LAN, MAN и т.п.) и общие требования к ним
- Вводит понятие основных коммуникационных устройств: повторителей, коммутаторов и т.п.
- Референсная сетевая модель, использующаяся для описания в т.ч. Ethernet
- Задачи основных уровней
- Принципы управления сетевыми инфраструктурами
- Универсальная адресация -- MAC-адреса.
- ...

### Референсная модель


<a href="https://ibb.co/2NHPLhx"><img src="https://i.ibb.co/k1v0rBj/image.png" alt="image" border="0"></a>

Она, по сути, маппирует физический уровень и уровень Data Link из модели OSI, рассматривая их более подробно, а всё, что выше, в терминологии референсной модели, -- это протоколы более высокого уровня (Upper Layer Protocols).

В свою очередь, канальный уровень (Data Link) модели OSI в референсной сетевой модели распадается на два подуровня: LLC и MAC. Каждый из уровней взаимодействует со своими соседями через некоторые интерфейсы, которые мы называем точками доступа -- Service Access Point. У нас есть соответствующие SAP для физического уровня (PhSAP), для MAC (MSAP), LLC и так далее.

Комитет 802 как раз занимается именно этими уровнями. Всё, что выше, -- прерогатива RFC.

### SAP -- Service Access Point (точка доступа к сервису)

**LSAP** -- интерфейс для протоколов верхнего уровня к сервисам уровня LLC

**MSAP** -- доступ к сервисам уровня MAC для LLC, определяется 
- **одним** МАС-адресом для получения и передачи данных (один персональный unicast адрес у устройства)
- одним широковещательным адресом для получения данных (мы можем получать данные на широковещательный адрес, но **отправлять** с него нельзя)
- одним или несколькими групповыми адресами для получения данных (у конкретного абонента может быть ноль несколько multicast адресов для **получения** данных, отправлять с них нельзя)

### LLC -- Logic Link Control (управление логическим каналом)

Определяет три типа функционирования коммуникационной инфраструктуры, предоставляющей сервисы для протоколов верхнего уровня
- без установления соединения и подтверждений -- классический режим best efforts
- с установлением соединения (восстановление после ошибок и управление): прежде чем начать передать данные, устанавливаем соединение
- без установления соединения с подтверждением (восстановление после ошибок, очередность доставки, запрос данных)


В классическом Ethernet работает самый простой режим из возможных -- без установления и подтверждений. Поэтому если оборудование не может передать кадр дальше, то этот кадр отбрасывается и мы об этом ничего никому не сообщаем. Поэтому все механизмы надёжной передачи данных должны обеспечиваться за счёт протоколов более высокого уровня (Upper-layers protocols).

## MAC -- Medium Access Control

Управление доступом к среде. На этом уровне определяется некоторый функционал, связанный с тем, в каком виде передаются данные:

- разделение на кадры и обнаружение кадров
- адресация узлов получателей данных (как выглядит адрес)
- передача информации об отправителе данных
- прозрачная передача данных уровня LLC
- защита данных от ошибок в процессе передачи. Тут появляется понятия FCS --  frane check sequences -- проверочные последовательности или коды для кадра
- управление доступом к физической среде передачи данных

Сюда же потенциально относятся вопросы управления потоком данных между конечными и промежуточными устройствами.

### Физический уровень

Отвечает за способность получать и передавать биты данных между двумя сущностями. Отвечает за модуляцию сигнала.

На практике часто происходит агрегация более крупных информационных последовательностей (4, 5, 8 бит) в другие информационные последовательности, передаваемые через физический интерфейс.

### Универсальный адрес

Он представляет собой 6 октетов.

<a href="https://ibb.co/646KTFd"><img src="https://i.ibb.co/30txjcJ/image.png" alt="image" border="0"></a>

В рамках этих октетов определяется последовательность бит в зависимости от сетевой инфраструктуры и технологии: например, режимы передачи (LE и BE) в Ethernet и Token Ring отличаются.

Однако важно, что первые три октета позволяют узнать некоторую специфичную информацию о производителе устройства (OUI: Organizationally Unique Identifier) либо по нему мы можем понять, что этот кадр какой-то специфический с точки зрения функционала и используемых механизмов адресации. Например, для мультикаст аресов этот адрес OUI будет адресоваться специальным образом.

Плюс есть группы специальных адресов, которые говорят о том, что мы работаем с какими-то специальными пакетами со специальными режимами адресами.

Например, код 01-80-C2-... говорит о том, что это некоторый специализированный адрес.

Ещё один момент -- интерпретация двух младших разрядов в нулевом октете. По этим разрядам можно понять, к какому классу адресов относится адрес.

Первый признак -- I/G (универсальный или групповой адрес): 0 = I, 1 = G.

Второй признак -- универсальный или локальный адрес (U/L): 0 = U, 1 = L. Адрес был назначен при момощи какого-то механизма (не описывает конкретную индивидуальную систему и не назначен производителем -- это локальный адрес). Если адрес описывает конкретную систему и имеет контекст не только в конкретной сети, но и при переносе в другую инфраструктур этот адрес сохранится -- это универсальный адрес.

В Ethernet адреса передаются с младших разрядов (LSB: Less Significant Bits).

### Группа стандартов 802.1: BRIDGING & MANAGEMENT

Здесь существует довольно много стандартов, некоторые из них особенные:
- IEEE 802.1Ax-2008: ... Link aggregation: тут описаны механизмы агрегации каналов
- IEEE 802.1X: Port-based network-access controle: решаются вопросы аутентификации абонентов при подключении к сети, решение можно принять, например, на основании того, находится ли адрес устройства, которое хочет подключиться, в списке разрешённых, или а основании логина/пароля или цифрового сертификата.

## Базовый формат кадра Ethernet (Ethernet II  / Ethernet DIX)

<a href="https://ibb.co/1R4jJGK"><img src="https://i.ibb.co/xzrd8qG/image.png" alt="image" border="0"></a>

Стандартом предлагается выделить две сущности: более общую сущность **пакет** и более детальную сущность того, что происходит на канальном уровне, -- **кадр**.

Пакет состоит из нескольких частей: кадра, который несёт в себе сформированные на сетевом уровне данные и плюс служебные сигналы в начале и потенциально в конце пакета.

Сигнальная информация в начале состоит из **преамбулы** и **start frame delimiter**. Преамбула -- это просто последовательность единиц и нулей (10101010 ... 10101010), цель которой -- стабилизация и синхронизация передачи данных. Нарушение этой последовательности -- маркер начала кадра 10101011.

После них передаётся основной кадр, который состоит из нескольких частей. В нём есть заголовок из 3 частей и некоторые пользовательские данные, которые инкапсулированы внутрь ethernet кадра (MAC CLIENT DATA), а также некоторый трейлер из блоков FRAME CHECK SEQUENCE и опционально блока PADDING, который заполняет кадр до минимально допустимого размера.

В Ethernet данные передаются начиная с младших разрядов.

В заголовке у нас три поля -- адрес назначения, адрес источника (MAC-адреса), причём адрес получателя идёт первым, чтобы можно было применять технологию cut-through.

Последнее поле заголовка -- поле длины или типа.

### Поле EtherType

Значение этого поля интерпретируется в зависимости от того, в каком диапазоне оно лежит.
- если <= 1500 ⇒ воспринимается, как размер пользовательских данных (MAC Client Data)
- если > 1500 ⇒ определяет тип протокола верхнего уровня
	- 0x0800 -- IPv4
	- 0x0806 -- ARP
	- 0x8100 -- IEEE 802.1Q frame
	- 0x86DD -- IPv6
	- ...

### Максимальный размер пользовательских данных

В современном стандарте Ethernet размер поля MAC CLIENT DATA может сильно варьироваться. В старых версиях это было от 46 до 1500 октетов; в 802.1Q -- 1504 октета, а в некоторых технологиях, например, Jumbo Frames этот размер может быть ещё больше.

**Штатный размер** -- 1500 октет.

Расширенный формат пакета для упаковки дополнительных префиксов и суффиксов протоколов верхних уровней (например, MPLS) могут раздувать размер до 1982 октет.

### Поле выравнивания до минимального размера кадра

PAD = $\max(0, \mathtt{minFrameSize - clientDataSize + 2\times addressSize + 48})$, где $\tt minFrameSize = 512$

### Frame Check Sequence

Используется алгоритм CRC-32.

Дан полином $$G(x)=x^{32}+x^{26}+x^{23}+x^{22}+x^{16}+x^{12}+x^{11}+x^{10}+x^8+x^7+x^5+x^4+x^2+x$$

Берётся дополнение от первых 32 бит кадра. 

$n$ битов защищаемого поля принимаются за коэффициенты полинома $M(x)$ степенью $n-1$ (Первый бит поля адреса отправителя принимается за коэффициент при $x^{n-1}$, а последний бит поля пользовательских данных (или поля выравнивания) соответствует $x^0$).

$M(x)$ умножается на $x^32$ и делится на $G(x)$, в результате чего получаем остаток от деления $R(x)$ со степенью $\deg R \leq 31$. Коэффициенты $R(x)$ принимаются за 32 битную последовательность, дополнение от которой является CRC.

### Поле расширения (EXTENSION)

Применяется только в гигабитных сетях в полудуплексном режиме, чтобы кадр соответствовал минимальной длине уже для гигабитных скоростей (меньше 4096 бит, так что EXTENSION может содержать до 4096 - 512 = 3584 бит)

### Inter Frame Gap

Между кадрами есть некоторые пропуски: мы их отделяем друг от друга некоторыми пропусками, размер которых зависит от конкретной сетевой инфраструктуры.

|||
--|--
Стандартный 10М | 96 бит
1G | 64 бит
10G | 40 бит


## Алгоритм работы прозрачного моста 

Здесь уже речь идёт о связи инфраструктур через некоторое коммутирующее устройство, например, коммутатор, который по сути является мостом.

Этот алгоритм описывается стандартом IEE 802.1D-2004.

Любой порт на любом мосте в соответствии с этим алгоритмом имеет три базовых состояния:
- discarding -- порт не работает, все приходящие на него сообщения он откидывает
- learning -- промежуточное состояние: порт данные не продвигает, но может запоминать адреса абонентов, которые подключены к данному порту
- forwarding -- нормальное состояние передачи данных через порт


У любого коммутатора есть таблица продвижения (или FDB: Forwarding Database), которая ставит в соответствие номера портов и МАС-адреса клиентов, которые с этих портов доступны. Мост обучается конфигурации сети, постоянно обновляя эту таблицу.

<a href="https://ibb.co/jRR3qyV"><img src="https://i.ibb.co/JQQr8vx/image.png" alt="image" border="0"></a>

Всё начинается с того, что к нам приходит кадр, и мы должны решить, что с этим кадром делать дальше. Для начала надо посмотреть на то, кто является источником (Source) кадра и кому он адресован (Destination). Анализ этих признаков называется **применением активной топологии (Active Topology Enforcement)** -- это подпрограмма, которая принимает решение на основании Source и Destination о том, продвигать ли кадр дальше.

### Active Topology Enforcement
1. Порт, на который получен кадр, находится в состоянии продвижения (Forwarding) и
2. Порт, который рассматривается как порт назначения, находится в состоянии продвижения (Forwarding), и
3. Порт, который рассматривается как порт назначения, не является портом, на который получен кадр, и
4. Размер кадра (данных, передаваемых по сети / mac_service_data_unit) не превышает размер кадра, поддерживаемый сетью, подключённой к порту, рассматриваемому в качестве порта назначения: разные сегменты сети могут поддерживать разные размеры передаваемых данных. И в каком-то сегменте может быть поддержка гигантских кадров размерами до 9К, а в другом сегменте -- нет. 

> **Коммутаторы фрагментацией не занимаются, это дело сетевого уровня -- этим может заниматься маршрутизатор**


Если пришёл кадр, для которого в соответствии с FDB неизвестен порт назначения, его мы передадим на все порты в данном коммутаторе за исключением того порта, с которого он пришёл (аналог широковещательного сообщения).


---

Дальше мы смотрим на FDB, и там может быть фильтрация кадров (какие-то запреты или явные привязки к тому, что какой-то абонент должен быть обязательно на каком-то порту), и если мы этот кадр не отфильтровали, мы его помещаем в очередь на передачу.

При этом коммутатор может поддерживать несколько очередей: не все кадры могут быть равноправными, возможна их приоритизация, и в зависимости от приоритета кадр может быть помещён в ту или иную очередь.

Затем работает алгоритм выборки кадра из очереди по некоторой хитрой логике мы выбираем из наших очередей тот кадр, который должен быть передан в данный момент времени.

После этого мы по некоторым правилам можем изменить приоритет данного кадра по некоторым признакам (например, в 802.1Q). Следовательно, в кадре можно что-то поменять, и поэтому далее пересчитывается контрольная последовательность FCS и после этого мы передаём его в соответствующий порт.

### Алгоритм обучения коммутатора

Работает параллельно с алгоритмом прозрачного моста.

- Порт, получивший пакет, находится в состоянии обучения (Learning) или продвижения (Forwarding), и
- поле адреса источника кадра описывает конкретную конечную систему (то есть адрес не является групповым) **групповые адреса в FDB мы не сохраняем** и
- нет статических записей в таблице фильтрации, ассоциированной с этим МАС-адресом, в которой отображение портов определяет продвижение или фильтрации на данном порту, и
- результирующее количество записей в таблице фильтрации (FDB) не превышает максимально допустимого количества записей

При этом запись в FDB помещается не на постоянной основе: через некоторое время она удаляется, если она не подтверждается последующими кадрами.

При этом могут использоваться *теневые таблицы*: с какого-то моменты времени мы начинаем заполнять теневую таблицу (все новые записи будут помещаться и в старую, и в новую теневую таблицу), и в какой-то момент времени старая таблица просто заменится теневой, и заводится новая теневая таблица.

## Jumbo Frames

Начиная с некоторых современных стандартов сети, условно говоря, с гигабитного Ethernet, появилась возможность увеличить размер кадра 1.5К в несколько раз.

По сути, любой увеличенный размер кадра (то есть больше 1.5К) считается "гигантским". В классических стандартах Ethernet есть такие, которые модифицируют размер кадра, включая в него дополнительные поля, суффиксы и префиксы (например, 802.1Q), но мы не считаем их кадры гигантскими: это просто дополнения и расширения. Они всё равно не позволяют посылать пользовательские данные большего размера, поскольку MTU как был 1500 байт, так и остаётся -- на кадры просто навешивается дополнительная информация, не являющаяся пользовательской.

Когда мы говорим о современном Ethernet, и например, о сетевых технологиях, которые позволяют в рамках одной сети передавать данные с использованием разных технологий (например, **FCoE** -- Fibre Channel over Ethernet), то таким стандартом MTU (Maximum Transfer Unit) предполагается уже больше, равным 2500 октет, чтобы мы могли благополучно упаковать туда кадр Fibre Channel, который по размеру превышает 1500 октет.

Кроме того, **MPLS -- Multi Protocol Label Switching** тоже позволяет увеличить размер кадра до определённого количества бит, а именно 1518 + (n * 4) байт, где $n$ -- количество меток, но этот протокол мы в курсе не рассматриваем, а с точки зрения передаваемых пользовательских данных он их размер не увеличивает.

Здесь, за исключением FCoE, MTU не менялось. Однако при появлении сетей с большой пропускной способность появилось желание увеличить размер кадра: например, если увеличенный размер кадра понимает сетевая карта и на отправителе, и на получателе, и всё промежуточно сетевое оборудование тоже, то почему бы не отправлять больше? Соответствующая возможность появляется с помощью настроек соответствующих сетевых устройств.

### Целевые приложения для увеличенного размера кадра
- Server Clustering: чтобы не тратить полезный объём пропускной способности на дополнительные заголовки и между кластерами передаются большие объёмы данных
- Server Backups (larger MTUs permit faster backups): когда мы делаем копию состояния какого-то приложения, передаются большие объёмы данных
- high speed supercomputer interconnect (for data transfer, not messaging): это применимо именно для передачи данных. Когда мы используем сетевую инфраструктуру для обмена короткими сообщениями, например, для синхронизации каких-то переменных, в этом случае гигантский кадр ни к чему
- network file sevrer (NFS) protocol (9000 byte MTU to carry an 8192 NFS data bock): чтобы упаковать блок данных NFS размером в 8192 на канальном уровне, нам нужны гигантские кадры
- iSCSI SANs (9000 bytes to reduce the effect of TCP frame overhead): для сетей хранения данных, построенных поверх IP технологии
- FCoE SANs (2500 bytes to enclose an FC frame of 2000 bytes)

### Достоинства от увеличения размера кадра

Увеличив размер кадра, мы получаем больший эффект: у нас растёт пропускная способность сети и за счёт того, что мы посылаем меньшее количество кадров, а, следовательно, меньшее количество заголовков, нагрузка на обработку этих кадров снижается (снижается загрузка CPU на обработку этих сетевых заголовков).

<a href="https://ibb.co/cvYMQCL"><img src="https://i.ibb.co/n0PZjnC/image.png" alt="image" border="0"></a>

Несмотря на то, что все эти картинки довольно древние, всё это применимо и к современным сетям.

### Затраты на заголовок по отношению к полезным данным

<a href="https://ibb.co/XzTSbBM"><img src="https://i.ibb.co/dQyGr9x/image.png" alt="image" border="0"></a>

На примере протокола iSCSI, где идёт довольно глубокая инкапсуляция (идут заголовки для Ethernet, IPv4, TCP, iSCSI) и только потом идут полезные данные. Если мы используем стандартный размер кадра, то получается, что только порядка 8 процентов идёт именно на заголовки, а полезных данных всего лишь 91.81%. Если мы размер кадра увеличили, то эффективность использования полосы пропускания увеличивается, так как теперь эти заголовки занимают меньше 1.5% от объёма кадра.

### Недостатки использования гигантских кадров

На текущий момент часть недостатков, например, неэффективность коммутаторов из-за повышенных требований к буферной памяти или неэффективность сетевых стеков под большой MTU, уже не играют роли, потому что многие современные коммутаторы и реализации сетевых протоколов уже учитывают то, что размер кадра может быть больше, чем стандартный.

Однако потенциально мы можем столкнуться с некоторыми аномалиями, поэтому, прежде чем внедрять какое-то решение, использующее увеличенные размеры кадра, нужно это решение протестировать -- а не пойдёт ли что-то не так при увеличении загрузки на инфраструктуру?

Тем не менее, по-прежнему остаются две проблемы:
- увеличение задержек
- требуется автоматическое определение MTU

Понятно, что раз размер кадра увеличивается, то другим приложениям, которые конкурируют за доступ к сетевой инфраструктуре, требуется больше времени в ожидании доступа к этому ресурсу. 

Последний момент -- поддержка гигантских кадров должна быть на всём оборудовании, и максимальный размер этого кадра зависит от возможностей оборудования: какие-то сетевые карты поддерживают 4К, какие-то 9, и если попытаться послать кадр размером 9К тому, кто такие кадры не принимает, то данные кадр будет отброшен соответствующим сетевым адаптером как некорректный. Поэтому надо выбрать минимально возможный поддерживаемый объём кадра из устройств в конкретной сети.

## Управление потоком данных

Необходим механизм самосинхронизации сетевых устройств: например, если в сети есть какой-то медленный участок, либо целевое устройство не способно воспринимать данные на высоких скоростях, либо оно очень нагружено и не может обработать вовремя весь получаемый им поток данных. Таким образом, если получающее устройство не может обработать приходящий к нему поток данных, отправляющее устройство должно притормозить и передавать данные менее интенсивно.

Подобные механизмы могут работать на разных уровнях: например, в TCP, в новых версиях IP, но эту задачу можно попытаться решить и на канальном уровне. В современных реализациях Ethernet, который работает в ЦОД (со скоростями 10G и выше, его ещё называют Lossless internet) эти проблемы тоже решаются.

Этот механизм появился ещё в ранних версиях Ethernet (при переходы 10М -> 100М) и называется **PAUSE-кадрами**. Эти сообщения позволяют приостановить передачу данных.

Таким образом, референсная модель несколько обогатилась и в неё добавился опциональный подуровень **MAC Control**.

<a href="https://ibb.co/Ltfz4Gp"><img src="https://i.ibb.co/ts5MydC/image.png" alt="image" border="0"></a>

### Структура MAC Control кадра

У нас появилась возможность послать специальный пакетик -- MAC Control, в котором мы можем закодировать служебное сообщение нашему соседу о том, что мы чего-то от него особое хотим.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/4MLwJhL/image.png" alt="image" border="0"></a>

#### Содержимое PAUSE-кадра

- DA: unicast (можем послать конкретному получателю), broadcast (попросить замолчать всех), 01-80-c2-00-00-01 (этот адрес специально зарезервирован и указывает на соседнее устройство, дальше чем за соседа этот кадр распространяться не будет)
- SA: unicast
- Len/Type: 88-08
- MAC Control OpCode: 00-01
- Param: 512 / скорость интерфейса (этот параметр указывает, на сколько времени нам надо остановиться и замолчать, ничего не передавая)

На самом деле MAC-Control, который был придуман в 100-мегабитном Ethernet, ни для чего другого, кроме как посылки PAUSE-кадров, не использовался. Этот кадр -- обычный кадр Ethernet, в поле Len/Type которого указано число 88-08.

Посылая такие PAUSE-кадры один за другим, мы можем продлять время замалкивания, чтобы справиться с соответствующей нагрузкой.

Идея хорошая, однако получилось так, что этим механизмом в современных сетях практически не пользуются. Он есть, про него почти никто не знает, его даже можно включить, однако последствия посылки таких кадров непредсказуемы. 

#### Недостатки

Основной недостаток в том, что мы блокируем абсолютно *весь* трафик на некоторое время. Мы не можем выполнить приоритизацию трафика и выбрать, какой трафик блокировать: на конечном узле может работать большое количество разных приложений, и среди них могут быть такие, трафик от которых блокировать мы не имеем права, поскольку они критичные для нас, а есть, наоборот, такие, которые мы можем смело заблокировать без особенных последствий.

Ситуация усугубляется, если сеть сложная, и, например, один коммутатор начинает другому соседнему коммутатору посылать эти PAUSE-кадры. Поэтому такой механизм был первой попыткой реализации управления потоком данных на канальном уровне, но он был неудачным, потому что мы блокируем всё без возможности выбора.

### Решение

В современном Ethernet используются специальные механизмы:
- 802.1Qaz: Priority groups: разделение трафика по некоторым группам приоритетов
- 802.1Waz: DCB Exchange Control: обмен настройками между некоторыми устройствами
- 802.1Qau: Congestion Notification: оповещение о перегрузках
- 802.1Qbb: Priority-based Flow Control: приоритизация в управлении потоком передаче данных

Эти решения применимы в современных сетях уровня ЦОД (10Гбит/c и выше). За счёт этих механизмов теперь можно обеспечить **гранулярную** приостановку передачи данных: мы блокируем не всё, а только часть трафика из определённой группы.

### Приостановка трафика группы с определённым приоритетом

<a href="https://ibb.co/LtGKNp8"><img src="https://i.ibb.co/pzmqhXx/image.png" alt="image" border="0"></a>

Теперь у нас есть возможности выделить разные группы трафика -- очереди. Есть очереди с высоким приоритетом, а есть очереди с низким приоритетом. И трафик, который попадает в низкоприоритетную очередь, мы можем взять и заблокировать. В результате часть пропускной способности мы спасём, например, заглушив устройство, которое посылает много данных, но с низким приоритетом, но высокоприоритетный трафик по-прежнему будет проходить.

На уровне ЦОДов такие механизмы используются повсеместно, однако в локальных сетях они не применяются, и управление потоком передачи данных в обычных сетях реализуется не на уровне Ethernet, а протоколами более высокого уровня -- как правило, транспортного.


## Autonegotiation Link Parameters

Если в сети имеются устройства, которые могут работать на разных скоростях (одна и та же сетевая карта в принципе может работать на скоростях 10М, 100М и 1G и в полнодуплексном и даже полудуплексном режиме), то сетевые технологии позволяют им договориться о том, в каком режиме им работать: в зависимости от того, что может наше устройство, и что может соседнее устройство, мы переходим в максимально возможный режим работы. При этом различные режимы работы электрически несовместимы: так используются разные модуляции, разные способы кодирования сигналов и так далее, поэтому в начальный момент времени устройства должны договориться, в каком режиме они работают и только после этого непосредственно приступить к работе. Причём договариваться надо именно на физическом уровне.

Чтобы эти механизмы заработали, надо было добавить некоторые изменения в стандарт.

<a href="https://ibb.co/0MZMLSm"><img src="https://i.ibb.co/jMGMY2b/image.png" alt="image" border="0"></a>

На этой картинке показана эволюция стандартов с точки зрения референсной сетевой модели в сетях 10BaseT -- передача данных по витой паре на скоростях до 10Мбит/с, 100BaseT и 1000BaseT. Видно, что на физическом уровне появляются прямоугольнички *AutoNeg* (в 10М системах такой необходимости не было). В 100М сетях такой механизм был опционален (хотя на самом деле он есть везде), а в гигабитных он обязателен, без него сеть работать не будет. При этом в гигабитных сетях этот механизм стал чуть более высокоуровневым, но на самом деле функционал остался по сути тем же самым.

### NWay алгоритм

Механизм автосогласования работает за счёт NWay алгоритма. Он позволяет согласовать
- скорость соединения
- дуплексность соединения
- для гигабитных сетей выбор для конечных устройств режиме управляющий/управляемый (master/slave) для того, чтобы мы могли правильно кодировать данные: так как в таких сетях по кабелю данные передаются в обе стороны, схема модуляции чуть сложнее и включает в себя понятия ведущий/ведомый
- обратно совместим с механизмом проверки целостности канала **Link Integrity Test** 10М-сетей, если сеть не понимает, что такое автосогласование
- включает механизм получения, обработки и передачи NLP-сигналов (**Normal Link Pulse**).

### Fast Link Pulse vs Normal Link Pulse

Механизм NLP предназначен для того, чтобы проверять, что устройство не отвалилось, если оно не передаёт данные, а живо, но просто молчит. 

<a href="https://ibb.co/zh7cdXw"><img src="https://i.ibb.co/C5MdLbF/image.png" alt="image" border="0"></a>

С помощью этих импульсов можно как раз закодировать возможности автосогласования. Вместо одиночных импульсов передаются несколько импульсов подряд в течение 2мс, и эти импульсы образуют некоторое кодовое слово. Старые устройства, которые не понимают FLP, будут воспринимать такие сигналы как NLP, а новые -- как предложение о согласовании параметров.

### FLP Burst

<a href="https://ibb.co/tqWsR47"><img src="https://i.ibb.co/K23qnXM/image.png" alt="image" border="0"></a>

Эта кодовая последовательность состоит из 33 импульсов. Из них
- 17 нечётных используются для синхронизации
- 16 чётных передают управляющие данные. При этом 1 кодируется как наличие импульса, а 0 -- как его отсутствие.

### Base link code word

<a href="https://ibb.co/vZjw6Jh"><img src="https://i.ibb.co/SR3s4Kc/image.png" alt="image" border="0"></a>

Кодовое слово стоит из заголовка (selector field), в котором кодируется номер стандарта, по которому мы работаем, а дальше мы кодируем наши возможности, устанавливая единичку в соответствующем бите поля Technology ability field.

Плюс есть специальные дополнительные флажки, которые могут использоваться для подтверждения того, что мы увидели от соседа соответствующий с гнал (Ack), и то, что мы можем послать признак того, что после этого кодового слова может идти следующая страница с дополнительными возможностями (NP). Например, в следующей странице будет закодирована информация про гигабитные сети.


### Алгоритм работы NWay
1. Получение минимум 3 одинаковых сигналов FLP последовательностей
2. Выбор наиболее приоритетной технологии, поддерживаемой обоими устройствами
3. Передача FLP последовательности с установленным битом подтверждения 6-8 раз, чтобы сосед наверняка нас услышал
4. Перевод интерфейса в согласованный режим

### Проблемы с несоответствием параметров соединения

- Соединение не устанавливается при несовпадении скоростных режимов работа, так как используются отличные параметры сигналов на физическом уровне
- Соединение может установиться при статической конфигурации на одном/обоих концах при рассогласовании режимов дуплексности
	- потеря кадров от полнодуплексного абонента к полудуплексному при коллизиях
	- повторная передача в обратном направлении при коллизиях

Поэтому автосогласование полезно, так как нам не надо ничего настраивать руками.

# ARP: Address Resolution Protocol

Используется для того, чтобы связать IP-адреса с MAC-адресами. При этом при создании протокола предполагалось, что он сможет связать адреса канального уровня любого протокола с адресами сетевого уровня тоже любого протокола. Но сегодня мы используем ARP только для связи Ethernet адресов с адресами IPv4. В IPv6 будут работать несколько другие механизмы.

Основной стандарт -- **RFC 826**. Плюс есть стандарты **RARP -- Reverse ARP** (RFC 903) и **IARP -- Inverse ARP** (RFC 2390).

## Формат ARP-пакета

Цель: узнать адрес соседа. Если мы хотим узнать адрес соседа, то мы должны спросить его у всех устройств, так как в Ethernet нет какого-то централизованного регистратора (хотя, например в Fibre Channel он есть: там есть некий сервер имён, куда мы можем обратиться и узнать необходимые нам адреса). Поэтому обычно мы используем широковещание.

<a href="https://ibb.co/wydwPMK"><img src="https://i.ibb.co/WnHPMgc/image.png" alt="image" border="0"></a>

Мы посылаем запрос и ожидаем ответ от того устройства, чей IP -адрес мы спрашиваем. От имени владельца никто другой при штатной настройке отвечать не будет. 

Поэтому формат пакета простой: мы задаём интересующий нас адрес **THA -- Target Hardware Address** устройства с IP-адресом **TPA**, здесь же мы сообщаем IP-адрес отправителя **SPA**, свой МАС-адрес **SHA**. Раз мы спрашиваем THA, то обычно это поле не заполняется.

Остальные поля в заголовке дают потенциальную универсальность протокола. Например, в поле **HTYPE** указывается тип протокола, который работает на канальном уровне, а в **PTYPE** указываем тип протокола, который работает на сетевом уровне. В зависимости от этих типов потенциально могли использоваться ещё и адреса переменной длины, поэтому дополнительно указывается длина адресов канального и сетевого протоколов **HLEN** и **PLEN**. Оставшееся поле **OPTYPE** кодирует тип операции -- запрос или ответ.

В стандартном случае эти поля имеют следующие значения:
- HTYPE -- Ethernet 0x0001
- PTYPE -- IPv4 0x0800
- OPTYPE
	- Request 0x0001
	- Reply 0x0002


### ARP запрос

Здесь показан типовой ARP запрос

<a href="https://ibb.co/0smNqwR"><img src="https://i.ibb.co/nP62rWN/image.png" alt="image" border="0"></a>

Мы посылаем широковещательный запрос, посылаем свой МАС-адрес и тип протокола ARP в Ethernet-пакете, а дальше идёт сам ARP-запрос.

Wireshark добавляет свою аналитику в квадратных скобках: этот пакет не gratuitous.

Если у нас в сети есть хост, адрес которого мы запрашиваем, он нам ответит реплаем. Если такого хоста нет, нам никто не ответит, и, послав несколько таких запросов мы понимаем, что соседа у нас нет или он не хочет с нами общаться и пообщаться с ним не удастся.

### ARP ответ

Ответ адресный: тут уже нет никакого broadcast.

<a href="https://ibb.co/KGxprbs"><img src="https://i.ibb.co/DbfHRzM/image.png" alt="image" border="0"></a>

Интересующий нас ответ будет находиться в первом поле -- sender MAC address.

Получая ответ, мы заносим у себя в ARP-кеш связку IP-адрес:MAC-адрес на какое-то время.

### Gratuitous ARP

<a href="https://ibb.co/fYhTKhT"><img src="https://i.ibb.co/DDxj6xj/image.png" alt="image" border="0"></a>

В данном случае устройство запрашивает свой же IP-адрес. Этот механизм позволяет проверить, не занят ли наш IP-адрес каким-то другим устройством -- это нормальная ситуация, когда мы подключаемся к сети и в сетевых настройках у нас уже прописан какой-то IP и мы хотим начать его использовать. Но в сети IP-адреса не должны дублироваться -- они назначаются программно, и возможны ошибки конфигурирования. Если кто-то уже использует наш IP, то надо использовать другой IP.

Такая проблема возникает как при статической конфигурации, так и при использовании DHCP: там может быть конфликт при выдаче IP-адресов.

На самом деле в современных сетевых стеках мы не указываем Sender IP, и там будут все нули: то есть он может быть, а может и не быть. Это идеологически понятно: вроде как мы ещё не проверили, имеем ли мы право использовать этот IP-адрес, а мы уже используем его как Sender IP.

Обычно мы посылаем 2 или 3 таких сообщения. Если ни на одно из них ни пришёл ответ, мы можем использовать свой IP.


## Проблемы безопасности

Потенциальные атаки -- ARP-Spoofing/ARP-Poisoning^
- Заполнение FDB коммутаторов ложной информацией. 
	- возможен перевод коммутатора в режим концентратора при переполнении таблиц коммутации/продвижения (на современных устройствах всё лучше, потому что есть циклические буферы, или можно просто заблокировать порт, с которого приходит слишком много таких сообщений)
	- возможно перенаправление трафика на другой порт для его перехвата
	- DOS атака на конечные системы посредством коммутатора
- Заполнение ARP-кэша конечной системы ложной информацией
	- DOS атака на систему
	- перенаправление и перехват трафика от атакуемой системы

С этим можно бороться, просто не пуская в сеть какие-то левые устройства или мониторя сетевой трафик

### Защита от атак на уровне ARP протокола

- ротация таблиц коммутации в режиме циклического буфера
- ограничение на количество МАС адресов на клиентский порт
- отключение неиспользуемых портов коммутатора
- статические записи в FDB и ARP-кэше
- аутентификации при подключении к сети (802.1Х) + антивирусы и antimalware на конечных узлах.

При этом современные ОС не заносят данные в  ARP-кеш в пассивном режиме: если нам приходит ARP-ответ от хоста, о котором мы не спрашивали, то правильная ОС эти данные заносить не будет.


### ARP и IPv6

В IPv6 протокол ARP не используются. Там работает механизм **NDP** -- механизм обнаружения соседних узлов. При этом проблемы безопасности по сути остаются те же самые.

**SNDP** -- Secure Neighbor Discovery Protocol решает эти проблемы, но под него гораздо сложнее настраивать сетевые инфраструктуры.

# Дополнительные сервисы канального уровня для сетей Ethernet

## Простые сервисы

### Типы Ethernet-коммутаторов

#### По управляемости
- неуправляемые (unmanaged) -- мы не можем повлиять на функционирование устройства
- управляемые (managed) -- предоставляют какие-то хитрые сервисы, и позволяют их настройку и изменение

#### По типу поддерживаемых физических интерфейсов
- с фиксированной архитектурой
- с гибкой архитектурой (использование заменяемых трансиверов)


#### По предоставляемым сервисам
- L2 (Layer 2) -- сервисы канального уровня
- L3 (Layer 3) -- сервисы сетевого уровня. По сути являются маршрутизаторами
- L3+ (иногда обозначаются как L4 или L5). Предоставляют сервисы, работающие на транспортном  и даже прикладном уровне: например, NAT (NAPT), Firewall и так далее


### Способы управления коммуникационными устройствами
#### Командный интерфейс

Подключение через любой Ethernet-порт коммутатора или через специальный терминальный порт.

Используются протоколы Telnet (когда мы не беспокоимся о безопасности, Telnet ничего не шифрует) и SSH.

#### Веб-интерфейс

HTTP, HTTPS


#### SNMP: Simple Network Management Protocol

Это протокол прикладного уровня. Стандарт описывает сетевой протокол, схемы базы данных с конфигурациями, а также набор и структуру объектов данных, используемых при работе протокола.

Многие сетевые устройства его поддерживают и он является универсальным. Однако базовая версия протокола имеет проблемы с безопасностью, поэтому сегодня для управления его не используют, а используют в основном для мониторинга сетевого оборудования

#### Проприетарные приложения и протоколы

#### SDN (Software Defined Networks)

Там есть стандартные подходы для организации сетевых структур и управления ими.


### Зеркалирование трафика (Mirroring)

Мы можем настроить наше коммуникационное устройство таким образом, чтобы мы могли получить копию исходящего/приходящего трафика с заданного/на заданный порт или группу портов и переслать её на другой порт.

Например, если у нас есть проблемный хост, мы можем попросить пересылать весь трафик, который идёт на проблемный порт, на специальный назначенный для этих целей порт, на котором запущено какое-то приложение, которое этот трафик анализирует, например, Wireshark.

Типовые применения:
- troubleshooting
- отладка сетевых приложений в процессе разработки
- мониторинг трафика с целью обеспечения безопасности: например, системы обнаружения вторжений IDS Intrusion Detection System. Эта интеллектуальная система по определённым паттернам в трафике понимает, что например на веб-сервер идёт не стандартная типовая нагрузка, а его дудосят, или идёт сеанс перебора паролей, и может на это среагировать: например, заблокировать диапазон сетевых адресов, с которых идёт соответствующая атака.


Понятно, что эти IDS можно было бы поставить и на самом сервере, но анализ сетевого трафика может быть довольно затратным и сложным и сильно снизить производительность сервера и работы основного критичного приложения. Поэтому вместо этого мы настраиваем сетевое оборудование, предваряющее сервер, таким образом, чтобы весь трафик на сервер передавался ещё и на IDS, например, на другой машине.

### Фильтрация трафика

- отключение неиспользуемых портов -- это основное правило безопасности локальных сетей
- ограничение по МАС-адресам на то, какой МАС-адрес на каком порту может встречаться. Если мы видим какое-то новое сетевое устройство, и его адрес не соответствует тому, что мы ожидаем там увидеть, мы можем этот порт заблокировать
	- Эти правила могут быть статическими: администратор может внести соответствующие записи в таблицу фильтрации МАС-адресов на устройстве
	- либо можно динамически на портах, к которым подключаются клиентские системы, задать ограничение на то, что с заданного порта мы можем запомнить какое-то ограниченное число адресов, и никакие другие впоследствии не пускать.
	- когда мы видим не разрешённый МАС адрес, мы можем либо заблокировать весь порт, либо не пускать это сообщение дальше, либо послать специальное сообщение администратору
- Ограничение на количество пересылаемых кадров определённого типа -- защита от багов и вирусов, которые генерят широковещательные, групповые сообщения и сообщения с неизвестным адресом назначения -- а эти сообщения будут рассылаться по всем портам, кроме порта отправителя, что очень 
ресурсоёмко для коммутатора и для сети в целом. Поэтому может возникнуть желание количество таких кадров ограничивать
- Ограничение на пропускную способность порта, чтобы данный трафик не перегрузил сеть, потому что есть какие-то более важные по отношению к нему приложения

## VLAN

### Problem: flexible connectivity and hardware utilization

Типовая ситуация: в организации куча клиентов. Эти устройства можно разделить на несколько групп с условием, что устройство из одной группы может взаимодействовать с любым другим устройством из той же группы, но не могло взаимодействовать с устройствами из других групп. По сути, между устройствами надо организовать отдельные широковещательные домены -- отдельные изолированные сети. При это понятно, что при необходимости эти сети можно будет связать друг с другом при помощи маршрутизатора.

Классическое решение -- взять для каждой группы по отдельному коммуникационному устройству (коммутатору) и соединить каждое устройство с соответствующим коммутатором. Но если таких сетей много, то придётся закупать много коммутаторов. Более того, клиенты из одной группы могут располагаться в разных местах на довольно большом удалении драг от друга. 

Другое решение -- можно взять один большой физический коммутатор и сделать из него несколько логических коммутаторов. На уровне программного обеспечения этого коммутатора мы скажем, какие порты к какой группе принадлежат. Это сделать очень просто: понятно, что в таком случае у каждого логического коммутатора будут свои таблицы продвижения и какие-то управляющие структуры данных, но с точки зрения аппаратуры и логики самого коммутатора изменения будут минимальными. Такое решение называется **виртуальными локальными сетями**.

### Definition
- Logical, software defined subnetwork
- It allows similar devices on the network to be grouped together into one broadcast domain, irrespective of their physical location to the network

Естественно, что может возникнуть ситуация, когда мы в рамках одного коммутатора такую сетевую инфраструктуру с VLAN построить не сможем. Здесь возникает вопрос: как организовать связь клиентов из одной группы, но подключёнными к разным коммутатором?

Для этого можно соединить эти два коммутатора через свободный порт на каждом из них. Однако такое решение не масштабируемое, потому что чем больше коммутаторов, тем больше связей им будет необходимо, вплоть до того, что почти все порты на коммутаторах будут отданы под связи.

### Problem: can we do better?

Нам нужен признак того, что конкретный трафик принадлежит конкретной локальной сети. В таком случае надо менять формат кадра Ethernet на выходном порту коммутатора, который подключён к другому коммутатору, снабжая его некоторой меткой виртуальной сети. В свою очередь, коммутатор, на который приходит этот кадр, снимает эту метку и передаёт эту метку целевым устройствам в нужной подсети.

Такие метки называются **тегами**.

### VLAN: approaches

- in line with IEEE 802 standards... (единственный подход, который мы рассмотрим)
- some vendors can have proprietary technologies that solve same task or enhance standard approach

### Advantages

- move devices and people with minimal, or ever no, reconfiguration
- change device's broadcast domain and access to resources without physically moving the device
	- by software reconfiguration: a switch, a networks services (RADIUS etc)
	- by moving its cable from one switch port to another
- isolate parts of network from others by placing them in different VLANs 
- share devices and other network resources without losing data isolation and security
- direct broadcast traffic to only those devices which need to receive it to reduce traffic across the network
- connect 802.1Q-compatible switches together through one port on each switch

### IEEE 802.1Q

Virtual Bridged Local Area Networks
- define VLAN service: introduce some modifications in network devices behavioral (algos)
- define methods for traffic prioritization
- GARP VLAN registration protocol
- dynamic VLAN assignment
- interoperability VLAN and STP

### IEEE 802.1Q Tag

Изменяются кадры:

<a href="https://ibb.co/w7n89Rd"><img src="https://i.ibb.co/VxFb7tL/image.png" alt="image" border="0"></a>

Добавляется так называемый 802.1Q тег. Он вставляется в то место, где раньше было поле типа/длины. При этом фактически первые 16 битов в этом теге (**TPID**) как раз задают некоторый код, который раньше воспринимался как код типа-длины, и этот код всегда одинаковый (0х8100). С одной стороны, это очень неэкономно, а с другой -- это позволяет сделать такой механизм прозрачным для коммуникационных устройств, которые ничего про 802.1Q не знают и воспринимают этот TPID как некоторый хитрый тип вложения. После этого идут полезные 16 бит про VLAN, а затем те 16 бит, которые говорят о типе или длине того протокола, который был инкапсулирован в кадр Ethernet изначально.

Таким образом, размер пользовательских данных с точки зрения кадра Ethernet расширился с 1500 до 1504 октет. 

Кроме того, в этом же теге присутствуют **Tag Control Information**:
- **user priority** -- 3 bits, can be used by switch to determine QoS to apply to the frame
- **canonical format indicator** -- 1 bit, defines whether MAC addr is presented in the frame in canonical format (usually is 0 for the Ethernet)
- **VLAN Identifier (VID)** --  12 bits, uniquely identifies the VLAN  which the frame belongs to

### VID values

Value | Descr
--|--
0x000 | null-VLAN, there is no VLAN information in the tag, only user priority information is here
0x001 | Default VLAN, used for classifying frames on ingress through an untagged port
0x002 - 0xFFE | User defined VLANS
0xFFF | Reserved for future implementations

### Пример


<a href="https://ibb.co/bsskLqt"><img src="https://i.ibb.co/Byy9jdk/image.png" alt="image" border="0"></a>

При этом такой пакетик может быть виден не на всех системах: это зависит от ОС, сетевой карты, драйверов и так далее, которые могут удалять эти метки ниже, чем соответствующая библиотека перехвата трафика.

### VLAN tagging rules

- Except for mirror ports, each port must belong to at least one static VLAN. By default, a port is an untagged member of the default VLAN / By default, a port is not in any VLAN and do not forward any traffic
- A port can be untagged for zero or one VLAN. It transmits traffic for that VLAN without adding VLAN tag. Клиентские системы обычно находятся как раз за нетегированными портами
- A port can be tagged for zero or more VLANs. It transmits traffic for these VLANS with adding appropriate VLAN tag
- A port **cannot** be untagged and tagged for the same VLAN: если порт входит как нетегированный в VLAN 2, то он должен при передаче этого трафика этот тег снять. А если он тегированный, то наоборот, он должен передать трафик с установленным тегом.

### Problem: can we do even better?

Вся настройка этих тегов требует человеческого вмешательства. Хочется, чтобы коммутаторы сами договаривались о портах соединения двух коммутаторов, и когда клиент перемещается в другой порт, он динамически поменял своё членство в VLAN.

### VLAN types
- static: configurable "by hand"
- dynamic:
	- created by propagation VLAN configuration between switches (GVRP, MVRP etc)
	- created by propagation VLAN configurations due authentication / authorization process on the port (RADIUS etc)

#### non standard VLAN types

Can be defined by vendors as value added service.

Example AlliedTelesis:
- **Protected**: ports are unable to communicate with each other directly, however traffic from these ports can be routes to another VLANs
- **Private**: there are two kinds of ports: **private** and **uplink**. Private ports are unable to communicate with each other directly, if they are not in the same port group. However, they are able to communicatie with other devices in the network through uplink ports

### Dynamic VLAN information propagation: protocols
- GARP VLAN Registration Protocol
- Multiple VLAN Registration Protocol (заменил GARP в 2007 году)
- проприетарные протоколы от вендоров

При этом бывает такое, что и клиентские системы работают с тегированным трафиком, если им полезно быть одновременно в нескольких VLAN. Тогда клиентский порт можно тоже сконфигурировать как тегированный, и соответствующие теги сниматься на них не будут, следовательно, на конечное устройство будут приходить кадры с тегами. Сетевая карта на этом устройстве уже сама будет разбирать эти теги, определяя, из какого VLAN какой кадр пришёл и как с ним нужно взаимодействовать.

### Архитектура GARP (Generic Attribute Registration Protocol)

Это универсальный подход, который может использоваться для обмена некоторой информации (атрибутов) между устройствами. Поверх протокола GARP мы можем строить некоторые полезные нам сервисы, например, как в данном случае, VLAN Registration Protocol, но помимо этого может быть менее известный MRP -- GARP Multicast Registration Protocol, которая используется в инфраструктурах, где мы должны управлять процессом передачи Multicast сообщений.

У нас есть две базовых сущности -- 
- **GAP Participant**, то есть сущность, участвующая в обмене атрибутами. В данном случае GARP Participant'ом является отдельный порт на коммутаторе. 
- **GARP Application** -- мы можем развернуть приложение на порте Participant, и это приложение как раз и является, например, MRP. Это некоторая часть, которая содержит в себе атрибуты, которыми мы обмениваемся в рамках реализации какого-то полезного на механизма, например механизма обмена информацией о членстве в VLAN'ах.

<div align="center"><img src="https://i.ibb.co/fFTvNTj/image.png" alt="image" border="0"></div>

Взаимодействие между приложениями на разных участниках происходит при помощи механизмов **GIP: GARP Information Propagation**, а **GID - GARP Information Declaration** содержит в себе описания соответствующих атрибутов, и сами устройства, взаимодействуя через сетевую инфраструктуру протоколами ниже, обмениваются кадрами **GARP PDU**, в которые инкапсулируется вся управляющая информация.

### Архитектура GID

<div align="center"><img src="https://i.ibb.co/BnCszTd/image.png" alt="image" border="0"></div>

Он состоит из некоторого набора атрибутов и соответствующих им состояний.

### Структура GARP PDU
- Protocol ID (2 oct)
- Message
	- Attribute type (1 oct)
	- Attribute #1
		- attribute size
		- attribute event
		- attribute value
	-	...
	-	attribute #N
	-	end of message label


#### Attribute events
- JoinIn / JoinEmpty
- LeaveIn / LeaveEmpty / LeaveAll

При помощи Join сообщения мы регистрируем какую-то информацию на устройстве, при помощи LeaveIn эту регистрацию мы убираем.

Messaging is controlled by application state machine timers
- **Join Timer** -- control frequency of GARP PDU messaging
- **Leave Timer** -- control time for attribute registration
- **Leave All Timer** -- control frequency of the total reset event 

#### Recommendation for setting GVRP timers
- Leave time >= Join time * 3: если какое-то сообщение потерялось и мы его не получили, то мы не должны снимать регистрацию соответствующего атрибута прямо сразу, а дать возможность подтвердить эту регистрацию при помощи следующего полученного сообщения
- Leave All Time >= leave time * 8
- Join time should be between 0.4 and 6 seconds

#### Example of GVRP PDU Traffic

<div align="center"><img src="https://i.ibb.co/2gSLPgx/image.png" alt="image" border="0"></div>

#### Example of GVRP PDU Message

<div align="center"><img src="https://i.ibb.co/PtzVFDZ/image.png" alt="image" border="0" height="200"></div>



## Port Based Network Access Control

Идея в том, что у нас есть какая-то сетевая инфраструктура с коммутатором, к которому подключаются сетевые устройства. В зависимости от того, кто туда подключился, мы должны принимать решения
- пускать ли вообще в сеть это устройство
- если пускать это устройство в есть и у нас сконфигурированы VLAN'ы, в какой VLAN это устройство подключить.

Первый подход -- использовать MAC-адреса. Для этого на каждом коммутаторе должны быть табличка, какие МАС мы пускаем, а какие нет. Но это решение неудачное, потому что оно плохо масштабируется, да и МАС адрес можно подделать.

Второй более правильный подход - - **credential-based**: например, ввод логина-пароля. Для этого мы можем на каждом коммутаторе завести табличку с логинами и паролями, однако это не решает проблему масштабируемости.

В таком случае нам нужен **сервер аутентификации** -- единая база с логинами и паролями, к которой просто обращаются коммутаторы, спрашивая, можно ли дать доступ устройству с такими кредами и если да, то в какой VLAN его отправить.

<a href="https://ibb.co/QdhVGgS"><img src="https://i.ibb.co/KwBgHP4/image.png" alt="image" border="0"></a>


### Алгоритм аутентификации

1. Кандидат посылает пакет EAPOL-Start (опциональный шаг). Клиент может такой пакет и не посылать, потому что если на коммутаторе сконфигурирован порт-аутентификатор, он любой первый пакет от клиенты триггернёт на прохождение аутентификации
2. Аутентификатор посылает пакет EAP-Request/Identity, прося клиента представиться
3. Кандидат посылает пакет EAP-Response/Identity, который передаётся серверу аутентификации, представляясь.
4. Сервер аутентификации, выбрав алгоритм аутентификации, посылает пакет EAP-Request
5. Кандидат отвечает серверу пакетом EAP-Response, в котором содержится удостоверяющая его информация
6. Сервер подтверждает доступ клиента пакетом EAP-Success или отказывает в доступе EAP-Reject. Опционально на данном этапе коммутатору и клиенту сервером могут быть переданы различные сетевые настройки, такие как, например, членство во VLAN.
7. В случае успеха порт становится открытым для любого трафика (не обязательно от клиента), пока с ним ассоциирован МАС-адрес клиента в случае установки режиме piggybacking, либо только с МАС адреса клиента
8. Клиент может завершить сеанс связи, послав пакет EAPOL-Logoff, после чего порт перейдёт в состояние блокировки трафика до следующей удачной авторизации.

### Возможные конфигурации

Рассмотрим, кто у нас может выступать в качестве кандидата на доступ к сетевой инфраструктуре. 

#### Соискатель -- конечная система

В этом случае возможные конфигурации такие: во-первых, у нас есть один аутентификатор, к которому непосредственно подключено клиентское устройство. Этот случай как раз показан на рисунке выше.

С другой стороны, понятно, что в принципе возможна конфигурация, когда к одному аутентификатору посредством соответствующего сетевого оборудования подключается не один, а много соискателей (например, с помощью концентратора). Такая конфигурация потенциально возможна, но она не рекомендуется к использованию, потому что она небезопасна.

#### Соискатель -- коммуникационное устройство

Здесь аналогично, возможна конфигурация один аутентификатор - один соискатель; также возможна один аутентификатор - много соискателей (но она является небезопасной).

Кроме того, допускается и взаимная аутентификация устройства: например, когда два коммутатора подключены друг к другу и изначально друг другу не доверяют, то для того, чтобы открыть порты, соединяющие их, на передачу, они сначала должны друг друга аутентифицировать. В этом случае коммутаторы могут иметь каждый свой сервер аутентификации (ААА сервер), либо возможна какая-то хитрая сетевая топология, когда этот процес будет задействовать только один ААА сервер.

### AAA сервер

Это некоторый сервис, который позволяет проводить аутентификацию устройства (Authentication), авторизацию  (Authorization), то есть выдачу соответствующих прав доступа к той или иной сетевой инфраструктуре в том или ином варианте с подключением к тому или иному VLAN, и учёт (Accounting) -- ведение логов о том, кто подключается и отключается от сети, по этим логам можно проводить аудит сетевой инфраструктуры.

Один из самых популярных сервисов -- **RADIUS** -- Remote Authentication Dial In User Service. У него существует несколько стандартов: базовый работает с помощью UDP (2000), есть модификация от 2012 года, которая работает с помощью TCP, что повышает надёжность этого сервиса.

Есть и другие реализации ААА серверов:
- Diameter
	- RFC 6733, 4004-4006
	- Улучшенная обработка ошибок (TCP)
	- Возможность работы в мультидоменной инфраструктуре, когда сервис отвечает за аутентификацию устройств в нескольких независимых доменах (домен в даном случае -- это домен аутентификации: некоторая база данных, в которой написано, какие устройства есть в сети, и какие у них есть права)
- TACACS/TACACS+ -- Terminal Access Controller Access-Control System
	- Первая версия появилась в 1984 году
	- 3 отдельных протокола, сервисы могут быть расположены на отдельных серверах

### Основные сообщения протокола RADIUS
Код | Тип сообщения
--|--
1 | Access-Request
2 | Access-Accept
3 | Access-Reject
4 | Accounting-Request
5 | Accounting-Response
11 | Access-Challenge (специальное сообщение, с помощью которого мы запрашиваем у клиента некоторую аутентифицирующую информацию)

### Структура пакета протокола RADIUS

- Код сообщения
- Идентификатор сообщения
- Размер сообщения
- Аутентификатор (16 байт)
- Атрибуты
	- Тип атрибуты
	- Размер атрибута
	- Значение атрибута

### Некоторые атрибуты
Код | Назначение атрибута 
--|--
1 | User-Name
4 | NAS-IP-Address
5| NAS-Port
31 | Calling-Station-ID -- идентификатор клиента, тут может быть MAC адрес
61 | NAS-Port-Type
79 | EAP-Message -- аутентифицирующая информация

### EAP -- Extensible Authentication Protocol

RADUIS -- это протокол прикладного уровня. При помощи этого протокола взаимодействуют аутентифицирующее устройство (NAS сервер), в роли которого на рисунке выступает коммутатор, и сервер аутентификации (ААА-сервер). Понятно, что должно быть какое-то взаимодействие и на уровне клиента -- пока клиент не получил доступ к сети, он продолжает работать на канальном уровне. Поэтому здесь мы проводим взаимодействие с помощью протокола EAP канального уровня, который работает непосредственно поверх Ethernet.

При этом у RADUIS слоёный пирог протоколов под ним может включать Ethernet, IPv4 и UDP -- он гораздо выше.

При этом сообщения RADUIS и EAP довольно похожи.

EAP поддерживает более десятка методов аутентификации, среди которых **MD5** и **TLS**.

#### Инкапсуляция EAP

Инкапсуляция на канальном уровне обеспечивается по стандарту 802.1Х "EAP over LAN".
- 2001 -- базовый стандарт
- 2004 -- использование данных механизмов в беспроводных сетях
- 2010 --  современный стандарт включает расширенные методы аутентификации


## Агрегированные каналы

Если сервисы для организации VLAN и аутентификации мы относим к механизмам обеспечения безопасности в сетевых инфраструктурах, то следующие два сервисы -- агрегированные каналы и STP, предназначены для повышения надёжности сетевых инфраструктур, а агрегированные каналы к тому же в ряде случаев могут повысить и производительность.

Для агрегированных каналов часто используется термин **trunks**, но он не совсем удачный, потому что этот термин воспринимается по-разному различными вендорами и различными сообществами. Например, Cisco транком называют канал, по которому проходят пакеты, относящиеся к разным VLAN.

**Основная идея** -- объединение двух или более физических каналов (соединений) между двумя, как правило, соседними сетевыми устройствами в один логический, для улучшения характеристик канала, таких как пропускная способность, доступность (надёжность) и так далее. Применяется не только в Ethernet-сетях, но и, например, в FiberChannel.

Однако если мы дублируем соединения между двумя устройствами, возникает проблема: в этом случае любой широковещательный пакет, который придёт на какой-то коммутатор, будет ретранслирован по всем портам.

<div align="center"><img src="https://i.ibb.co/qMK76b1/image.png" alt="image" border="0"></div>

Поэтому в таком случае, как на рисунке, один широковещательный пакет превратится в четыре.

Более того, если мы просто оставим эти 4 физических соединения и никак не предупредим коммутаторы о том, что на самом деле это один логический канал, то этот широковещательный пакет размножится ещё и между самими коммутаторами, то есть пакет, пришедший по первому линку на SW B, будет перенаправлен на остальные три назад. Такая же история будет происходить и для остальных линков, так что эти пакеты троекратно вернутся назад на коммутатор А. По такой же логике на коммутатор В в ответ придут 9 пакетов, и всё это дело будет экспоненциально размножаться, пока в рамках сети не будут рассылаться только эти широковещательные сообщения.

Поэтому коммутаторы надо предупредить о том, что эти соединения на самом деле представляют собой один логический канал. Это мы должны в явном виде настроить либо статически, зайдя в консоль управления коммутатором и указав, что это не отдельные 4 соединения, а 1 логическое; либо коммутаторы должны сами как-то договориться о отм, что они подключены друг к другу четырьмя соединениями, которое нужно объединить в одно логическое.

Это нам даёт повышенную надёжность: если какой-то линк будет выходить из строя, у нас останутся резервные каналы для взаимодействия. Плюс, если мы будем использовать режимы балансировки трафика между этими линками, мы можем повысить
пропускную способность сетевой инфраструктуры: у канала, соединяющего коммутаторы А и В она возрастёт пропорционально количеству этих линков.

Важно, что этот механизм обычно работает только между *соседними* устройствами. Если мы попробуем создать такую конфигурацию (это можно сделать только статически, а динамические протоколы обычно не позволяют провернуть такие штуки)

<div align="center"><img src="https://i.ibb.co/pfLkLTB/image.png" alt="image" border="0"></div>

то если какой-то линк разорвётся, то с точки зрения одного коммутатора он всё ещё останется рабочим, и он продолжит пытаться посылать туда сообщения, что приведёт к потере данных. Так что такая сложная конфигурация не позволяет просто отследить целостность каналов.

Конфигурация агрегированных каналов может быть статическая (руками в консоли) и динамическая (с помощью протоколов), когда соседние устройствами сами договариваются (они видят, что на самом деле они несколькими портами подключены к одному и тому же соседу, и вырабатывают общую конфигурацию по объединению этих нескольких физических каналов в один логический.

Здесь есть стандартный протокол **802.1AX LACP**, и есть проприетарные протоколы от различных вендоров, которые позволяют получить несколько более гибкие и мощные сервисы по отношению к стандартной реализации. При этом что хорошо в стандартном протоколе, так это то, что все устройства обязаны его поддерживать, в отличие от проприетарного, который, как правило, поддерживается только устройством одного производителя.

### Изменение в референсной модели

<div align="center"><img src="https://i.ibb.co/sgtrBhD/image.png" alt="image" border="0"></div>

Чтобы это всё реализовать, потребуется внести изменения в референсную сетевую модель. Раньше мы рассматривали всё, что происходит, в рамках **одного** физического соединения, и у нас был один столбик. Теперь, раз мы можем рассматривать несколько физических соединений как одно логическое, некоторый функционал у нас остаётся за физическим каналом (Physical layer, MAC, MAC Control, -- это для каждого линка своё), но поверх этого, с точки зрения протоколов более высоких уровней, этот канал должен восприниматься как единый сервис передачи данных. Поэтому уровень LLC для них уже будет общий, посему у нас добавляется опциональный уровень агрегации (**Link Aggregation Sublayer**), который уже будет общим для всех физических соединений, включаемых в этот канал, и на этом уровне как раз и будут реализовываться какие-то хитрые структуры данных, алгоритмы и посылка каких-тто управляющих сообщения для того, чтобы этот агрегированный канал мог функционировать.

### Балансировка нагрузки между подканалами в рамказ составного канала

Остаётся одна нерешённая проблема: как мы будем распределять трафик, который приходит коммутатор, по линкам в рамках одного канала, то есть какие сообщения мы будем передавать по какому из физических каналов?

Здесь может быть несколько подходов:

#### На уровне кадров

Это самый простой подход, который можно было бы предложить. Пусть на наше устройство приходит некоторый поток кадров, и первый пришедший кадр мы посылаем на первый линк, второй кадр -- на второй линк, третий -- на третий, четвёртый -- снова на первый (то есть в режиме некоторой циклической очереди), и так далее. 

**Достоинство**: мы получаем близкое к равномерному распределение кадров между подканалами (хотя количество передаваемых данных не обязательно, нам может так не повезти, что в один линк будут постоянно попадать гигантские кадры, а в другой только небольшие, правда тогда можно изменить логику балансировки, и использовать не счётчик кадров, а основываться на объёме переданных данных)

**Недостаток** потенциально ряд протоколов более высоких уровней более чувствительны к порядку прихода кадров, что трудно гарантировать при использовании нескольких подканалов. Причём даже если в протоколе реализован механизм переупорядочивания кадров в нужном порядке, мы всё равно потратим ресурсы на реализацию этого механизма: в буферной памяти на уровне данного протокола будут задерживаться сообщения, полученные вне очереди, что может быть не совсем желательно, если система находится под нагрузкой и обрабатывает большое количество сообщений.

#### На уровне взаимодействующих абонентов

В зависимости от реализации весь трафик от конкретного отправителя или весь трафик, предназначенный конкретному получателю, либо трафик между конкретной парой абонентов, будем направлять всегда в один и тот же канал. Таким образом, мы ориентируемся на адреса отправителя и получателя и на их основании будем выбирать, в какой линк отправлять тот или иной кадр. 

**Достоинство**: весь трафик между двумя абонентами в рамках конкретного протокола будет строго упорядоченным.

**Недостаток**: мы не можем гарантировать даже статистически равномерность использования каналов. В результате для конкретных приложений и конкретных абонентов пропускная способность канала будет равна скорости одного линка. Поэтому, используя такой механизм, мы не можем повысить скорость сети для конкретных абонентов.

Второй вопрос -- а какие адреса мы можем использовать для выбора балансировки. Здесь могут использоваться адреса **канального** уровня -- в этом случае коммутатор должен посмотреть только на кадр Ethernet, который он и так анализирует, поэтому здесь получается сравнительно простая реализация, однако этот механизм может не обладать необходимой гибкостью и опять же не гарантирует равномерную загрузку каналов.

С другой стороны, мы можем залезать на протоколы более высоких уровней и смотреть, например, IP адреса. НО этот механизм уже сложнее -- наше устройство должно будет понимать протоколы сетевого уровня и потенциально даже выше. Поэтому это будет требовать от коммуникационного устройства более глубокого анализа трафика, так что это целесообразно делать, если это устройство уже априори имеет соответствующий функционал, например, маршрутизатора, и используется на уровне L3 и даже выше.

#### С учётом количества переданных данных

**Достоинство**: наиболее равномерная загрузка подканалов

**Недостатки**:
- высокая сложность управления ⇒ затраты на аппаратную реализацию
- недостатки балансировки на уровне кадров

#### В не Ethernet сетях

Могут использоваться другие режимы балансировки: например, в FiberChannel абоненты обмениваются кадрами, из кадров составляются последовательности -- цепочки кадров, передаваемых в одну сторону в рамках обмена данными, и есть понятие Exchange -- несколько последовательностей, объединённых в рамках решения одной задачи. Поэтому весь трафик в рамках одного обмена мы можем запихивать в один канал, а другой обмен -- в другой канал.

### Алгоритмы балансировки

Режим балансировки на уровне абонентов и их адресов самый простой и реализуется всеми устройствами. Здесь можно реализовать несколько подходов способа назначения абонентов на соответствующий канал

#### **Round Robin** 

Циклический буфер абонентов, назначаемых на канал + должны быть алгоритмы старения информации: если абонент долго не общается, то мы должны снять с него привязку к соответствующему каналу.

Такой подход в принципе реализуем, но он достаточно сложен, и он того не стоит.


#### Хеширование

На практике используется как раз совсем простой подход, когда мы вычисляем номер канала как функцию от адреса абонента. Самый простой пример -- взять в качестве номера остаток от деления последнего октета МАС-адреса на количество подканалов в агрегированном канале. Либо, если мы базируемся на адресах и отправителя, и получателя, мы их каким-то образом комбинируем, например, с помощью XOR, берём какое-то подмножество бит и по вычисленному значению мы всегда и направляем в один и тот же канал. 

Здесь могут получиться и некоторые аномалии: если адреса абонентов не сильно удачные, может получиться так, что все эти абоненты будут направлены на один физический канал. Но статистически распределение между подканалами будет равномерное. Так что прежде чем разворачивать подобное решение, нужно посмотреть на то, какие адреса у нас есть, какие режимы обмена и на основании этого уже выбирать конкретный алгоритм балансировки.

### Типичные примеры использования подхода

#### Пример 1

<div align="center"><img src="https://i.ibb.co/LPvvLgs/image.png" alt="image" border="0"></div>

Абоненты общаются каждый с каждым, и нам не принципиально, какой режим балансировки мы будем использовать -- только по адресу отправителя или получателя, или всё вместе. Всё равно статистически получится более или мерное равномерное распределение данных в рамках агрегированного канала.

При этом у нас нет смысла лезть на уровень выше. Не нужно использовать балансировку, например, по IP адресам -- МАС адресов будет вполне достаточно.

#### Пример 2

<div align="center"><img src="https://i.ibb.co/Wk2BPVL/image.png" alt="image" border="0"></div>

У нас есть какой-то хост, с которым хотят активно общаться большое количество абонентов на другом конце агрегированного канала. Сам этот хост представлен одним МАС-адресом, поэтому очевидно, что здесь выбор режима балансировки должен быть похитрее.

С точки зрения Switch 1, на котором находятся абоненты, целесообразно делать балансировку от отправителя к серверу: у нас МАС адреса отправителей разные, а МАС получателя один и тот же, поэтому если мы наоборот, будем делать балансировку по МАС получателя, то весь трафик пойдёт по одному и тому же линку.

А в обратную сторону, когда мы получаем ответ от сервера, мы уже балансируем по получателю.

#### Пример 3

<div align="center"><img src="https://i.ibb.co/zrfRHzH/image.png" alt="image" border="0"></div>


В таком случае, чтобы реализовать алгоритм балансировки, надо смотреть на приложения, которые работают на взаимодействующих друг с другом системах. Если каждая система описывается одним МАС адресом (хотя на самом деле их может быть несколько, если работает система виртуализации и виртуальные машины), то для балансировки нам потребуется адресация из протоколов более высоких уровней.э

#### Пример 4

<div align="center"><img src="https://i.ibb.co/WW3R1YM/image.png" alt="image" border="0"></div>

У нас есть несколько локальных сетей. В этом случае понятно, что так как мы находимся за маршрутизатором, то каждый клиент видится внутри сервера под МАС-адресом маршрутизатора, поэтому балансировка трафика на уровне МАС-адресов работать никак не будет. Так что здесь должен работать режим балансировки на уровне сетевых адресов.

### Перебалансировка абонентов

Перебалансировка абонентов в общем случае производится только при изменении конфигурации агрегированного канала. Например, если агрегированный канал замечает, что изменилась доступность одного из его подканалов, то он исключает его из агрегированного канала, и поэтому меняется выбор подканала, по которому идёт тот или иной трафик. 

По аналогии, при добавлении или исключении подканала в агрегированном канале самим администратором тоже происходит перебалансировка -- причины ты же самые, что и при изменении доступности.

Системы, использующие интеллектуальные алгоритмы балансировки, могут принять решение о перебалансировке абонентов при изменении внешних условий (без изменения доступности каналов, например, загрузки канала). Но, как правило, это даёт слишком большую нагрузку на сетевое оборудование, поэтому такие решения на практике при стандартной реализации агрегированных каналов не используются, а используется что-то более простое, что можно реализовать условно аппаратным способом.

При использовании IP-адресов и логических (TCP/UDP) портов для балансировки соответствующие поля в пакетах выбираются просто по смещению (как раз из-за того, что используются простые алгоритмы), и это приводит к тому, что попытка балансировки трафика по протоколу, который инкапсулирует что-то другое (например, VPN) может быть неожиданной, так как по заданному смещению будут находиться не IP-адреса, а какая-то другая информация, возможно, константная.

### Проблема размножения кадров

- **Агрегированный канал -- логический порт**: условно -- 1 запись на МАС в таблице продвижения ⇒ широковещательный и т.п. трафик идёт по одному из подканалов. Тут нет неуправляемого размножения кадров
- **Двусторонний агрегированный канал** (оба коммутатора в курсе того, что физические порты включены в один агрегированный канал и передают трафик как между двумя логическими соединениями) -- тут тоже проблем не возникает
- **Односторонний агрегированный канал**, когда один из коммутаторов агрегирует подканалы в рамках одного канала, а второй коммутатор этого не делает -- специфичная ситуация, которая бывает, если второе устройство просто не поддерживает агрегированные каналы. В таком случае возникает проблема размножения кадров, но она управляемая. Также из-за этого возможна блокировка трафика из-за того, что кадры будут уходить из агрегированного канала не на тот порт, который указан в таблице продвижения.

Допустим у нас есть два коммутатора, которые соединены несколькими параллельными соединениями, но агрегации каналов в них нет.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/BNQSwpt/image.png" alt="image" border="0"></a>

Пусть с некоторого хоста отправляется трафик на неизвестный адрес. По правилам первый коммутатор должен переслать этот кадр на все порты, кроме того, с которого он получил этот кадр. Если на втором коммутаторе в таблице продвижения также нет МАС-адреса получателя, он сделает то же самое -- и каждый из кадров ещё трижды придёт на первый коммутатор. Такая ситуация называется петлёй, и эти пакеты будут бродить между коммутаторами условно бесконечно.

Аналогичная история и с широковещательными пакетами, только в случае с unicast, если в таблице продвижения всё-таки появится соответствующая запись, есть вероятность того, что размноженные пакеты всё-таки будут направлены в нужный порт и исчезнут из оборота, то broadcast пакеты безнадёжно будут путешествовать между коммутаторами до тех пор, пока между ними не останется только одно физическое соединение -- то есть пока правило пересылки кадра на все порты, кроме того, с которого он пришёл, не перестанет порождать новые пакеты.

Если агрегированный канал настроен с одной стороны, то пакет в обоих случаях (unicast и broadcast) будет передан по одной линии.

<a href="https://ibb.co/sFHDSVZ"><img src="https://i.ibb.co/64BphWk/image.png" alt="image" border="0"></a>

Если на втором коммутаторе агрегации каналов нет, то по правилам полученный кадр будет переслан на все другие порты. В зависимости от конфигурации первый свитч, получив дубликаты этих сообщений, может переслать их обратно на второй коммутатор, до тех пор, пока тот не обучит свою таблицу продвижения и не начнёт продвигать эти кадры туда, куда надо. В случае с broadcast ситуация похожая. Агрегированный канал иногда может определять, когда он получает дубликат того, что он отправил, и нивелировать подобную ситуацию.

### Проблемы статических агрегированных каналов
- **Проблема ошибок конфигурирования**:
	- то, что мы настроили агрегированный канал статически, ещё не означает, что со временем это не приведёт к наличию петель
	- нет STP ⇒ получаем кольцо
	- есть STP ⇒ получаем канал с характеристиками, меньшими, чем предполагаемые (+ нестабильность и непредсказуемость в работе). Сеть не упадёт, но смысла от агрегированных каналов уже не будет
	- в обоих случаях ошибка конфигурирования может привести к тому, что часть абонентов могут стать недоступными
- **Использование пассивных медиаконвертеров (для старых сетей)**
	- Если для агрегирования канала используется прозрачный радиомост -- то есть если каждая линия, соединяющая два коммутатора, составная и соединяется с помощью некоторого активного оборудования, которое весь трафик прозрачно перегоняет в радиоканал и обратно передаёт его по проводным сетям.
	<a href="https://imgbb.com/"><img src="https://i.ibb.co/zRB3jhb/image.png" alt="image" border="0"></a> 
	Если связь между этими мостами прерывается:
	<a href="https://imgbb.com/"><img src="https://i.ibb.co/tCMQGWq/image.png" alt="image" border="0"></a>
	То коммутаторы не знают о том, что произошёл разрыв, и думают, что данный подканал активен -- сами связи, идущие к коммутаторам, остались и работают. Это приводит к тому, что часть абонентов, которые используют этот подканал, остаются без связи.

### Динамические каналы

Снимают проблемы статических каналов за счёт использования специальных протоколов, работающих, как правило, между соседними устройствами, и позволяющими обнаруживать множественные соединения соседних устройств и объединять их в один логический канал.

#### Подходы к построению

- **Link Aggregation Control Protocol** -- работает между соседними устройствами различных производителей
- **Проприетарные протоколы** -- работают между устройствами одного производителя, как правило, соседними, но могут использоваться и топологии с промежуточными звеньями

#### Цели LACP

- Линейное увеличение пропускной способности
- увеличение доступности
- совместное использование ресурсов
- автоматические конфигурирование
- быстрое конфигурирование и реконфигурирование
- определенность поведения
- низкая вероятность дублирования пакетов и нарушения порядка их передачи
- поддержка всех существующих протоколов более высокого уровня (полностью прозрачный механизм)
- совместимость с устройствами, не поддерживающими агрегирование
- поддержка оборудования с разными возможностями и ограничениями
- неизменность формата кадра
- **поддержка управления сети** -- коммутатор должен уметь разделять трафик сети и трафик, который используется для управления

#### Ограничения LACP

- нет поддержки агрегирования более чем между двумя системами -- LACP не позволяет агрегировать сложные опосредованные соединения типа моста из двух коммутаторов, и если такое соединение появится в сети, то это будет кольцо, и для разрешения этой ситуации понадобятся уже другие протоколы 
- агрегирование только МАС уровня IEEE 802.3
- только соединения точка-точка в режиме полный дуплекс -- через LACP нельзя создать однонаправленные соединения
- все соединения в рамках канала должны работать на одной и той же скорости передачи данных. Поэтому если скорость соединения одного из подканалов падает, все другие подканалы также будут вынуждены работать на этой скорости, поэтому иногда такое медленное соединение может просто исключаться из группы

### Состав Link Aggregation Sublayer
<a href="https://ibb.co/VYYkvnb"><img src="https://i.ibb.co/jkkjL0q/image.png" alt="image" border="0"></a>

- **Frame Collector / Сборщик кадров**
	- Отвечает за получение входящих кадров и передачи их МАС-клиенту
	- не решает задачу переупорядочивания кадров -- кадры поступают клиенту в порядке их прихода на сборщик кадров
- **Frame Distributor / Распределитель кадров**
	- Отвечает за получение кадров от МАС-клиента и передачу их через каналы, входящие в LAG
	- реализует алгоритм(ы) распределения кадров по каналам LAG
		- не должен менять порядок кадров в рамках одного обмена
		- не должен допускать дублирования кадров
- **Aggregator / Агрегатор**
	- Объединяет сборщик и распределитель кадров и один или более агрегирующий парсер/мультиплексор, соответствующий физическому каналу, в единый МАС сервис
	- создаётся для каждой LAG
	- с каждым агрегатором ассоциируется один МАС-адрес.
		- может использоваться МАС одного из физических каналов или новый уникальный адрес
- **Control Parser/Multiplexer -- парсер/мультиплексор управления**
	- прозрачно пропускает сообщения управления каналов и сообщения от МАС-клиента в физический канал (нижележащий сервис)
	- разделяет входящие пакеты на пакеты управления каналом (передаёт сервису управления каналом) и все остальные (передаёт на агрегатор)
- **Link Aggregation Control / управление агрегированным каналом**
	- управляет уровнем агрегирования, используя
		- статическую информацию, заданную при конфигурировании устройства
		- динамическую информацию, полученную от LACP
	- **Задачи**
		- Для каждого порта
			- поддержание конфигурационной информации для реализации агрегации
			- обмен информацией с другими системами для включения канала в LAG
			- присоединение/отсоединение порта к соответствующему агрегатору
			- управление агрегатором, используя информацию от соседней системы
		- проверка, что канал действительно входит в LAG
		- добавление канала в LAG или создание LAG при необходимости
		- мониторинг состояния LAG
		- удаление канала из LAG или удаление LAG при необходимости
	- **Свойства**
		- автоматичность
		- непрерывность
		- определенность
		- контролируемость
		- совместимость
		- быстрота конфигурирования
		- низкий ризк недоставки кадров, дублирования или изменения порядка кадров
		- низкие затраты на протокол управления

### Принцип обмена данными по LACP

- обмен не командами, а состояниями. Это позволяет исключить несогласованность из-за разных конфигураций, ошибок или обрывов соединения
- партнёры могут взаимодействовать в пассивном и активном режимах
	- пассивный отвечает, только если приходят соответствующие запросы от активного
- 2 режима работы: быстрый и медленный, которые определяют периодичность посылки пакетов (1 и 30 секунд)
- сложная структура пакета

#### Формат пакета

<a href="https://ibb.co/Mn09HrX"><img src="https://i.ibb.co/0qbQLTw/image.png" alt="image" border="0"></a>

#### Принципы объединения в один агрегированный канал
- подканалы начинаются и заканчиваются на одних и тех же устройствах
- включены в одни и те же VLAN
- параметры соединения совпадают (скорость), полнодуплексный режим (!): оба коммутатора должны передавать свои состояния
- совпадение ключей, назначенных на портах (опциально, административные ключи могут не совпадать)

### Конфигурируемые параметры

- **Приоритет системы**
	 - выбор управляющей каналом системы
	- пара {приоритет системы, МАС системы}: чем меньше, тем выше приоритет
- **Приоритет порта**
	- Выбор порта, который будет включен в LAG, если их количество больше, чем поддерживает система
	- пара {приоритет порта, номер порта}: чем меньше, тем выше приоритет

#### Проблема выбора портов для включения в LAG

Так как у каждой системы своё распределение приоритетов, решения о включении порта в группу принимаются партнёрами независимо. Поэтому существует проблема согласования выбора портов в группе.

Для решения этой проблемы одних приоритетов мало, и был введён алгоритм динамического распределения ключей -- как раз эти ключи должны совпадать на портах для включения их в одну группу. Именно эти ключи передаются в LACPDU. Если ключ порта не совпадает ни с одним ключом из другого порта, это значит, что он не соединён ни с каким другим портом.


### Упрощённый алгоритм динамического управления ключами

Вводятся два типа ключа:
- **административный** -- 16-разрядное число, которое задаётся при конфигурировании устройства. Опциальный
- **операционный** -- меняется динамически управляюще системой при формировании LAG в рамках этого алгоритма

<u>Управляющая</u> система **может** принять во внимание приоритет портов на партнёре, если того хочет.

<u>Управляемая</u> система **всегда** учитывает приоритет порта управляющей системы. Он складывается из
- приоритета системы
- идентификатора сситемы
- приоритета порта на управляющей системе
- номера порта на управляющей системе

#### Идея алгоритма

Выстраиваем на управляющей системе порты в порядке убывания приоритет.

Берём очередной порт:
- если его нет, то алгоритм завершается
- если порт может быть включен в LAG, добавляем его туда
- если порт не может быть включён в LAG, модифицируем операционный ключ для LAG

### Множество LAG между двумя соседними устройствами

Алгоритм динамического управления ключами может сформировать несколько LAG (зависит от программного обеспечения коммутатора).

Обычно на практике
- если у портов совпадают административные ключи, то формируется одна LAG, остальные переходят в режим ожидания (standby)
- если у портов не совпадают административные ключи, то может сформироваться столько LAG, сколько есть различных комбинаций ключей (ключ на управляющей системе, ключ на подчиненной системе) на активных соединениях

#### Временные параметры LACP

- период
	- быстрый: 1 сек
	- медленный: 30 сек
- таймаут: 3 * период
- время ожидания агрегации -- 2 сек
- время обнаружения отключения -- 60 сек для медленного режима

### Маркерный протокол (Marker Protocol)

Опциональный протокол стандарта 802.1AX.
- может применяться распределителем кадров, например, для организации балансировки с учётом таймаутов на канале или с учётом нагрузки
- удалённая система должна уметь отвечать на маркерные сообщения
- в стандарте описан формат и реакция на получение запроса с маркером, но не прописаны сценарии применения такого механизма

### Агрегированные каналы и VLANы

Конфигурации VLAN на каналах, входящих в агрегированные каналы, должны совпадать.
- иначе непредсказуемость работы
- контролируется ПО коммутатора
- в нормальном коммутаторе ПО не позволит создать агрегированный канал на портах с разной конфигурацией VLANов

## STP: Spanning Tree Protocol

Определяет протокол построения покрывающего (остовного) дерева для обеспечения отсутствия петель коммутации в сетях.

### Основные этапы работы STP

- выбор корневого коммутатора (порта)
- выбор пути с минимальной стоимостью до корня
- отключение неиспользуемых соединений

#### Режимы работы порта
- Blocking: порты, которые не вошли в spanning tree и отключены. Он получает BPDU, но никуда его не передаёт
- Listening: порт ожидает приёма сообщения. Он получает и ретранслирует сообщения BDPU
- Learning: порт получает данные и обновляет свои таблицы
- Forwarding: после отработки STP -- рабочее состояние
- Disabled (не участвует в STP)

Такое количество режимов работы связано с тем, что есть режим выбора корневого коммутатора и надо постоянно обновлять информацию о топологии сети. Для обмена такой информацией используются **BDPU**.


### Выбор корневого моста

Как правило, корневой мост выбирается на основе Bridge ID (МАС-адреса), однако, также учитывается и приоритет, который можно задать вручную, чтобы коммутатор стал корневым.

### Алгоритм выбора корневого моста
- в начальный момент времени каждый коммутатор считает себя корневым
- рассылает BDPU со своим ID в качестве корня
- получив BDPU с меньшим ID, перестаёт считать себя корнем, и выбирает в качестве корня коммутатор с этим ID
- ретранслирует BPDU от данного коммутатора

### Выбор пути с минимальной стоимостью до корневого моста

Выбираем путь с меньшей стоимостью до корня. Каждое сообщение, проходя этот путь до каждого коммутатора, накапливает стоимость пройденного пути, и анализируя эти сообщения, каждый коммутатор понимает, с какого порта приходят сообщения с наименьшей стоимостью, и назначает этот порт **корневым** -- именно по нему будет идти взаимодействие в режиме Forwarding.

Чем больше скорость участка, тем меньше его стоимость:

<a href="https://imgbb.com/"><img src="https://i.ibb.co/XJvQXkt/image.png" alt="image" border="0"></a>



### Отключение неиспользуемых соединений

### Служебные сообщения

Используются при создании покрывающего дерева и для его поддержания, потому что возможны некоторые аварийные ситуации, когда активный линк отключается, и эти ситуации надо отслеживать. Поэтому STP работает постоянно, тестируя сетевую инфраструктуру на то, что линки, которые мы используем, действительно живы, и если они не живы, будет происходит перестроение топологии.

Configuration BPDU (Bridge Protocol Data Unit) -- это сообщения протокола. 

Кроме этого, есть особые специальные сообщения примерно такого же формата, но в них скрыт некоторый доп смысл. Например, **Topology Change Notification BDPU** -- посылает тот мост, который увидел, что в сети что-то поменялось, например, отрубился активный интерфейс -- либо умер линк, либо умер партнёр на другом конце провода, и эти изменения, которые нашёл этот мост, он при помощи TCN оповещает в базовой версии протокола, посылая их корневому коммутатору. Но подобные сообщения в более новых версиях рассылаются всем соседям. 

Корневой коммутатор инициирует конфигурационные BDPU и все коммутаторы их просто пересылают. Сами по своей инициативе, когда коммутаторы не считают себя корнем, такие сообщения не посылают в базовой версии протокола. 

Коммутатор в ответ на получение TCN посылает TCA. Это сообщение дойдёт до корневого моста, и он понимает, что что-то в сети поменялось, и он должен оповестить всю сеть о том, что что-то поменялось. В формате пакета есть флаг ТС, которые устанавливает корневой, это сообщение пересылается в течение некоторого временного промежутка, сконфигурированного исходя из предполагаемого диаметра сети (их можно поменять при необходимости). Это сообщение будет продавливаться через всю сеть, и се коммутаторы в результате узнают, что топология изменилась. Раз она изменилась, то изменится доступность определённых МАС адресов по портам. И значит появятся какие-то некорректные записи в таблицах продвижения коммутаторов. Поэтому каждый коммутатор, получив это оповещение об изменении топологии, очищает всю таблицу продвижения. Плюс идёт пересчёт топологии, то мы заново рассчитываем маршруты, поэтому в течение некоторого времени сетка будет простаивать.

 В каждом состоянии порт по умолчанию находится 15 секунд в изначальной версии протокола (это можно поменять) (discarding --> forwarding), поэтому сетевая инфраструктура некоторое время будет недоступна. Порядка минуты сеть не работает. Поэтому базовая версия STP нам не подходит по текущим меркам.

При изменении топологии получается фактически происходит сброс всей сетевой инфраструктуры, и в течение какого-то времени эта инфраструктура будет недоступна.

## RSTP: модификация STP

Проблема того, что сетевая инфраструктура реагирует на изменение доступности портов довольно долго, нам не нравится. Плюс есть состояния listening/learning портов, которые избыточны: сегодня состояние listening по большому счёту не нужно.

Появился Rapid STP протокол, в котором избавились от состояния Listening. Также появились краевые порты egde ports -- это порты, на котором мы гарантированно знаем, что за ним нет кольца. Например, если на порт коммутатора повешен хост, на нём уже никаких колец возникнуть не может. Поэтому этот порт не нужно включать в STP так, чтобы изменения этого SP влекли события на нём.

Или если на какой-то порт повешен только один коммутатор, на который повешены одни хосты -- тут тоже не будет колец, поэтому тут нет смысла включать полноценную поддержку STP.

В таких случаях можно назначить порт как краевой -- то есть за такими портами есть либо хост, либо кусок сети, за которым нет колец.

Потенциально там на самом деле может получиться некоторая кольцевая инфраструктура, но по умолчанию edge port не учитывает изменения топологии только до тех, пока на него не пришёл BDPU. В этом случае порт тут же теряет статус краевого и становится обычным портом -- это защита от того, что вдруг когда-то кто-то всё-таки закольцует сеть за этим портом.

Кроме того, теперь все коммутаторы генерируют BDPU, а не только корневой. Это решает проблему, если у нас умирает корневой коммутатор или падает путь к нему. Теперь каждый играет активную роль, а не только пассивного ретранслятора сообщения от корневого. Поэтому реакция на события будет быстрее.

Кроме того, изменились тайминги перевыбора корневого коммутатора, режим выбора соседних устройств, формат DBPU (новые флаги и т.п.).

Теперь флаг ТС об изменении топологии могут рассылать все коммутаторы: мы не ждём сообщение от корня. Поэтому мы моментально удаляем запись из таблицы продвижения.

Изменились роли портов. Порт, который ведёт от коммутатора в сегмент сети (от корня в низлежащие сегменты), он был выделенным (Non-designated), а все порты, которые не являются этими выделенными (назначенными) имели статус неназначенных. Если происходила авария на неназначенном порте, мы должны были по изменениям топологии переключиться на какой-то из неназначенных портов. Теперь появилось два дополнительных состояния -- неназначенный порт может быть альтернативным или резервным. 


### STP и агрегированные каналы

С точки зрения STP агрегированный канал это одно логическое соединение. Эти два механизма могут работать совместно.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/2jk5Knr/image.png" alt="image" border="0"></a>

Если мы в такой сетке включим LACP, но без STP, будет закольцовывание -- сетка всё равно работать не будет.

Если убрать LACP и включить только STP, сеть работать будет. Но все лишние соединения будут заблокированы. В результате во всей сетке останется всего три линка. Сеть будет работоспособной; если на одном из назначенном линков произойдёт авария, мы переключимся на резервный, и всё будет хорошо -- надёжность будет высокая, но производительность будет низкая, потому что вместо 2-3 линков на каждом сегменте будет использоваться только один.

Поэтому хочется использовать оба механизма сразу, и STP, и LACP. Сначала включаем LACP -- так каналы сагрегируются в логические линки, и поверх этих логических линков должен будет сработать STP.

В таком случае, если работают оба протокола, получится и повышенная надёжность, и повышенная производительность.


### STP и VLANы

Вопрос, как это реализовать.

Есть несколько подходов.

Первый -- одно общее дерево на все VLAN. Это просто, но могут быть и неоптимальные маршруты.

 Пусть у нас есть куча коммутаторов, соединённых в кольцо, и к каждому коммутатору подсоединены хосты. В этой сетке есть VLANы. Поэтому линки между коммутаторами передают тегированный трафик.

<a href="https://ibb.co/xM0pS1X"><img src="https://i.ibb.co/9qLF9bc/image.png" alt="image" border="0"></a>

Как сделать так, чтобы трафик в сети передавался оптимально межу хостами?

У нас есть кольцо. STP это кольцо где-нибудь разомкнёт, но можем ли мы повлиять на то, в каком месте он разомкнёт это кольцо? Радикальное решение -- снизить скорость на каком-нибудь линке. Не радикальное решение -- изменить приоритет (то же самое что было в LACP) -- некоторое число, которые занимает 2 октета, и если они равны, то дальше сравнивается МАС-адрес. Если мы задаём поле Priority в явном виде, можно перевесить любой МАС-адрес, поставив максимальный приоритет. Тем самым можно сдвинуть в сети корень.

Если обрубить связь внутри одного VLAN, то хосты в рамках этого vlan будет вынужден гонять трафик через всю сетку ==> большие задержки + зафлуживание всей сети пакетами из VLN (например, если сделать размыкание вести в самом нижнем сегменте, то 30 VLAN будет страдать).

Но картинка такая, что как бы мы не разомкнули, то какой-то из VLAN всё равно будет обиженным -- то есть хосты этого VLAN будут находиться на разных концах сети. Поэтому решение в виде общего дерева для всей сети не очень хорошее.


Второй подход -- каждому VLANу по дереву. Для каждого VLAN будет выбран свой корень, своё покрывающее дерево. Но проблема в том, что таких VLAN будет много, покрывающих деревьев будет много ⇒ очень много служебных сообщений + очень много вычислительных ресурсов сетевого оборудования на поддержание этих деревьев.

Третий подход -- промежуточное решение. Исследуя топологию сети, распределение хостов по VLAN и тд,  можно построить несколько оптимальных деревьев. В нашем случае хотя бы два дерева достаточно, чтобы не было такого, чтобы хосты из одного VLAN не оказывались на разных концах сети -- например, к одному дереву привязать 42 и 8, а к другому -- VLAN 12 и 30. Деревьев меньше, чем VLAN ⇒ будут несколько деревьев, на которые некоторым оптимальным образом лягут VLAN.

Эта идея используется в MSTP. Мы можем создать несколько vlan-независимых деревьев и привязать деревья к ним + обмен данными между деревьями инкапсулируется в один пакет, поэтому нет взрывного роста количества управляющих пакетов, хотя сами пакеты чуть увеличатся.

### MSTP

Совместим с RSTP.

Вводится понятие экземпляра покрывающего дерева. Их ограниченное количество, но для совсем больших сетей вводятся уровни иерархии -- появляется понятие региона -- некоторое выделение коммутаторов, имеющих общий взгляд на топологию. В регионе используется один и тот же набор деревьев. Но сеть может быть такой большой, что в другом регионе может быть оптимальным другой набор деревьев.

Внутри регионов связываются коммутаторы, внутри регионов еть ещё куча VLAN, несколько экземпляров деревьев.

Регионы обмениваются через общее дерево CIST. Весь обмен сообщениями в рамках сетевой инфраструктуры происходит через общее дерево между регионами + внутри каждого из регионов есть общее дерево, которое как раз и будет совместимо с RSTP, в рамках которого будут рассылаться все управляющие сообщения. Однако дополнительные сущности MSTI независимы от этого общего дерева.

Структура конфигурационного пакета

- заголовок
- параметры CIST (это соответствует тому что будет в RSTP -- если коммутатор не знает что такое MSTP, дальше в пакете он не смотрит)
- параметры msti1
- ...
- параметры msti n


Пакетики распространяются в рамках CIST.

Этот протокол довольно сложный, иногда нужна ручная конфигурация.

### Shortest Path Bridging и TRILL

В STP было плохо то, что какие-то линки в нём отключаются. Да, если использовать хитрую конфигурацию VLAN, можно получить интересные эффекты,, всё равно какие-то линки отключаются -- это не очень хорошо и слишком накладно. Использовать все возможные пути коммуникации -- современная идея

<a href="https://ibb.co/S0BKp3f"><img src="https://i.ibb.co/P4g586D/image.png" alt="image" border="0"></a>

Аналогичное решение, но сделанное несколько по другому и являющееся стандартом не IEEE а ETF (RFC) -- TRILL: Transparent Interconnection of Lots of Links. Мы прозрачно дл конечных приложений используем все возможные пути доступа.

# IPv4

Этот протокол появился в 1981 году, то есть он достаточно старенький, а следовательно, в нём используется ряд решений, которые сегодня бы приняты не были. 

Протокол IP создавался совместно с ICMP, и предполагалось, что они будут использоваться тоже совместно.

### Задачи

Данный протокол работает в сетях с **коммутацией пакетов**. Большинство решений в IPv4 появились из-за того, что посылаемые данные мы вынуждены дробить на пакеты.

Также этот протокол обеспечивает передачу **блоков** данных (дейтаграмм) от отправителя к получателю, определяемых **адресом** фиксированного размера. Адрес на самом деле занимает не так много места -- 32 бит, на 1981 год этого казалось много. Из-за этого возникло много проблем ⇒  разные схемы адресации, диапазоны адресов, хитрые схемы преобразования адресов и так далее.

В этом протоколе реализован **механизм фрагментации данных**. При помощи IP через сетевую инфраструктуру канального уровня, которая имеет ограничение на размер кадра (1500 для MTU в стандартном Ethernet) надо дробить блоки данных (в IP максимум 65К), чтобы запихнуть в канальный уровень + обратно восстанавливать раздробленные данные.


### Ограничения протокола

Что протокол не может:
- нет механизмов **обеспечения надёжности** доставки данных. На самом деле есть некоторые рудиментарные механизмы, которые совместно с ICMP кое-что могут дать, но это настолько рудиментарно, что как будто их и нет. Более того, эти механизмы могут быть недоступны, если кто-то заблокирует ICMP-сообщения, поэтому можно сказать, что формально в IPv4 таких механизмов нет. Для решения этих задач используются протоколы транспортного уровня: TCP, SCTP, PGM и т.д.
- нет механизмов **управления потоком данных** в базовой версии. Есть ECN (Explicit Congestion Notification) (RFC3168), но эти механизмы добавлены потом и работают не совсем самостоятельно и зависят от решений, которые используются в протоколах более высокого уровня, и полноценного механизма управления потоком всё равно не выходит. Если нам это нужно, то используются хитрые протоколы транспортного уровня
- Нет механизмов **гарантии передачи дейтаграмм в определённой последовательности**. Мы взаимодействуем через маршрутизирующие устройства между локальными сетями, не обязательно построенных при помощи Ethernet. В межсетевых коммуникациях могут быть различные пути доставки сообщений: данные могут теряться и задерживаться, поэтому отосланные одним хостом данные другому хосту могут пойти по разным путям, и если первый пошёл по длинному пути, а второй по короткому, то второй пакет может прийти быстрее. Но если мы разбили дейтаграмму на фрагменты, то для фрагментов мы нужный порядок обеспечиваем. Но для отдельных дейтаграмм такой порядок не гарантируется. То есть сбор дейтаграмм из фрагментов есть, но восстановление потока из множества дейтаграмм не работает. Если же это нам необходимо, тот тут снова надо пользоваться протоколами более высоких уровней.

## Адресация

Допускается несколько форматов задания адреса, но наиболее употребим в виде 4 октетов в десятичной системе счисления, разделенных точками -- W.X.Y.Z

Так как мы распределяем адреса уже в глобальном масштабе, естественно, чтобы они распределялись блоками и чтобы в одном сегменте сети адреса хостов принадлежали одному блоку, и тогда задача **маршрутизации**, то есть организации путей доставки сообщений от одного хоста к другому в глобальном масштабе, будет решаться гораздо проще. Иначе мы должны были бы знать, где находится каждый хост в глобальной сети, и тогда таблицы маршрутизации, где содержалась бы информация о каждом хосте, были бы гигантскими, а задача маршрутизации - трудно разрешимой.

Поэтому адресное пространство в IPv4 предполагает некоторую иерархическую структуру. При этом она не так сильно выражена, как в IPv6.

В рамках локального сегмента сети мы предполагаем, что адреса хостов принадлежат какой-то определённой группе адресов. Для определения этих групп существует два подхода:
- исторический подход -- **классовая адресация**, который на сегодняшний день считается устаревшим: когда по первому октету адреса мы понимаем, к какому блоку относится адрес, и маршрутизация выполняется в рамках этих заранее определённых блоков
- современный подход -- **задание маски сети**

### Классы адресов

Предложено было ввести 5 классов адресов -- A, B, C, D, E, которые определяются значением старших бит старшего октета адреса:
- A: 0XXXX...
- B: 10XXX...
- C: 110XX...
- D: 1110X...
- E: 1111X...

Класс определяет, сколько бит в адресе хоста будет отводиться под адрес сети (то есть под адрес непрерывного блока, который формально принадлежит одной локальной сети), а какая -- на номер хоста в сети, то есть номер хоста в рамках блока.
- A: W -- адрес сети, X.Y.Z -- адрес хоста
- B: W.X -- адрес сети, Y.Z -- адрес хоста
- C: W.X.Y -- адрес блока, Z -- адрес хоста
- D: multicast трафик -- это класс формально остался
- E: экспериментальный класс, единственный адрес, который мы из него используем -- это 255.255.255.255.

Этот механизм является устаревшим, потому что он не обладает необходимой гибкостью: предполагается, что есть ограниченное количество больших сетей класса А (126 сетей, где может быть порядка миллиона хостов -- такие большие локальные сети имеют право быть, но вряд ли она будет работоспособна), класса В и класса С:

<a href="https://ibb.co/CM84MGC"><img src="https://i.ibb.co/SdyHdCY/image.png" alt="image" border="0"></a>

В этой таблице формально в столбце "максимальное число узлов в сети" **надо вычитать ещё 2**: у нас не могут быть заняты адреса со всеми единичками (это широковещательный адрес сети) и со всеми нулями (это адрес самой сети).

Помимо широковещательного адреса сети (типа 192.168.10.255/24) есть *ограниченный* широковещательный адрес 255.255.255.255 -- по второму адресу вещание будет вестись по всем адресам в рамках широковещательного домена -- то есть если в рамках локальной сети мы создадим несколько сетевых диапазонов, то с 255.255.255.255 broadcast будет работать для всех из них. Однако с точки зрения прохода этих пакетов через маршрутизаторы они ведут себя практически одинаково: **широковещательные сообщения маршрутизаторы не передают**.

Впоследствии стало понятно, что такие жёсткие разделения на классы и использование их и только их для определения сетевого диапазона и, соответственно, определения маршрутов передачи данных не обладают необходимой гибкостью: если нам нужна сетка не на 254 хоста, а на 300, то придётся брать класс В, но в классе В может быть 2^16^-2 хостов, что уже довольно много и неразумно.

### Маски

Маска может интерпретироваться в двух видах. Например, она может записываться так же, как и сам IP-адрес: для класса А маска была бы равна 255.0.0.0 -- маска показывает, какие биты отвечают за адрес сети, и в данном случае 255 = 8 единичек ⇒ за адрес сети в таком случае будут отвечать первые 8 бит.

Можно писать и просто через слеш /8 после адреса. Маска обязательно должна быть непрерывная, то есть сначала идут только единички, а затем только нолики (соответствует в битовом представлении шаблону 1\*0\*), и поэтому для задания маски можно просто указать, сколько в ней единичек. 

Соответственно, для класса В эта маска будет равна 255.255.0.0 = /16; для класса С -- 255.255.255.0 = /24.

Теперь, если нам нужна сетка на 300 хостов, мы можем просто сдвинуть маску на один разряд влево, и получить маску не /24, а /23, то есть не 255.255.255.0, а 255.255.254.0.

Маска -- это параметр настройки: мы её конфигурируем в настройках сетевого адаптера, но мы её не передаём в пакете. То есть **информация о маске в дейтаграмме отсутствует**. Маска есть только на конечных системах и на маршрутизаторах для построения таблицы маршрутизации, но в пакетах она не указываются -- там только адреса.

### Зарезервированные адреса

В нормальных сетях -- то есть в рамках глобальной пересылки данных такие адреса встречаться не должны.

- **0.0.0.0/8** хост отправитель из данной сети (0.0.0.0/32 может применяться в поле адреса отправителя). Сейчас этот подход считается устаревшим, но он используется, например, в Gratuitous ARP, если хост не хочет указывать свой адрес, он может указать там 0.0.0.0.
- **10.0.0.0/8** -- блок адресов для частных сетей, не маршрутизируется в интернете. Мы можем внутри организации спокойно использовать такие адреса, зная, что никто в глобальном масштабе на них не претендует. Эти адреса могут использоваться внутри частных сетей без разрешения регистраторов. Любой маршрутизатор в глобальной сети не пропускает пакеты с такими получателями или отправителями.
- **127.0.0.0/8** -- блок адресов для использования внутри хоста (обычно 127.0.0.1/32), не должны появляться в сети. Эти адреса можно использовать для организации коммуникации внутри системы, например, посредством сокетов, и чтобы внутренний трафик никуда за пределы этой системы не выходил, можно использовать специальный адрес *localhost*, который по умолчанию равен 127.0.0.1, но на самом деле можно использовать любой адрес из этого диапазона, и он будет считаться локалхостом.
- **169.254.0.0/16** -- блок адресов для адресации  в рамках локальной сети, используются при автоматическом самоназначении адреса. Адрес хосту мы можем назначить **статически**, как на лабах, либо **динамически** -- DHCP (для этого нужен какой-то централизованный сервер, который будет обслуживать запросы клиентов) или 169.254.0.0/16 (APIPA/Zeroconf), когда DHCP-сервера нет -- здесь хост будет сам себе назначать адрес из этого диапазона, чтобы попытаться пообщаться хотя бы с соседними хостами. Есть ещё **комбинированный** способ назначения сетевых адресов: например, если нам не удалось сконфигурировать его динамически, мы делаем это статически.
- **172.16.0.0/12** -- блок адресов для частных сетей, не маршрутизируется в интернете, аналогично 10.0.0.0
- **192.0.2.0/24** -- блок адресов для использования в документации (примерах настройки сети: если мы укажем в доках какой-то реальный адрес, его кто-то повторит и возникнет конфликт), не должны появляться в интернете
- **192.88.99.0/24** -- блок адресов преобразования адресов IPv6 в IPv4. Сейчас он не особо актуален
- **192.168.0.0/16** -- блока адресов для частных сетей, не маршрутизируется в интернете
- **198.18.0.0/15** -- блок адресов для тестирования производительности

### Зарезервированные адреса класса D (Multicast)
- **224.0.0.0/24** -- блок адресов для локального использования, не передаются за пределы сети. Из этого диапазона используются также некоторые фиксированные адреса, которые для некоторых протоколов будут иметь определённые роли. Например, 224.0.0.5 -- все маршрутизаторы в рамках локального сегмента.
- **224.0.1.0/24** -- блок адресов для использования в интернете, назначаются IANA
- **239.0.0.0/8** -- для использования внутри домена, не должен выходить за пределы административного домена (сети некоторой организации). Он будет распространяться между локальными сетями, в отличие от 224.0.0.0/24, но не должен покидать пределов организации.

### Замечание

 Хосты, находящиеся в одном широковещательном домене, но имеющие адреса из разных сетей, не могут непосредственно (без посредничества маршрутизатора) взаимодействовать друг с другом на сетевом уровне (но, естественно, могут на канальном). Таким образом, хосты смогут взаимодействовать по МАС-адресам, но по протоколам более высоких уровней они общаться не смогут, потому что логически они будут находиться в разных сетях.

В этом случае в сеть надо добавить роутер, который должен находиться в двух подсетях сразу, и на хостах каждой из подсетей сконфигурировать этот роутер как шлюз.


### APIPA/Zeroconf

RFC 3927: описывает механизмы автоконфигурирования IPv4 адресов при помощи протокола ARP.

Естественно, раз мы будем назначать себе адрес децентрализованно, то потенциально возможны конфликты. Эти конфликты разрешаются при помощи ARP протокола.

Идея такая: если у нас не получается динамически получить себе IP-адрес (например, если DHCP-сервер не отвечает), то мы берём себе случайный адрес из диапазона 169.254.0.0/16. Прежде чем начать его использовать, надо убедиться, что этот адрес не занят. Если он не занят, то начинаем им пользоваться, а если занят, то выбираем какой-то другой.  

Посылаются пробные пакеты (ARP):

<a href="https://ibb.co/mNLYb23"><img src="https://i.ibb.co/MBYjZtm/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/8bVHfQz"><img src="https://i.ibb.co/ZSC0FbH/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/t24ZzKd"><img src="https://i.ibb.co/ykXhpP3/image.png" alt="image" border="0"></a>

## Заголовок IP протокола

<a href="https://ibb.co/7ty2fCR"><img src="https://i.ibb.co/HTgnS4x/image.png" alt="image" border="0"></a>

- **Версия**: для IPv4 значение равно 4. IPv5 нет, следующая версия -- 6. А 7 и 8 тоже занято
- **Длина заголовка**: в IPv4 заголовок может иметь переменную длину. У нас есть поле **Параметры (от 0 до 40 байт)**, которое является частью заголовка, и вообще говоря оно очень сильно опциальное и используется очень редко. Под это поле выделено 4 бита, и если мы будем считать длину заголовка в октетах, то нам этих 4 бит не хватит, поэтому мы считаем длину заголовка в **четырёхоктетных блоках** (двойных словах). Поэтому сразу видно, что минимальное число, которое може быть в этом поле (минимальное количество четырёхоктетных блоков) -- 5, поэтому заголовок должен быть выровнен по этим блокам
- **Длина пакета**: пакет может быть переменной длины. Тут отводится 16 бит, а длину пакета мы считаем в октетах, значит, максимальная длина дейтаграммы -- 65535 октет ⇒ максимальная длина данных будет 65535 минус длина заголовка.
- **Контрольная сумма** -- считается по всему заголовку сложением по модулю 2 16-разрядных слов. При подсчёте контрольной суммы по заголовку данное поле принимается равным 0.
- **Протокол** -- идентификатор протокола транспортного уровня, который будет лежать в данных
- **TTL (Time to Live) / Число переходов** -- число переходов, через которые может пройти дейтаграмма то есть число маршрутизаторов, через которые мы допускаем проход этого сообщения. Каждый маршрутизатор, через который проходит пакет, вычитает из этого поля единицу (хотя можно настроить это так, чтобы он вычитал больше, или вообще ничего не вычитал). Если маршрутизатор увидит, что после вычитания у него получается 0, то он эту дейтаграмму уничтожит, то есть дальше она не будет передана. Это сделано для борьбы с *петлями маршрутизации*: может появиться такая ситуация: <a href="https://ibb.co/khDjs1P"><img src="https://i.ibb.co/Bg6b5NY/image.png" alt="image" border="0"></a>И тогда, если надо послать пакет от хоста 1 из сети А хосту 2 из сети Е, то пакет будет путешествовать между роутерами в соответствии с их таблицами маршрутизации. Каждый роутер может быть сконфигурирован так, что в нём будет указано, какому соседу спихивать пакет в зависимости от сети назначения. И настроено может быть так, что 1 роутер пакеты для сети Е будет спихивать на 2, 2 -- на 3, а 3 -- на 1. Таким образом, получилось кольцо маршрутизации.

Естественно, раз поле TTL изменяется каждый раз при прохождении через маршрутизатор, каждый раз изменяется заголовок, поэтому необходим эффективный алгоритм модификации контрольной суммы.

<a href="https://ibb.co/S0G7vqT"><img src="https://i.ibb.co/jGsZ47K/image.png" alt="image" border="0"></a>

### Тип обслуживания

Определяет, как мы будем передавать пакет в случае, если есть альтернативные маршруты в сети в разными характеристиками.

Это поле содержит ряд флагов, описывающих приоритет данного пакета (далее помечены биты)
- 0-2 -- приоритет (precedence) данного IP-сегмента
- 3 -- требование ко времени задержки (delay) передачи IP-сегмента (0 -- нормальная, 1 -- низкая задержка)
- 4 -- требование к пропускной способности (throughput) маршрута, по которому должен отправляться IP-сегмент (0 -- низкая, 1 -- высокая)
- 5 -- требование к надёжности (reliability) передачи IP-сегмента (0 -- нормальная, 1 -- высокая)
- 6-7 -- в изначальной версии протокола зарезервировано, сейчас могут использоваться рядом служб, например, ECN (Explicit Congestion Notification) и Differentiated Services (QoS)


### Фрагментация

Размер дейтаграммы в IP-протоколе может быть достаточно большим (до 65535 октет), в то время как на канальном уровне обычно сети такой размер кадра не предоставляют. Поэтому если мы хотим послать много данных на канальном уровне, мы вынуждены разбивать дейтаграмму на сетевом уровне на порции меньшего размера. Это и есть **фрагментация**

Чтобы её реализовать, нам достаточно в заголовке пакета иметь несколько полей, которые будут отвечать за сборку дейтаграммы -- целого сообщения из фрагментов.
- **Идентификатор** -- значение, назначаемое отправителем пакета и предназначенное для определения корректной последовательности фрагментов при сборке дейтаграммы. Он определяет, к какой дейтаграмме относится фрагмент. Любая дейтаграмма, даже если она не фрагментирована, имеет этот идентификатор, который в рамках обмена между конкретными отправителем и получателем инкрементируется. При этом часто отсчёт начинается не с нулевого идентификатора, а с некоторого числа, возможно, случайного.
- **Флаги** -- содержат 3 бита флагов
	- 0 бит -- должен быть всегда равен нулю
	- 1 бит -- DF (don't fragment) определяет возможность фрагментации пакета (1 -- фрагментация запрещена)
	- 2 бит -- MF (more fragments) показывает, не является ли этот пакет последним в цепочке пакетов (1 -- ещё есть фрагменты)
- **Смещение фрагмента**: сами фрагменты, принадлежащие одной дейтаграмме, не нумеруются, а обозначаются смещениями, определяющими позицию фрагмента в потоке данных в 8-октетных блоках. Поэтому все фрагменты разделяются на блоки, кратные 8 байтам.

Фрагментация может критиковаться за сложность обработки и реализации: она требует серьёзных затрат со стороны сетевого оборудования, сложного анализа заголовков и т.д. Поэтому целесообразней выбрать блок передаваемых данных таким образом, чтобы он априори не фрагментировался. На это идут некоторые протоколы: например, TCP старается передавать данные сегментами такого размера, чтобы на сетевом уровне они не фрагментировались. Этот запрет фрагментации отражается с помощью бита DF Don't Fragment, и если вдруг всё-таки понадобится фрагментировать дейтаграмму для дальнейшей передачи, то дальше она передаваться не будет.

Фрагмент было решено задавать именно смещением, а не номером, чтобы выстраивать независимую и плоскую адресацию фрагментов, так как фрагментация может происходить неоднократно на разных роутерах через сети с разными MTU -- иначе понадобилось бы на каждом промежуточном роутере собирать дейтаграммы целиком для дальнейшего фрагментирования

#### Пример работы механизма фрагментации

Выполняется на стороне хоста
- MTU = 1500 байт
- размер дейтаграммы = 4600 байт
- передача внутри сети

Выполняется маршрутизатором
- для сети 1 MTU = 9000 байт (Jumbo Frame)
- для сети 2 MTU = 1500 байт
- размер дейтаграммы = 4600 байт
- передача из сети 1 в сеть 2

#### Пример 1: внутри сети, фрагментация разрешена

<a href="https://ibb.co/CmwvkXh"><img src="https://i.ibb.co/xX2GpcJ/image.png" alt="image" border="0"></a>

В каждом фрагменте будет 1500 октет (1480 данных + 20 заголовка), следовательно, смещение будет равно (1480 / 4) / 2 = 185


#### Пример 2: роутер, фрагментация разрешена

<a href="https://ibb.co/F0p4N92"><img src="https://i.ibb.co/pRqjGgc/image.png" alt="image" border="0"></a>

#### Пример 1: внутри сети, фрагментация запрещена

<a href="https://ibb.co/BrNBpSM"><img src="https://i.ibb.co/X38tQvR/image.png" alt="image" border="0"></a>

Сетевое API выдаст ошибку, в сети ничего не появится

#### Пример 2: роутер, фрагментация запрещена

<a href="https://ibb.co/cv195fD"><img src="https://i.ibb.co/RS9Knrz/image.png" alt="image" border="0"></a>

Роутер отбросит дейтаграмму и назад пошлёт ICMP сообщение

### Параметры

Это опциальные поля. Считается на сегодняшний день устаревшим, но сетевое оборудование часть этих опциональных полей может поддерживать, а какое-то, наоборот, считать их небезопасными и резать.

Переменная длины заголовка снижает производительность, потому что каждый следующий блок данных нужно искать по какому-то вычисляемому смещению, что мешает работать каким-то сервисам, которые анализируют пакеты на лету. 

Эти поля представляют собой некоторые блоки данных, в которых мы можем задать параметры работы протокола IP: в том числе при помощи них можно задавать маршруты прохождения через сеть (но это не работает) или диагностику (например, как в `tracert` с ICMP).

Они состоят из параметров опций и некоторых данных, их описывающие:
- Флаг Copy (1 бит)
	- 1 -- опции копируются во все фрагменты
	- 0 -- опции только в первом фрагменте
- Поле класса (2 бита)
	- 0 -- управление
	- 2 -- отладка и измерение
	- 1 и 3 зарезервированы
- Номер опции (5 бит)
- Длина опции (8 бит, может отсутствовать)
- Данные (переменной длины кратно 8 бит, могут отсутствовать)

#### Типы опций

- End of Options (class=0, number=0, length=1 octet)
	- Завершает перечень опции в заголовке, нужен для выравнивания заголовка по 4 октетам
- No Options (class=0, number=1, length=1 octet)
	- Может использоваться между опциями для выравнивания до 32-битных слов
- Security (class=0, number=2, length=11)
	- Устаревшая
- Loose Source Route (class=0, number=3, length=vary)
	- Используется при маршрутизации от источника: когда источник показывает, через какие узлы должен пройти пакет, зная конфигурацию сети. Задаёт начало маршрута
- Record Route (class=0, number=7, length=vary)
	- Позволяет записать перечень узлов, через которые прошёл пакет -- можно восстановить маршрут передачи данных
- Stream ID (class=0, number=8, length=4)
	- устаревшая
- Strict Source Route (class=0, number=9, length=vary)
	- Используется при маршрутизации от источника, жёстко задаёт весь маршрут целиком 
- Time Stamp	(class=2, number=4, length=vary)
	- Позволяет записать время прохождения (временные метки) пакета через узел, по которым можно потенциально оценить задержки при передаче данных. Этот механизм работает, но не небольших расстояниях, потому что количество меток, которые можно поставить, сильно ограничено (`ping -f`)


Механизмы Strict Source Route и Loose Source Route есть, но современные маршрутизаторы его блокируют, так как считается, что они небезопасны.

## Маршрутизация

### Задачи маршрутизации

Это поиск наилучшего пути для доставки пакета получателю. Хотя на процесс построения маршрутов в глобальных сетях, помимо оптимальности, могут влиять экономические и политические факторы (например, наличие договора между провайдерами или стоимость использования того или иного канала -- Policy Based).

Однако в обычных сетях всё просто, и маршрутизация может строиться на основе каких-то метрик, оценивающих оптимальность маршрута. Например, такой метрикой может быть количество устройств на пути от отправителя к получателю.

Эти маршруты могут задаваться **статически** (можно настроить маршрутизатор и сказать ему, чтобы пакеты туда шли через один интерфейс, а пакеты сюда через другой -- это жёсткие настройки, которые не меняются) и **динамически** (когда устройства с помощью специализированных протоколов договариваются о том, как они будут передавать данные).

Способы определения маршруты могут быть как **от источника** (source-based, strict/loose), когда источник указывает путь прохождения пакеты, так и **по получателю** (destination-based), когда источник только знает, куда спихнуть сообщение дальше. Сегодня в основном используется маршрутизация по получателю, потому что маршрутизация от источника, во-первых, небезопасна (в маршрут можно потенциально встроить какой-нибудь прослушивающий роутер), а во-вторых, каждый источник должен будет отслеживать состояние сетевой топологии для построения этого маршрута

### Таблица маршрутизации

На конечной системе она может выглядеть как-то так

<a href="https://ibb.co/9YvBDbL"><img src="https://i.ibb.co/YjWJCcM/image.png" alt="image" border="0"></a>

Таблица маршрутизации состоит из записей, которые позволяют определить, куда дальше передавать сообщение на сетевом уровне -- на какого ближайшего соседа спихивать задачу передачи данных, либо этот сосед в той же подсети и есть получатель сообщения, и тогда с ним мы будем общаться уже на канальном уровне.

Маршрутизация работает по принципу **наиболее точного маршрута**: в таблице маршрутизации мы видим несколько записей, каждая из которых определяет некоторый сетевой адрес, плюс с этим сетевым адресом связано понятие маски, при помощи которой мы будем понимать, к какой сети относится получатель пакета. 

Пусть мы хотим послать сообщение на адрес 192.168.208.14. Мы на это сообщение накладываем максимально возможную маску из тех, которые есть в таблице маршрутизации: в данном случае это 255.255.255.255. Наложив эту маску, мы получим адрес хоста (в данном случае он будет тот же самый). Такой записи в таблице маршрутизации нет, поэтому мы берём следующую маску -- это будет 255.255.255.0. Наложив эту маску, получим адрес 192.168.208.0. Такой адрес в таблице маршрутизации есть ⇒ мы нашли запись, соответствующую этому маршруту, и пакет, предназначенный этому хосту, мы будет посылать, используя маршрут, соответствующий этой записи.

Если бы мы хотели отправить пакет на 10.10.10.8, мы бы тоже постепенно накладывали разные маски (сначала 255.255.255.255, затем 255.255.255.0, потом 255.0.0.0, потом 240.0.0.0, и только потом 0.0.0.0), в коеном счёте получили бы запись 0.0.0.0, и для этого хоста мы бы использовали запись для 0.0.0.0.

Таким образом, сдвигая маску, мы будет находить этот самый наиболее точный маршрут. Посылать данные мы будем на **адрес шлюза** -- это тот самый сосед, на которого мы всё спихнём, через соответствующий **сетевой интерфейс**.

Если нам подходят несколько соседей, то мы будем выбирать более выгодного согласно **метрике**.

Первая запись -- 0.0.0.0 -- маршрут последней надежды -- с ним совпадёт любой адрес, и если до этого не нашлось более точных маршрутов, будет использоваться именно он. Эта спасительная запись называется **маршрутом по умолчанию (default gateway)**, если такой записи не найдётся, то в сеть ничего послано не будет. 

При этом **шлюз должен находиться в том же сетевом диапазоне, что и интерфейс, с которого мы посылаем пакеты** -- он должен быть локально доступен.

Вторая запись -- 127.0.0.0 с маской 255.0.0.0 -- это localhost, и весь трафик остаётся внутри машины.

Третья запись -- 192.168.208.0/24 -- локальная сеть: тут как раз адреса шлюза и интерфейса совпадают, следовательно, данные будут передаваться через локальный интерфейс напрямую получателю, и никакой маршрутизатор использовать не надо -- взаимодействие возможно на локальном уровне.

Четвёртая запись -- 192.168.190/32 со шлюзом и интерфейсом 127.0.0.1 -- это наш собственный IP: если мы посылаем пакет на наш IP-адрес, он должен оставаться внутри машины и в сеть не попадать. Это самый точный маршрут -- маршрут до конкретного хоста.

Пятая запись -- 192.168.208.255/32 -- это локальное широковещание, которое работает в локальном сегменте сети без маршрутизаторов (шлюз и интерфейс -- наши IP-адреса). Аналогично и последняя запись -- 255.255.255.255/32

Предпоследняя строчка -- 224.0.0.0/4 -- мультикаст, и здесь весь мультикаст трафик отправляется в локальную сеть (интерфейс и шлюз -- собственные IP)

### Алгоритм работы маршрутизатора

- Адрес назначения соответствует локально доступной сети?
	- посылаем пакет через локальный интерфейс
- Поиск записи в таблице маршрутизации соответствующей сети назначения?
	- посылаем пакет соответствующему маршрутизатору для дальнейшей пересылки
- Есть маршрут по умолчанию?
	- посылаем пакет соответствующему маршрутизатору для дальнейшей пересылки
- Посылаем отправителю сообщение об отсутствии маршрута (ICMP: Destination host unreachable)

### Поиск записи в таблице маршрутизации соответствующей сети назначения

Принцип наиболее точного маршрута:
- берём наибольшую маску
- накладываем на адрес назначения и сравниваем с записями с таблице маршрутизации
	- совпадение -- успех
	- несовпадение -- сдвигаем маску до следующей максимальной и повторяем данный пункт

Хотя в реальности роутеры устроены сложнее и используют более хитрые структурки данных

### Примеры статической маршрутизации

У нас может быть два подхода к реализации пересылки данных на маршрутизаторах:
- с использованием маршрута по умолчанию
- без использования маршрута по умолчанию

#### Без использования маршрута по умолчанию

<a href="https://ibb.co/JjJPK9M"><img src="https://i.ibb.co/hFzvySt/image.png" alt="image" border="0"></a>

Понятно, что у каждой сети есть свой адрес и у каждого маршрутизатора тоже есть соответствующие IP-адреса в каждой из сетей.

<a href="https://ibb.co/s9JCxy1"><img src="https://i.ibb.co/QvjkSrH/image.png" alt="image" border="0"></a>

Наша цель -- сделать так, чтобы все три хоста h1-h3 могли взаимодействовать друг с другом.

Если роутер, например, R1, уже и так соединяет две сети и находится в них сразу, то предполагается, что он уже и так умеет пересылать пакеты между сетями N1 и N2. То есть как только мы включим службу маршрутизации на R1, то если на него из сети N1 придёт пакетик на сеть N2, то он это поймёт и его в сетку N2 перекинет. Понятно, что это делается на основе каких-то записей в таблице маршрутизации, задействующей локальные интерфейсы роутера, но для того, чтобы это заработало, нам руками делать почти ничего не нужно. Поэтому тут никаких особых связей добавлять в таблицу маршрутизации не нужно.

В то же время маршрутизатор R1 ничего не знает про сети N3-N5. Поэтому если из сети N1 на него придёт пакет, предназначенный для сетей N3-N5, то маршрутизатор не будет знать, что с ним делать, и пошлёт ICMP Destination host unreachable. Поэтому надо научить маршрутизатор, поместив в таблицу маршрутизации соответствующие записи. Добавим записи, которые мы должны внести в таблицу маршрутизации:

```
сетевой_адрес	маска	шлюз	сетевой_интерфейс	метрика
N3						N2.2	N2.1				2 (например)
N5						N2.4	N2.1				2
N4						N2.2	N2.1				3
```

Теперь с сетями N3 и N5 всё хорошо, потому что маршрутизаторы R2 и R4, на которые будут приходить пакеты, предназначенные этим сетям соответственно, смогут уже сами доставить их до нужного места. Однако сеть N4 по-прежнему будет недоступна из-за того, что на пути до неё стоит маршрутизатор R2, который про сеть N4 тоже ничего не знает. Поэтому записи только на одном маршрутизаторе для коммуникации между сетями N1 и N4 недостаточно.

Другая ситуация, если мы хотим получить ответ из сетей N3-N5. Обратно пакеты уже не дойдут, потому что тот же хост h3 из сети N5 не знает, куда отправлять пакеты для N1. Поэтому правильным было бы сконфигурировать статические маршруты на всех остальных маршрутизаторах. Проделаем это для R2

```
сетевой_адрес	маска	шлюз	сетевой_интерфейс	метрика
N1						N2.1	N2.2				2
N5						N2.4	N2.2				2
N4						N3.3	N3.2				2
```

И для R3

```
сетевой_адрес	маска	шлюз	сетевой_интерфейс	метрика
N1						N3.2	N3.3				3
N2						N3.2	N3.3				2
N5						N3.2	N3.3				3
```

Здесь мы не использовали маршруты по умолчанию.

#### С использованием маршрута по умолчанию

Маршрут по умолчанию удобно задать для маршрутизаторов R1, R3 и R4, потому что они взаимодействуют с нелокальными сетями через один и тот же интерфейс. При этом самая хорошая ситуация в R3: там мы можем заменить вообще все записи в таблице маршрутизации маршрутом по умолчанию

```
сетевой_адрес	маска	шлюз	сетевой_интерфейс	метрика
0.0.0.0			0.0.0.0	N3.2	N3.3				10		(default gateway)
```

В R1 мы большую часть записей шлём через R2.2:

```
сетевой_адрес	маска	шлюз	сетевой_интерфейс	метрика
0.0.0.0			0.0.0.0	N2.2	N2.1				10
N5						N2.4	N2.1				2
```

## Управление адресным пространством сети

### Сабнеттинг
Разделение доступного сетевого диапазона путём сдвига маски сети.

<a href="https://ibb.co/gWPd22N"><img src="https://i.ibb.co/LgJrFFm/image.png" alt="image" border="0"></a>

При этом надо помнить, что маршрутизаторы, соединяющие сети -- это тоже хосты внутри сетей, которые занимают адрес.

### Супернеттинг

Объединение доступных сетевых диапазонов путём сдвига маски сети для получения общего сетевого диапазона большего размера. Например, так можно избавиться от маршрутизаторов

<a href="https://ibb.co/ctsbsn0"><img src="https://i.ibb.co/L6sQs7m/image.png" alt="image" border="0"></a>

Бывает полезно ещё и для сжатия таблиц маршрутизации.

# ICMPv4

## Назначение ICMP

Создан для совместного использования с IP, в первую очередь для передачи сообщений об ошибочных ситуациях при доставке IP-дейтаграмм
- только для первого фрагмента в случае фрагментации дейтаграммы
- не передаются ICMP-сообщения об ошибках доставки ICMP-сообщений

ICMP  создан для использования совместно с IP и формально не является протоколом транспортного уровня, тем не менее, он инкапсулируется внутрь IP-протокола. Он является инфраструктурным протоколом сетевого уровня.

При этом то устройство, которое дальше не смогло доставить IP-дейтаграмму, в ответ посылает ICMP-сообщение по двум правилам: во-первых, мы не спамим ICMP-сообщениями для каждого доступного фрагмента, то есть для того, у которого смещение 0. Кроме того, не передаются ICMP сообщения об ошибках доставки ICMP-сообщений, чтобы не множить их до бесконечности. Однако если ICMP-запрос представляет собой эхо, то ошибка о доставке будет отправлена, потому что эхо-запрос -- это не сообщение об ошибке доставки.

## Формат ICMP-сообщения

Инкапсулирован в IP. Номер протокола = 1.

Заголовок
- Тип ICMP сообщения (1 октет)
- Код ICMP сообщения (1 октет) (подтип)
- Контрольная сумма (2 октета), алгоритм аналогичен IP
- Данные (зависят от типа сообщения)

## Основные типы сообщений

### Destination Unreachable

- Тип 3
- Код
	- 0 = net unreachable
	- 1 = host unreachable
	- 2 = protocol unreachable: хост разобрал IP-дейтаграмму, но не понимает, что там внутри и не может её разобрать
	- 3 = port unreachable
	- 4 = fragmentation needed and DF set
	- 5 = source route failed: когда мы используем маршрутизацию от источника, в современных сетях это мы не увидим
- Данные
	- неиспользуемые 32 бита для выравнивания
	- IP-заголовок + 8 октет не доставленной дейтаграммы. Это нужно чтобы по этой части мы поняли, что конкретно было не доставлено. По заголовку можно понять, кому мы доставляли пакет, а по 8 октетам дейтаграммы можно увидеть кусочек заголовка транспортного уровня, чтобы понять, например, с каким портом не удалось провзаимодействовать: в 8 октетов поти поместится UDP-заголовок.

### Time Exceeded
- Тип 11
- Код
	- 0 -- time to live exceeded in transit
	- 1 -- fragment reassembly time exceeded: когда сообщение было фрагментировано, но мы не получили все фрагменты. Перед тем, как отправить дейтаграмму, нужно собрать все её фрагменты. Если какой-то фрагмент получен не был, то через какой-то таймаут мы перестаём его ждать, уничтожаем все фрагменты и отправляем соответствующее ICMP сообщение. Таким образом, если проблема возникла с первым фрагментом, то об этом сообщит маршрутизатор, а если с каким-то из других, то об этом сообщит конечная система
- Данные
	- 32 неиспользуемых бит
	- IP-заголовок + 8 октет не доставленной дейтаграммы

### Redirect

Посылает маршрутизатор, если он знает более оптимальный маршрут через ту же подсеть

- Тип 5
- Код
	- 0 = redirect datagrams for the Network
	- 1 = redirect datagrams for the Host
	- 2 = redirect datagrams for the Type of service and Network
	- 3 = redirect datagrams for the Type of Service and Host
- Данные
	- IP-адрес шлюза, через который предпочтительней доставлять дейтаграммы
	- IP-заголовок + 8 октет не доставленной дейтаграммы

По идее, получив redirect, хост должен был изменить записи в совей таблице маршрутизации в динамике. Однако этот механизм можно использовать для атак: прослушав какое-то сообщение в сети, можно на него послать redirect, и в результате можно либо перенаправить все сообщения в условную пустоту, либо на какое-то устройство, которое будет прослушивать весь трафик. Поэтому такой тип сообщения считается небезопасным и блокируется фаерволлом. Поэтому сегодня хосты либо игнорируют эти сообщения, либо реагируют на очень небольшое $\Delta t$ в районне секунды, на короткий промежуток времени внося изменения в таблицу маршрутизации, а потом быстро выкидывая эту запись.

### Echo or Echo Reply
- Тип
	- 8 для запроса
	- 0 для ответа на запрос
- Код 0
- Данные
	- Идентификатор
		- Используется для идентификации соответствия запросов ответам: формально на одном хосте может быть запущено несколько экземпляров утилиты `ping`
		- аналог порта в TCP и UDP
	- Номер последовательности
		- должен увеличиваться для каждого следующего запроса, номер пакета в рамках сеанса
	- Данные
		- произвольная последовательность октетов определяемая отправителем запроса
		- должна быть возвращена отправителю при ответе

# UDP

Самый примитивный и простой протокол транспортного уровня. Один из старейших используемых протоколов

## Задачи и ограничения протокола

- Дейтаграммный режим передачи в сетях с пакетной передачей данных
- подразумевает использование протокола IP в качестве протокола низлежащего уровня
- позволяет пересылать данные между приложениями с минимальными затратами на транспортные протоколы
- ориентирован на транзакционную модель взаимодействия
- не гарантируется
	- доставка пакетов
	- защита от дубликатов
	- борьба с перегрузками

## Формат пакета

<a href="https://ibb.co/JRZz179"><img src="https://i.ibb.co/LzKCFt3/image.png" alt="image" border="0"></a>



### Номера портов

Номера портов (совместно с номером протокола) определяют передающий данные процесс на локальной системе (сетевом адресе) и принимающий процесс на удаленной системе (сетевом адресе), определяют протокол более высокого уровня, могут использоваться для целей фильтрации трафика
- Назначаемые
	- системные (0 - 1023)
	- пользовательские (1024 - 49151)
- Динамические (49152 - 65535)

Назначаемые порты делятся на
- назначенные (assigned): закреплены за определенными широкораспространенными сервисами (рекомендательно)
- неназначенные (unassigned): доступны для назначения пользовательским процессам
- зарезервированные (reserved):
	- 0, 1023, 1024 etc то есть порты на границах диапазонов

### Длина

Общий размер дейтаграммы в байтах (заголовок + пользовательские данные)
- минимальное значение 8
- максимальный размер пользовательских данных 2^16^ - 8 = 65527, на практике меньше (65507) из-за IPv4


### Контрольная сумма
- вычисляется по псевдозаголовку, заголовку UDP и пользовательским данным
- алгоритм: последовательность байт воспринимается как последовательность 16-битных чисел (при необходимости дополняются 0 до четного количества)
- суммирование в обратных кодах (с переносом в младшие разряды)
- взятие обратного кода (дополнение всех бит до единицы)
- если равна 0, то считается, что контрольна сумма не вычислялась


### Псевдозаголовок

<a href="https://ibb.co/5Tv2TjR"><img src="https://i.ibb.co/ZdKNdgM/image.png" alt="image" border="0"></a>

Он берёт информацию с сетевого уровня, то есть с уровня IP. 

Номер протокола (поле protocol) для UDP всегда должен быть равен 17.

## Развитие UDP

- Предлагаемый стандарт UDP-Lite
- UDP для IPv6
	- Основное отличие -- изменение псевдозаголовка, потому что поменялись адреса

## UDP-Lite

У нас есть приложения, которым важно получить данные, даже если они немного искажены, то есть где на уровне кодека может быть реализован механизм обнаружения ошибок. Это видеотрансляции, IP-телефония и так далее. В таких случаях важно получить хоть что-то, чем не получить ничего.

Предложено разбить пакет на критичные и некритичные сектора. Если ошибка будет в критических данных, то это плохо, а если в некритических -- то это не страшно. В таком случае контрольная сумма может вычисляться только по части UDP-заголовка и критических данных -- в критических данных может быть часть, формирующая заголовок прикладного уровня. Всё остальное вычисляться не будет.

### Формат заголовка

<a href="https://ibb.co/q0gLzmv"><img src="https://i.ibb.co/0B9pkYx/image.png" alt="image" border="0"></a>

Поле, которое раньше называлось длиной и было избыточным, потому что та же самая длина есть на уровне IPv4, теперь интерпретируется как размер того блока, который покрывается контрольной суммой.

### Покрытие контрольной суммой
- соответствующее поле в заголовке протокола
- определяет сколько октетов защищаются контрольной суммой
- минимальное значение 8 (длина заголовка)
- алгоритм расчёта контрольной суммы такой же, как и в UDP




### Дополнительно
- Номер протокола 136
- Потенциально может использоваться совместно с UDP, так как совместим на уровне заголовка (одно поле интерпретируется по-другому)
- поддержка нативно используется уже в довольно древних версиях linux

## UDP Usage Guidelines

RFC 8085
- Рекомендации по использованию UDP для разработчиков сетевых приложений
- Зависят от типа приложения:
	- Bulk-transfer applications -- приложения, которые посылают много данных (больше нескольких (few) дейтаграмм за RTT)
	- Low data-volume applications -- приложения, которые посылают мало данных (несколько дейтаграмм за RTT, в среднем одна)

### Рекомендации
- Борьба с перегрузками (congestion control)
	- Крайне рекомендуется (SHOULD) реализация на прикладном уровне
- Борьба с фрагментацией
	- Использование механизмов вычисления MTU
- Обеспечение надёжности доставки
	- На прикладном уровне
- Контрольные суммы, если приложение надо как-то серьёзно защищать от ошибок в данных -- контрольные суммы в UDP очень слабые, так что это надо тоже реализовывать на прикладном уровне
- Использование нескольких портов в рамках одного приложения -- лучше использовать для одной коммуникации единственное соединение, только если нет веских причин так не делать. Это снизит  нагрузку на коммуникационное оборудование
- Реакции на ICMP-сообщения
- ...

# Протоколы динамической маршрутизации в IP-сетях


## Задача

Построение, отслеживание и перестроение маршрутных таблиц без участия администратора после начального конфигурирования маршрутизирующего устройства

## Классификация
- по масштабу
	- внутридоменные (IGP: Interior Gateway Protocol) в рамках одной организации, связывают сети организации друг с другом
		- RIP
		- OSPF
	- внешние (EGP: Exterior Gateway Protocol) в глобальном масштабе
		- EGP
		- BGPv4 (Border Gateway Protocol)
- По механизмам построения маршрутов
	- вектор расстояний (distance vector) в виде {назначение: метрика} (RIP)
	- состояние каналов (link state protocol) позволяют восстановить графовое представление сети (OSPF)
	- на базе политик и правил

## RIP: Routing Information Protocol


RIP обладает тем же свойством, что и STP: он позволяет восстанавливать сетевую инфраструктуру после изменения, но делает это очень долго. Кроме этого, с ним связан ряд ограничений: например, он не может использоваться в достаточно больших сетях, и там надо применять более хитрые протоколы типа OSPF.

### Достоинства RIPv2 (с криптографической аутентификацией)
- простота конфигурирования и управления сетевой инфраструктурой в небольших сетях
- из-за этого в прошлом получил более широкое распространение по сравнению с OSPF и другими IGP протоколами
	- в настоящее время не рекомендуется для использования некоторыми производителями сетевого оборудования
- сравнительно небольшие затраты пропускной способности сети в небольших сетях
- возможности взаимной аутентификации маршрутизаторов (RFC 4822)

### Ограничения RIPv1 по сравнению с RIPv2
- нет поддержки безклассовых сетей (нет поля маски сети при распространении маршрутов)
- нет информации о следующем узле в маршруте
- нет поддержки понятия автономной системы (не решаются задачи взаимодействия между IGP/EGP протоколами)
- нет поддержки использования групповых адресов для обмена маршрутной информацией
- нет защищённых механизмов взаимной аутентификации устройств

### Ограничения RIPv2

- является протоколом внутридоменной маршрутизации ⇒ в глобальных сетях мы его использовать не можем, потому что он использует сети с небольшим (15) диаметром, он ориентируется на количество пересылок через маршрутизаторы: 16 пересылок будет считаться как недостижимость, хотя 16 это довольно много
- базовая стоимость интерфейса = 1 ⇒ не видит разницы между гигабитным и килобитным интерфейсом, можно крутить стоимости, но если стоимость будет равна 4, то макс диаметр сети будет сужаться
- использует подход "счет до бесконечности" для разрешения ряда нештатных ситуаций, что может повлиять на время их разрешения ⇒ это работает долго
- использование фиксированных метрик (стоимостей) маршрутов, то есть не учитываются динамические параметры сетевой инфраструктуры

### Алгоритм "вектор расстояний"
- используется в сетях с 1969 года
- впервые предложен Фордом и Фалкерсоном в 1962
- базируется на уравнения Беллмана, предложенных в 1957 году (принцип динамического программирования)
- наиболее широко известен как алгоритм Беллмана-Форда

#### Основные характеристики
- маршруты строятся посредством обмена данными только между соседними устройствами
- чем меньше стоимость маршрута, тем он считается более выгодным
- стоимость маршрута является суммой его компонент
- при наличии нескольких маршрутов выбирается минимальный из них
- в классике жанра он работает по уравнениям по матрице смежности всей графовой структуры, но в реальных сетях работает в распределенном виде

Маршрутизаторы изолированно друг от друга решают задачу построения своих маршрутных таблиц, при этом обмениваясь векторами расстояний -- грубо говоря, своими маршрутными таблицами, представлениями о сети. Однако сама структура связей сетей маршрутизатором неизвестна, известны только метрики


#### Уравнения Беллмана

Пусть
- $D(i, j)$ --  метрика лучшего маршрута между узлами $i$ и $j$
- $d(i, j)$ -- метрика **маршрута** между соседними узлами (формально равно бесконечности, если узлы не соседние)
- $k$ -- узлы, соседние с $i$
- метрики неотрицательные

$$D(i, i) = 0\quad\forall i\\D(i, j)=\min_k\{d(i, k)+D(k, j)\}\quad\forall i, j: i\neq j$$


<a href="https://ibb.co/DzPzpVM"><img src="https://i.ibb.co/2W0WNnM/image.png" alt="image" border="0"></a>

### Задачи маршрутизатора

- поддержание таблицы со всеми доступными маршрутами для данной системы, состоящий из адреса сети назначений и следующего маршрутизатора
- периодически рассылать информацию о своих маршрутах соседним узлам
- при получении сообщения от соседних маршрутизаторов пересчитать стоимости своих маршрутов для каждой из сетей в своей таблице
	-  если пришел маршрут в ранее неизвестную сеть, то добавить его в свою таблицу
	- если пришёл маршрут в известную сеть, но с меньшей метрикой, то обновить маршрутную запись на новую
	- если пришёл маршрут от сети с большей метрикой от соседа, от которого данный маршрут был изучен ранее, то обновить маршрутную запись, **даже если метрика превышает прошлое значение**

Также соседний маршрутизатор может прислать маршрут с метрикой бесконечность -- это значит, что через него сеть стала недоступна либо он не хочет пересылать данные в эту сеть через этот интерфейс.


### Старение маршрутной информации
 По умолчанию
 - маршрутизаторы рассылают сообщения раз в 30 секунд +- лаг в 5 секунд, чтобы не было перегрузки сети, если маршрутизаторы все включаются одновременно
 - если сообщение от соседнего маршрутизатора, подтверждающего маршрут, не было получено в течение 180 секунд, то маршрут считается некорректным, и он может быть изучен от другого соседа с большей метрикой + через 120 секунд мы про него забываем (сборка мусора) и после этого про него даже не оповещаем соседям
 - соседние маршрутизаторы оповещаются о недоступности маршрута сообщением со стоимость для данного маршрута превышающей максимальную (бесконечность)

### Счёт до бесконечности

<a href="https://ibb.co/Lh9cKR6"><img src="https://i.ibb.co/1JRPcQK/image.png" alt="image" border="0"></a>
 
 Есть некоторая целевая сеть, в которую мы хотим попасть и которая доступна через маршрутизатор D. При этом в сети есть и другие маршрутизаторы A, B, C, а стоимость пересылки между ними составляет 1 за исключением прямого маршрута C -- D, который стоит 10.

D непосредственно подсоединён к сети, у него метрика 1.

С точки зрения B, изучив все маршруты, он понимает, что сообщения в целевую сеть надо посылать через D с метрикой 2.

Аналогичным образом C и A понимают, что надо пересылать через B с метрикой 3.

Теперь мы вносим аварийную ситуацию: по каким-то причинам линк между B и D становится недоступным. Это замечает B и отмечает недоступность целевой сети (unreach). В то же время C и A говорят, что через них доступна целевая сеть с метрикой 4. Поэтому B в следующий момент времени, когда получит анонс от A и C, получает от них сообщение, что на самом деле целевая сеть доступна с метрикой 4 и благополучно этот маршрут изучит. При этом понятно, что этот маршрут на самом деле с точки зрения С был через В, и по сути С вернул этот маршрут В, добавив к нему +1. В результате локально тут получилось кольцо маршрутизации: С для целевой сети ссылается на В, а В для целевой сети ссылается на С. И хотя В анонсирует, что маршрут от него до целевой сети недоступен, С всё ещё получит анонс от А, с которого целевая сеть, по его мнению, доступна через сам С. Получилось кольцо маршрутизации.

На следующей итерации анонсирования информации из-за закольцовывания маршрутизации все метрики увеличатся на 1, и так далее до того момента времени, пока мы не перешагнём через стоимость дорогого маршрута C-D. И только когда этот маршрут станет самым выгодным, мы переключимся на него, и связь с целевой сетью восстановится только в момент времени x+1.

Таким образом, походит существенное количество итераций, пока сетевая инфраструктура не восстановит маршруты. Пр этом может случиться так, что мы досчитаем до бесконечности -- и тогда маршруты будут инвалидированы.


### Разделение горизонта (Split horizon)

Проблема счёта до бесконечности была в том, что мы перезаписывали маршруты от соседей, которые ссылались на нас самих: когда мы видим анонсирование маршрута, мы не знаем, на кого дальше сосед хочет спихнуть трафик, и не можем там увидеть себя: сосед просто говорит, что можно слать через него за какую-то стоимость, а что там дальше, нам не сообщает.

Решение: маршруты, изученные от соседа, назад соседу не сообщаются, то есть обратно через этот интерфейс маршрут анонсироваться не будет. Поэтому через время таймаута сосед поймёт, что маршрут больше никто ему не говорит, и либо изучит более выгодный маршрут, либо поймёт, что сеть стала недоступной.

Поэтому теперь маршрутная таблица будет обновляться по таймауту.

Ещё один плюс -- количество данных, которыми будут обмениваться соседние маршрутизаторы, значительно уменьшится: теперь они сообщают не весь вектор расстояний, а только ту его часть, которые изучили не от данного соседа.


### Poisoning reverse (Отравление отправителя/Обратное давление)

- используется совместно с разделением горизонта
- соседу, от которого были изучены маршруты, они сообщаются с метрикой, превышающей максимальную
	- \+: маршруты обновляются сразу же, не дожидаясь таймаута
	- \-: увеличивается размер пересылаемой информации: мы сообщаем весь вектор, но в нём появляются записи с бесконечностью

### Ограничения разделения горизонта
- спасают только от колец маршрутизации между соседними узлами
- не спасают от транзитивных колец: возможны топологии, когда несколько маршрутизаторов образуют кольцо маршрутизации
	- A -> B, B -> C, C -> A


### Обновления по событиям (trigger update)
- маршрутизатор посылает обновления о маршрутах сразу же при изменениях своей таблицы маршрутизации, а не через время периодической рассылки (но с ними тоже связан таймер задержки, в котором мы ждём до оповещения соседа о произошедшем изменении чтобы не переполнить сетку и не реагировать на каждый чих)
- позволяют сократить время схождения сети
	- в ряде случаев полностью избавиться от счета до бесконечности
	- не являются панацеей, возможны плохие ситуации из-за задержек передачи и потери пакетов ==> кольца всё равно могут возникать

### Сообщения RIP протокола

В качестве транспорта используется UDP, с точки зерения стека -- прикладной протокол, по сути -- сетевой
- порт 520 для получателя и отправителя (для отправителя может отличаться)
- широковещательные (типичный режим работы, на хостах мб реаизон RIP Listener и модифицировать свои маршрутные таблицы, хоть сегодня это почти не используется), одноадресные (NBMA: non broadcast multiple access сети, где широковещания нет, но абонентов много, а также ответы на запросы, пусть даже и широковещательные) и групповые сообщения (RIPv2 -- 224.0.0.9) для адресации получателя, и его будут получать только RIPv2 маршрутизаторы


### Формат RIP пакета

<a href="https://ibb.co/80Wb3Q0"><img src="https://i.ibb.co/f2h9RT2/image.png" alt="image" border="0"></a>

### Поля заголовка
- Команда
	- 1 - RIP запрос (очень редко, когда маршрутизатор включается -- насильное опрашивание соседей)
	- 2 -- RIP-ответ (при периодическом обновлении)


#### Формат записи для RIPv1:

<a href="https://ibb.co/nz9VQb3"><img src="https://i.ibb.co/WgZdB6D/image.png" alt="image" border="0"></a>

address family identifirer -- IPv4

в RIPv1 нигде не передаётся маска.

### Взаимодействие запрос-ответ

- как правило только при включении системы
	 -	 широковещательная рассылка запроса
	 -	адресный ответ от соседей
 -	должна содержать маршруты, о которых требуется информация
 -	либо запрос на получение полной таблицы маршрутизации (1 запись: сеть с адресом 0, метрика 16)


### Расширения RIPv2

<a href="https://ibb.co/kq6nJnt"><img src="https://i.ibb.co/KVzZDZJ/image.png" alt="image" border="0"></a>

Основное: появилась маска. Теперь мы можем его использовать в сетях в безклассовой адресацией.

Также появился тег маршрута, и этим тегом мы можем помечать маршруты, например, для определения, из какого протокола маршрутизации был изучен маршрут, если в системе используется сразу несколько таких протоколов.

Next Hop -- аналог ICMP Redirect, когда в сегменте сети маршрутизатор знает более выгодный маршрут. Это может быть полезно, если тот выгодный маршрутизатор не хочет использовать RIP, поэтому штатными средствами про него мы не узнаем.

### Дополнительные поля в маршрутной записи
- Семейство адресов
	-  0x0002 -- IP
	- 0xFFFF -- аутентификация
		- Передаётся в качестве **первой** маршрутной записи
		- Plain Text -- кодовое слово, чтобы случайно включённые маршрутизаторы не рушили сетку, ни от чего не защищает
		- HMAC
	- Тег маршрута
		- Оповещение об источнике маршрута (внешние/внутренние)


### Аутентификация

<a href="https://ibb.co/Lx9t3Rx"><img src="https://i.ibb.co/QPYN4QP/image.png" alt="image" border="0"></a>

### Поля аутентификационной записи
Тип
- 2 -- пароль в открытом виде
	- только для ошибок в конфигурации
	- не даёт защиты от целенаправленной атаки на сситему
	- единственный тип в стандарте 1998 года
- 3 -- криптографическая хеш-функция (~ 2007)
	-  MD5 
	- HMAC-SHA1

### Криптографическая аутентификация

<a href="https://ibb.co/kysT8tK"><img src="https://i.ibb.co/3s9bNn1/image.png" alt="image" border="0"></a>

Вопрос: зачем нужно поле Sequence Number? Затем, чтобы злоумышленники не перехватывали старые пакеты и не пересылали их спустя некоторое время, когда эти пакеты уже будут неактуальными, что обрушит сеть. Это так называемые атаки повторами

Если реализован стек IPSec, то эти механизмы уже являются избыточными. 

### Enhanced Interior Gateway Routing Protocol

Цисковский протокол, который тоже использует идею вектора расстояний.

<a href="https://ibb.co/NYhrrKV"><img src="https://i.ibb.co/9YXhhW8/image.png" alt="image" border="0"></a>


## OSPF: Open Shortest Path First 

<a href="https://imgbb.com/"><img src="https://i.ibb.co/Mcb2KyK/image.png" alt="image" border="0"></a>

### Особенности

- Каждый маршрутизатор имеет полное представление о сети в виде графа (но это неточно: всю сеть в очень большой сети на каждом маршрутизаторе представлять не хочется ==> сеть разбивается на регионы)
- построение маршрута до других сетей, используя алгоритм Дейкстры
- быстрая реакция на изменение топологии сети с минимальными накладными расходами с точки зрения количества служебного трафика
- возможность балансировки нагрузки в сети
- возможность взаимной аутентификации маршрутизаторов
- возможность импорта внешних маршрутов (BGP, статические и т.п.)
- устройства обмениваются состояниями каналов

### Некоторые важные понятия

**Autonomous System** -- группа маршрутизаторов, обменивающаяся маршрутной информацией с использованием одного общего протокола

**Neighbouring routers** -- устройства, имеющие интерфейсы в одной сети

**Adjacency** -- вид отношения, формируемый между соседними маршрутизаторами (neighbouring routers) с целью обмена маршрутной информацией. Не все пары соседних устройств образуют данное отношение.

Сети в рамках АС делятся на подмножества -- области (areas), которым даются идентификаторы из 4 октетов. Плюс есть обязательная магистральная область blackbone с id 0.0.0.0. Области сделаны для того, чтобы сократить объём информации, передаваемый внутри гигантской автономной системы.

Маршрутизаторы между областями особые, называются граничными -- area border routers ABR. Он не может связывать две не магистральные области, это правило по умолчанию. Эти маршрутизаторы ограничивают распространение о графе сетей.

Для внешних сетей есть ASBR -- AS border router, которые связывают нашу автономную систему с другими сетями -- наш домен маршрутизации с другим обменом маршрутизации, через них может идти импорт маршрутов

<a href="https://ibb.co/mzPMhcC"><img src="https://i.ibb.co/VBkPMqW/image.png" alt="image" border="0"></a>

Каждый маршрутизатор внутри домена маршрутизации -- автономной системы, тоже должен иметь некоторый уникальный идентификатор, который часто выбирается как младший или старший IP-адрес одного из интерфейсов этого маршрутизатора.


Для того, чтобы устройства смогли наладить обмен информацией между собой, они должны друг друга видеть ⇒ появляется понятие соседних маршрутизаторов, которые находятся в одной сети. Информацию о соседних маршрутизаторах можно узнать, получи соответствующий OSPF-пакетик, который рассылается ими на специальный мультикаст адрес. С некоторыми из соседних маршрутизаторов будут устанавливаться более тесные отношения, и именно с ними и будет налажен обмен данными.

### Части протокола OSPF

- **Flooding** -- часть OSPF протокола, при помощи которой происходит распространение и синхронизация базы данных (link-state-database) между маршрутизаторами ("затопление" или "растекание" информации по сети)
- **Hello Protocol** -- часть OSPF протокола для установления и поддержки соседских отношений. В широковещательных сетях также применяется для обнаружения соседних маршрутизаторов.

### Основные типы сетей OSPF
- Точка-точка (point to point) -- непосредственное соединение двух устройств, дуплексное или полудуплексное
- Широковещательные (например Ethernet)
- Нешироковещательные с множественным доступом (NBMA), например X.25
- Точка-много точек (Point to multipoint), например FrameRelay
- Виртуальные


В тех сетях, где нет широковещания, но есть множественный доступ к сетевой инфраструктуре, не могут рассылаться мультикаст сообщения. Поэтому в таком случае при настройке соединения между маршрутизаторами надо будет явно прописать, кто будет являться соседом. В этом случае обмен данными будет уже адресным.

В широковещательных сетях при взаимодействии маршрутизаторов друг с другом им назначаются особые роли для экономии трафика, чтобы обмен данными между ними был более предсказуемым.

### Link-State Database

- **Соединение** (Link) -- интерфейс маршрутизатора
- **Состояние соединения** -- описание интерфейса и его отношения с соседними маршрутизаторами
	- IP адрес
	- Маска
	- Тип сети
	- Соседние устройства
	- ...
- **LSDB (Link State Database)** -- набор записей о состоянии соединений в сети. Фактически это графовое представление о сети, задаёт её топологию

Важно, что представление LSDB задаёт ориентированный граф. Узлами в этом графе могут быть как маршрутизаторы, так и сети.

<a href="https://ibb.co/BgQC1SY"><img src="https://i.ibb.co/9q1rMCd/image.png" alt="image" border="0"></a>

При этом есть понятие тупиковой сети (stub network), которая находится только за одним маршрутизатором и дальше ни с кем не соединяет. А промежуточные сети (networks) воспринимаются как полноценные участники графа.

У каждого ребра в этом ориентированном графе есть какие-то стоимости. Рёбра R -> N всегда имеют вес больше нуля, а N -> R всегда принимаются за 0.

Стандарт определяет структуру данных для хранения этого графа -- матрицу смежности.

### Графовое представление сети
- LSDB позволяет представить сеть в виде взвешенного ориентированного графа в виде матрицы смежности + списков соседства
- Узлы графа -- маршрутизаторы и сети
- Дуги -- связи между маршрутизаторами (точка-точка) и между сетями и маршрутизаторами (стоимость 0)
- Для каждого маршрутизатора и сети строится отдельная матрица смежности

<a href="https://ibb.co/8Bxp30q"><img src="https://i.ibb.co/N3NPhs5/image.png" alt="image" border="0"></a>

Сети, например, N2 являются тупиковыми --  в них нет других маршрутизаторов; есть полноценные сети типа N3, в которых присутствуют несколько маршрутизирующих устройств; возможны конфигурации, когда маршрутизаторы соединением точка-точка соединены непосредственно между собой (RT3 - RT6), а также хитрые ситуации, когда, например, хост подключается непосредственно к маршрутизатору (H1 -> RT12).

Это графовое представление описывается следующей матрицей смежности:

<a href="https://ibb.co/tp9nSHL"><img src="https://i.ibb.co/s9ZchgW/image.png" alt="image" border="0"></a>

В направлении FROM (по горизонтали) присутствуют все маршрутизаторы + сети, в которых есть несколько маршрутизирующих устройств. В направлении TO -- вообще все сети и все маршрутизаторы + запись для хоста H1.

Здесь видно, что дуги, исходящие из сетей, имеют нулевую стоимость. Все остальные метрики назначаются, исходя из величины, обратно пропорциональной пропускной способности сети, но эту метрику можно выбирать и исходя из каких-то других соображений

### Индивидуальные матрицы смежности для маршрутизаторов и сетей

<a href="https://ibb.co/pZnrfd3"><img src="https://i.ibb.co/k0M64Xh/image.png" alt="image" border="0"></a>

Кроме глобальной матрицы всей сети, на уровне соответствующего маршрутизатора поддерживаются локальные матрицы связей маршрутизаторов и соседних сетей (сама сеть поддерживать такую структуру данных не может, поэтому за сеть это делает маршрутизатор).

При обмене блоками данных -- LSA (Link State Advertisement) видно, какие состояния будут экспортироваться маршрутизатором от себя, а какие -- от имени подключенной к нему сети.

Имея такое матричное представление, можно запустить любой алгоритм вычисления путей на графах (стандарт рекомендует алгоритм Дейкстры)

### Результат работы алгоритма для маршрутизатора 6

<a href="https://ibb.co/GsYJY91"><img src="https://i.ibb.co/RhrSrNM/image.png" alt="image" border="0"></a>

Маршрутизатор восстанавливает маршрут до любого компонента сети, представляя себя корнем этого дерева (origin)

То, что описывает правила маршрутизации, -- не граф, а сама таблица маршрутизации

<a href="https://ibb.co/RTqzJj8"><img src="https://i.ibb.co/0yxhzs5/image.png" alt="image" border="0"></a>

### Зонирование (area)

- Каждая область содержит независимую от других LSDB, включающую маршрутизаторы и сети данной зоны
- Из области анонсируются в другую область только суммарные (обобщающие) маршруты без подробного графового представления -- похоже на то, что анонсируется в RIP
- минимизация сложности подсчёта минимальных путей
- минимизация служебного трафика

### Идентификатор   области и маршрутизатора

Это 4-октетный адрес, как в IPv4. Можем его назначать вручную для маршрутизаторов, либо он может быть назначен автоматически как младший или старший IP из интерфейсом маршрутизатора.

### Типы областей
- Backbone 0.0.0.0 -- магистральная область. Обязательно должна быть. Маршрутизаторы, которые находятся в этой области, называются магистральными
- Area (просто области, передают информацию всем обо всех маршрутах и о всех сетях)
- Stub Area -- не принимает информацию о внешних маршрутах по отношению к автономной системе, использует маршрут по умолчанию, то есть не принимает информацию, которая приходит от граничного маршрутизатора автономной системы -- это внешние маршруты. Для этих внешних маршрутов будет использоваться маршрут по умолчанию. Внутри этой области не может быть ASBR, если он не ABR
- No-so-stubby-area: тупиковая область, но не совсем: внутри неё может быть граничный маршрутизатор автономной системы ASBR
- Totally stub area: полностью тупиковая область, где вообще все маршруты вне этой области воспринимаются как маршруты по умолчанию

<a href="https://ibb.co/R6pTSQQ"><img src="https://i.ibb.co/6tR0ZDD/image.png" alt="image" border="0"></a>

С точки зрения области 1.1.1.1 внутри неё известно подробное графовое представление о ней, а про область 0.0.0.0 известно только то, какие сети там есть и что маршруты до них лежат через ABR

### Типы маршрутизаторов
- Internal
- ABR
- Backbone (которые находятся в магистральных областях)
- AS Boundary (ASBR)


### Виртуальные каналы

В OSPF есть ограничение: любая область должна быть соседней с магистральной, то есть она должна быть непосредственно к ней подключена через соответствующий ABR.

- используются, когда область не имеет непосредственного подключения к магистральной области
- обеспечивают логическое соединение между ABR данной области и магистральной (остовной) областью
- виртуальный канал устанавливается между двумя ABR, имеющими общую область с одним ABR, подключенным к магистральной области


<a href="https://ibb.co/kX579sN"><img src="https://i.ibb.co/Fzmr0LR/image.png" alt="image" border="0"></a>

Это конфигурируется на самих роутерах и позволяет обойти жёсткие ограничения стандарта.

### Работа OSPF в широковещательных сетях (внутри локальной сети)

Если к сети подключено много маршрутизаторов, и будет взаимодействие каждый с каждым -- то есть каждый будет анонсировать какие-то изменения в сети, то по сети будет ходить очень много пакетов. Поэтому было принято решение осуществлять взаимодействие иерархически -- выбрать какое-то главное **(назначенное), designated, DR** устройство (на самом деле не устройство, а интерфейс, потому что маршрутизатор в соответствующей сети представлен своим интерфейсом, а в другой сети этот маршрутизатор может быть и не назначенным), для надёжности выберем запасного **backup designated router BDR**, и все остальные. И процесс установления соседских отношений и дальнейшей синхронизации баз данных будет осуществляться только между DR и всеми остальными по отдельности. Все остальные друг с другом взаимодействовать не будут.

Поэтому синхронизация будет идти в две итерации
- не назначенный маршрутизатор увидел изменение и сказал об этом DR
- DR распространяет эту информацию другим соседним устройствам

При этом любой маршрутизатор распространяет информацию ещё и в другие сети -- так будет работать алгоритм флудинга.



- маршрутизаторы обмениваются информацией о конфигурации сети, если только установили соседские отношения (adjacency)
- установление соседских отношений (отношение смежности) не между всеми маршрутизаторами, а только частью для минимизации трафика
- используется hello протокол

Соседские отношения устанавливаются, если
- сеть типа точка-точка
- сеть является виртуальным каналом
- роутер DR
- роутер BDR
- сосед DR
- сосед BDR
- интерфейсы маршрутизаторов находятся в одной подсети
- совпадают типы сетей (PTP, BC)
- интерфейсы маршрутизаторов принадлежат одной области
- совпадает тип области (нормальная, тупиковая и т.д.)
- маршрутизаторы прошли взаимную аутентификацию, если включена
- одинаковые временные параметры -- hello, dead timer -- на них завязана стабильность работы сетевой инфраструктуры
- рекомендуется, чтобы MTU в IP тоже совпадал 

### Выбор DR и BDR
- первый активный маршрутизатор в подсети всегда становится DR
- второй активный маршрутизатор в подсети становится BDR
- если отказывает DR или BDR, то маршрутизатор с наибольшим приоритетом становится BDR
- если два маршрутизатора имеют равные приоритеты, то выбирается маршрутизатор с большим ID
- приоритет маршрутизатора равный 0 препятствует его выбору в качестве DR или BDR




### Формат заголовка OSPF

<a href="https://ibb.co/TB1HkZZ"><img src="https://i.ibb.co/6R84m22/image.png" alt="image" border="0"></a>

Начинка зависит от типа пакета: 

### Типы OSPF пакетов
- 1 - Hello
- 2 - Database Description (LSDD)
- 3 - Link State Request (LSR): запросы о состоянии каналов
- 4 - Link State Update (LSU): полная информация о состоянии канала
- 5 - Link State Acknowledgement (LSAck): подтверждение того, что информация через LSU получена

Чтобы понять, насколько у устройств разное представление о сети в целом, посылается не вся эта информация, а некоторая заголовочная часть, которая как раз позволяет понять, есть ли что-то у соседа новое или всё то же самое. Это и передаётся в пакетах LSDD.

Если у соседа есть что-то новое, мы посылаем ему LSR, он при помощи LSU сообщает полную информацию, а мы при помощи LSAck подтверждаем её получение.

Не путать LSAck (тип пакета) с LSA -- Link State Advertisement -- самой записью в базе данных.

### Формат Hello-пакета

<a href="https://ibb.co/2kVBQ7q"><img src="https://i.ibb.co/0G43Sjq/image.png" alt="image" border="0"></a>

#### Опции
- Е -- маршрутизатор поддерживает внешние маршруты. При помощи этого мы ограничиваем маршрутизаторы в тупиковой области: они обычно такие маршруты не поддерживаются. Маршрутизаторы не устанавливают соседские отношения, если не совпадают Е-биты в приветственных пакетах
- МС -- маршрутизатор поддерживает работы в мультикаст режиме
- N/P -- маршрутизатор поддерживает LSA Type 7 (NSSA)
- EA -- маршрутизатор поддерживает External Attribute LSA (Type 8). Не поддерживается большинство реализаций OSPFv2
- DC -- маршрутизатор поддерживает каналы по требованию
### Состояния соседских отношений
- **Down** -- маршрутизатор не получал ни от кого приветственных (hello) сообщений. В этом случае он периодически рассылает hello-пакеты на случай, если в сети всё-таки кто-то появится
- **Attempt** (только в NBMA-сетях) -- посылка сообщения потенциально соседнему маршрутизатору: когда явно прописан сосед, с которым он должен подружиться, и тот пока не ответил
- **Init** -- маршрутизатор получил приветствие от соседнего маршрутизатора и добавил его  список соседей
- **Two-way** -- маршрутизатор получил адресный ответ на своё приветствие. Опционально происходит выбор DR/BDR, либо сообщается о том, кто в сегменте сети является DR/BDR

Дальше идёт процесс обмена синхронизации баз данных

- **ExStart** -- начало процесса синхронизации LSDB. Маршрутизатор с максимальным ID становится мастером, его сосед slave
- **Exchange**: мастер делится информацией о LSDB с соседом при помощи пакетов LSDD. Сосед подтверждает полученные пакеты при помощи LSAck, передаются только заголовки LSA
- **Loading**: если мастер имеет более свежую информацию для какой-либо записи
	- slave запрашивает её LSR
	- мастер передаёт её LSU
	- slave подтверждает её LSAck
	- Обратно аналогично
- **Full**: соседи находятся в полностью синхронизированном состоянии

### Состояния интерфейсов маршрутизаторов

- down
- loopback
- point to point
- waiting -- если ещё не определились
- DR
- backup
- DRother

### Обновление состояния сети

Процесс происходит, если один из маршрутизаторов обнаружил изменение в состоянии своих каналов (флудинг). Разделяется на локальный флудинг для локального сегмента (взаимодействия DR/BDR и Other) и флудинг в глобальном масштабе, когда информация растекается по всей сети

Локальный

<a href="https://ibb.co/1mjtJTR"><img src="https://i.ibb.co/NybdnKW/image.png" alt="image" border="0"></a>


<a href="https://ibb.co/7pxvGjL"><img src="https://i.ibb.co/3F5104Q/image.png" alt="image" border="0"></a>

### Основные типы записей LSA
- **Router Links, type 1**
	- состояние каналов маршрутизаторов
	- распространяются в рамках области
	- рассылаются всеми маршрутизаторами
- **Network Links, type 2**
	- состояние каналов присоединенной сети
	- распространяются в рамках области
	- рассылаются DR
- **Summary Links, type 3**
	- суммарное (обобщённое) состояние каналов сети
	- рассылаются ABR между областями
	- содержит маршруты к сетям вне области, не описывает маршруты внутри автономной системы
- **AS Summary Links, type 4**
	- Состояние каналов ASBR
	- рассылается ABR
	- содержит информацию о наличии в области ASBR
- **AS External Links, type 5**
	- состояние внешних каналов автономной системы
	- рассылается ASBR внутри автономной системы
	- содержит внешние маршруты по отношению к автономной системы, в т.ч. маршруты по умолчанию


<a href="https://ibb.co/WGVJjtt"><img src="https://i.ibb.co/S5fCGrr/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/pyL72Hv"><img src="https://i.ibb.co/rswjkBG/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/7zMVVh8"><img src="https://i.ibb.co/g7qwwYH/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/mbmbL1F"><img src="https://i.ibb.co/ydDdwGB/image.png" alt="image" border="0"></a>

<a href="https://ibb.co/S09WF10"><img src="https://i.ibb.co/jG1BnxG/image.png" alt="image" border="0"></a>


# NAT: Network Address Translation

Прозрачный для конечных приложений механизм для преобразования адресов из одной группы в адреса другой группы. То есть происходит обычная подстановка одних IP-адресов вместо других, или связок (IP/номер порта) -- в таком случае речь уже будет идти о NAPT (Network Address Port Translation -- развитие NAT).
- при условии, что приложение не включает на прикладном уровне IP-адрес хоста (IP/Номер порта) и не опирается при своей работе на данную информацию, то есть приложение написано корректно и не берёт информацию с сетевого уровня в прикладной
- часть протоколов всё равно требует дополнительной поддержки (например, FTP)
- когда приложение общается не через один порт, а через несколько: например, один порт на посылку данных, а другой на приём (FTP)
### Классификация
- **Basic NAT** -- преобразование только сетевых адресов
- **Network Address Port Translation (NAPT)** -- преобразование сетевых адресов и номеров портов

Далее под NAT будем иметь в виду NAPT!

## Принцип функционирования

Здесь приведен именно классический NAT без портов

<a href="https://ibb.co/xq5ctMh"><img src="https://i.ibb.co/F47fLB6/image.png" alt="image" border="0"></a>

Два хоста 

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExMjg5NDc0NjEsODc1MzA4OTQyLC0yOD
QxMjM0MDEsLTIwNTA4ODQ1OTgsMjEwOTM2MzU3LDE2ODQzMzUy
OTMsLTQzMjEzNzgyMSw0NTkzOTYzMDcsMTg0NTQyNDIxNywtNT
IzOTgyODIzLC01OTc0OTY0NzAsLTQxNDYwNjQzNiw5ODUwNjQz
NzYsLTExNDUzMjg1OCwxNzUxMzE2OTk3LC03NzQzNDE5MjUsLT
E0MzA0MjUzMjYsMTI2OTA2MTI0MiwzNzU5OTIwNTUsMzg5MTY0
OTE0XX0=
-->