~~strikethrough text~~## Введение

### Используемая литература: основная

L. Peterson and B.Davie, Computer Networks: A Systems Approach: https://book.systemapproach.org/ --- используется как основной учебник по сетям в западных университетах

James F. Kurose and Keith W. Ros, Computer Networking: A Top-Down Approach (нестандартный подход)

Олифер В.Г., Олифер Н.А.. Компьютерные сети. Принципы, технологии, протоколы. ~1000 страниц. 

Таненбаум и Уизирел (Tanenbaum and Wetherell). Компьютерные сети. -- традиционный учебник по сетям.

### RFC -- Request For Comments

По изучаемым протоколам --  ietf.org/blog/how-read-rfc/
 

### Дополнительная литература

Wireshark and Ethereal Network Protocol Analyzer Toolkit, Syngress - ~550 страниц на английском или их аналоги -- какая-нибудь книжка по Wireshark -- основному анализатору протоколов на лабораторных работах.

Что-то про программирование сетевых приложений (про сокеты и прочие радости)

Литература для подготовки к сертификационным экзаменам по сетевым технологиям основных производителей ПО и оборудования. Лучше читать на английском



## Задачи современных сетей

### Зачем нужны сети

Одна из основных проблем -- обеспечение *надёжной* передачи данных между абонентами. Чтобы это сделать, у нас будет работать ряд механизмов -- коды обнаружения или коррекции ошибок, специальные протоколы, алгоритмы построения альтернативных маршрутов передачи данных и так далее.


### Интерактивные сервисы

IP-телефония, видео конференции, обмен мгновенными сообщениями, социальные взаимодействия (в т.ч. игровое) требуют обеспечение *минимальных* задержек в передаче данных.
 
Однако часть протоколов, которыми мы пользуемся на сегодняшний день, не сильно под это заточены. Да, при помощи определённых механизмов мы можем это обеспечить, однако то, чем мы сейчас пользуемся, можно было бы сделать намного лучше (привет легаси из семидесятых, когда взгляд людей на устройство сетей и архитектурные решения, которые казались вполне разумными, были совершенно иными и сегодня не сильно выдерживают критику). Предложены современные решения, которые позволяют всё делать намного быстрее, однако из-за необходимости обратной совместимости с уже существующим ПО и оборудованием эти изменения внедряются очень медленно.

### Использование ресурсов

Можно пользоваться файловыми хранилищами и прочими системами, которыми пользуются одновременно большое количество людей. Возникает вопрос: а как обеспечить приемлемую пропускную способность сети?

Понятно, если каждый из нас, находясь в некоторой сетевой инфраструктуре, захочет скачать кино в HD-качестве, мы это кино по идее  будем качать очень долго, но на самом деле всё происходит быстрее, -- и не из-за того, что к каждому дому подключен терабитный канал для обмена информацией, а за счёт того, что мы не одновременно все пользуемся нашей сетью с максимальной нагрузкой на эту инфраструктуру.

Здесь работает принцип **статистического мультиплексирования**: да, нам нужна высокая пропускная способность от сети, но нас спасает то, что она нужна не всем одновременно. Поэтому мы проектируем часто сеть не на максимальную нагрузку, которая будет требоваться в пике -- если все одновременно начнут обмениваться гигантскими объёмами информации, а за счёт того, что существенная часть пользователей в конкретный момент времени простаивает и ничем не обменивается. Исходя из этого подхода мы можем проектировать сеть с несколько ослабленными требованиями.

Есть, однако и особенные истории, например, проектирования внутренней сети суперкомпьютеров для организации быстрой коммуникации и пересылки данных. Тут мы проектируем сетевые инфраструктуры исходя из других предположений.

### Доставка контента

Есть даже такое понятие -- *CDN*: *Content Delivery Network*, когда у нас есть сервисы, отдающие статический (видео по требованию) или динамический (онлайн-трансляции) контент.

Тут есть разные интересные механизмы, связанные с системами хранения реплик и географическим кэшированием данных: если условный ролик из Австралии распространяется по миру и его начинают смотреть в других странах, то он закэшируется на серверах по всему миру, чтобы при каждом запросе к этом ролику не обращаться к далёким серверам.

### Компоненты сетевой инфраструктуры

<a href="https://imgbb.com/"><img src="https://i.ibb.co/vkDS7Fh/image.png" alt="image" border="0"></a>

На этой картинке видим 4 важных компонента: приложения (app) работают на базе некоторых вычислительных систем (host), которые обмениваются данными посредством некоторого сетевого оборудования (здесь использовано слово router, но это лишь один из подклассов сетевого оборудования), которое связывает конечные системы и другое коммуникационное оборудование посредством некоторых каналов связи (link).

### Что надо знать к концу курса

Что происходит, когда на каком-то узле сети инициируется некоторый обмен сообщениями с удалённым узлом?

Нарисуем простенькую сетевую инфраструктуру. Пусть в сети будет какой-нибудь Ethernet-коммутатор (Ethernet -- основной использующийся сегодня в локальных сетях протокол), который мы назовём *switch*. Это устройство, у которого есть несколько портов, к которым по кабельной инфраструктуре можно подключить какие-то конечные системы -- компьютеры host1 и host2, на которых стоит сетевая карта (NIC - Network Interface Card, но в разных сетях эти сетевые карты могут называться по-разному: например, в сетях хранения данных это может быть HBA -- Host Bus Adapter, в сетях типа Infiniband, предназначенных для быстрого обмена трафика большого объёма, -- HCA -- Host Channel Adapter и так далее).

Кроме этого, пусть у нас будет ещё один хост в сети -- DNS-сервер.

Также в сети есть промежуточное сетевое оборудование -- маршрутизатор Router.

Сетевые карты хостов образуют локальную сеть Ethernet. Маршрутизатор тоже подключается к этой сети одним из своих интерфейсов.

<a href="https://ibb.co/vZzzk5f"><img src="https://i.ibb.co/QrmmMBh/image.png" alt="image" border="0"></a>

У каждой сетевой карты есть адрес в сети Ethernet -- MAC (Media-Access Control)-адрес, который из себя представляет 6 *октетов*. Обычно первые три октета соответствуют производителю сетевого оборудования, а вторая часть назначается на заводе, либо при желании меняется операционной системой, хотя обычно это не требуется.

На уровне выше -- на уровне *межсетевых* коммуникаций: не между конкретными физическими устройствами, такими как сетевые карты, а для коммуникации на уровне хостов, используются IP-адреса. Каждый хост может иметь и несколько IP-адресов (у него может быть и несколько сетевых карт, и на одной карте может быть несколько IP), и в нормальной ситуации эти IP уникальны (хотя бывает и иначе).

IP-адрес может быть разных версий -- IPv4 или IPv6. IPv4 состоит из 4 восьмиразрядных чисел (октетов) вида 192.168.17.25.

Здесь надо обратить внимание, что в сетях используется термин *октет*, а не байт, потому что у байта на самом деле нет стандарта, и, строго говоря, байтом может быть и не 8 бит, а 7, и 13, и 29, если нам очень хочется -- это зависит от архитектуры. Поэтому грамотнее называть восьмиразрядные числа октетами.

DNS-серверы позволяют сопоставить IP-адресам более понятные человеку символьные доменные имена. У нас может быть запись типа 

```dns
A: 	ya.ru	123.53.87.9
```

Если MAC-адрес у нас имеет смысл в локальном сегменте -- то есть в пределах локальной сети до маршрутизатора, то IP-адрес позволяет общаться за пределами маршрутизатора между сегментами сети. 

Пусть у хостов следующие IP-адреса:

|host|IP|
|--|--|
|host1| 192.168.17.25
host2| 192.168.17.12

Тогда этим IP-адресам могут быть сопоставлены имена host2.local и host1.local соответственно.

На хостах согласно устройству сетевой инфраструктуры работают какие-то приложения, и чтобы адресовать конкретные приложения на хосте, мы поднимаемся на один уровень выше в стеке протоколов и начинаем задействовать транспортные протоколы (TCP, UDP, PGM, SCTP и так далее). Каждое приложение, которое открывает сетевое соединение при помощи транспортных протоколов, адресуется с помощью некоторого числового идентификатора -- 16-разрядного числа от 0 до 65535 -- порта. Дл каждого приложения, запущенного на хосте и взаимодействующего с сетью, также в соответствие ставится и номер порта.

Есть некоторые стандартные порты: например, 80 порт традиционно используют HTTP-сервисы, 53 порт -- DNS и так далее.

Чтобы идентифицировать конкретное приложение, которое работает на конкретном хосте в глобальном сегменте сети, нужна связка IP-адрес + номер порта. Часть этих портов назначается статически и хорошо известна; клиентские системы зачастую используют *динамические* порты.

Рассмотрим, как у нас будут работать не или иные механизмы в сети, когда мы посылаем некоторое простейшее сообщение от одного хоста к другому, например, командой `ping`.

Команда `ping` использует специальный протокол ICMP (Internet Control Message Protocol), который работает поверх IP и одна из функций которого  -- посылка эхо-запросов.

Попытаемся выполнить на хосте1 команду

```powershell
ping host2.local
```

Написав какое-то имя в виде буквенного идентификатора, подразумевается, что мы не знаем IP-адрес хоста для того, чтобы взаимодействовать с ним на сетевом уровне. Чтобы этот IP адрес, у нас потенциально есть несколько возможностей.

Например, у нас где-то на компьютере локально может находиться файл `hosts` в ОС, в котором можно прописать статические взаимодействия имён адресам.

Плюс если мы заранее взаимодействовали с этим хостом по этому имени, на нашем компьютере может быть закеширована информация о том, что с соответствующим доменным именем связан тот или иной IP-адрес -- DNS кэш. Его можно посмотреть командой

```powershell
ipconfig /displaydns
```
<div align="center"><a href="https://imgbb.com/"><img src="https://i.ibb.co/T0pCwpL/image.png" alt="image" border="0"></a></div>

Эта информация в кеше берётся из DNS-сервера. В настройках сетевой карты прописаны IP-адреса предпочтительных DNS-серверов, к которым надо обращаться за разрешением доменных имён.

Зная адрес DNS-сервера, мы должны сформировать запрос на него с указанием того доменного имени, IP-адрес которого мы хотим получить. Но чтобы взаимодействовать в этим хостом на канальном уровне, нам нужен не только его IP-адрес, но и MAC-адрес той сетевой карты, с которой мы взаимодействуем.

MAC-адрес нам нужен, потому что хост1 знает, что хост2 находится в том же сегменте сети. Иначе надо было бы обращаться к серверу вне локальной сети через маршрутизатор, и запрашивать MAC-адрес маршрутизатора, который находится в нашем сегменте сети.

По IP-адресу DNS-сервера мы поняли, что этот сервер находится в нашем сегменте локальной сети, а поэтому для взаимодействия с ним нам нужен его MAC-адрес. Для этого тоже есть несколько возможностей: во-первых, если мы раньше уже взаимодействовали с этим хостом, то информация о соответствии MAC-адресов и IP-адресов может быть закеширована -- такое понятие называется ARP (Address Resolution Protocol)-кеш. Этот протокол ARP используется для того, чтобы мы могли узнать MAC-адрес узла по его IP-адресу в локальном сегменте сети.
 
 Допустим, IP DNS-сервера --  192.168.17.42. Тогда в ARP-кеше должно быть соответствие вида 
192.168.17.42 -> MAC3. Эта запись может находиться там статически (например, мы можем записать это соответствие с помощью команды `arp -s`), но на практике она узнаётся динамически. Для этого мы посылаем в сеть специальный ARP-пакет в виде широковещательного запроса. Его получат все хосты в нашем локальном сегменте сети, а сам запрос будет спрашивать, какой MAC-адрес у данного (...42) IP.

Поэтому первое, что мы сделаем, введя команду `ping`,  -- пошлём ARP-запрос. Этот пакет попадёт на коммутатор, который, в свою очередь, перешлёт его всем хостам в локальной сети. И если бы в сети был бы ещё один коммутатор Switch2, то и на Switch2 был бы отправлен этот пакет, а он, в свою очередь, переслал бы его хостам, которые подключены к нему и так далее.

Все хосты, получив этот пакет, смотрят, не про них ли IP-адрес там спрашивается. Если нет, они этот пакет игнорируют, а если да, то этот хост должен сформировать соответствующий ARP-ответ. Это будет ответ от DNS-сервера нашему хосту1 с адресом MAC3.

При этом коммутатор тоже будет обучаться: при указании конкретного адресата пакета он пересылает этот пакет на конкретный хост, и поэтому он запомнит, что на какой-то конкретный порт коммутатора пришёл пакет от отправителя с адресом MAC1, поэтому в *таблице продвижения (forwarding database*) появится некая запись, что через порт номер 1 доступен МАС1.  Аналогичная вещь появится и на втором коммутаторе Switch2 (например, на его порте 10 доступен хост с MAC-адресом MAC1). Таким образом, коммутаторы эту информацию запоминают. Поэтому в случае адресного ответа от MAC3, пакеты. предназначенные хосту с адресом MAC1, будут посылаться не на все порты, а только на те, которые с ним связаны. Поэтому конкретный ответ от DNS-сервера дойдёт напрямую до хоста 1.

Зная IP-адрес и MAC-адрес DNS-сервера, мы готовы с ним взаимодействовать. Мы посылаем DNS-запрос на этот сервер по протоколу UDP, который представляет собой слоёный пирог из Ethernet, IPv4, UPD и DNS-протоколов. Мы в этом запросе будем спрашивать, какой IP-адрес у хоста с именем host2.local? 

Это сообщение будет доставлено непосредственно DNS-серверу, потому что коммутатор уже зарегистрировал два пакета MAC1 -> MAC3 через условный порт 1 и MAC3 -> MAC1 через условный порт 2, поэтому при передаче DNS-запроса маршрутизатор будет передавать пакеты только через эти порты напрямую.

DNS-сервер смотрит в свой каталог, находит там запись, соответствующую имени host2.local, и формирует нам ответ. Но опять же, чтобы отправить нам ответ, он должен узнать наш MAC-адрес: для этого он, скорее всего, выполнит ARP-запрос и получит ARP-ответ с нашим MAC1 (если DNS-сервер про наш MAC1 не знал). 

В результате мы получим DNS-ответ о том, что хосту host2.local соответствует адрес 192.168.17.12. Эту информацию мы помещаем в наш DNS-кеш.

Теперь мы должны узнать MAC-адрес второго хоста (MAC2). Для этого снова формируется ARP-запрос про IP второго хоста, и на него принимается ARP-ответ. В это же время в таблице продвижения на коммутаторе появится запись о том, что через условный третий порт на коммутаторе был получен пакет от хоста с адресом MAС2.

После этого всё готово, чтобы сформировать очередной пакет на второй хост (Ethernet + IPv4 + ICMP), на который тот может ответить, в свою очередь, разрешив наш IP-адрес в MAC-адрес при помощи протокола ARP.

## Классификация сетей

### По географическому принципу

- PAN -- Personal Area Network: сети, предназначенные для обслуживания одного человека. Самый типичный пример -- Bluetooth
- LAN -- Local Area Network -- сеть хостов внутри здания
- CAN -- Campus Area Network -- сеть хостов внутри кампуса
- MAN -- Metropolitan Area Network -- городские сети
- WAN -- Wide Area Network -- глобальные сети, например, интернет.

Эти разделения по сути условные, хотя есть некоторые типичные технологии и протоколы, которые в больше степени ориентируются на сетевую инфраструктуру того или иного масштаба. При этом часть протоколов и технологий являются универсальными и используются в сетях любого масштаба.

<a href="https://ibb.co/d4gZKch"><img src="https://i.ibb.co/VYm6BNK/image.png" alt="image" border="0"></a>

Обеспечить высокоскоростное соединение без потерь данных в рамках локальной сети просто, но при переходе к глобальным сетям скорость передачи данных между узлами падает, и надёжность тоже, потому что чем больше сеть, тем через большее количество промежуточных устройств нужно передать эти данные.

То, что скорость и надёжность передачи данных падает при переходе в глобальный масштаб, накладывает некоторые ограничения на то, как проектировались и что было заложено в те или иные сетевые протоколы.

### По средам передачи данных
 
Проводные:
- Оптические кабели
- Коаксиальные кабели -- в современных локальных сетях практически не используются, хотя они могут применяться в некоторых специализированных сетевых инфраструктурах
- **Витая пара**

Беспроводные

### По принципам адресации абонентов

#### Unicast

У конкретного абонента есть свой уникальный адрес как на сетевом (IP), так и на канальном (MAC) уровне. Сообщения посылаются персонально данному конкретному абоненту.

#### Multicast

Мы посылаем данные по какому-то одному (групповому) адресу, но их получит целая группа абонентов, заинтересованная в этом трафике. 

#### Broadcast

Широковещательные адреса: посылая сообщения на них, его получают все абоненты.

Он работает только в рамках локального сегмента -- до маршрутизатора, и у нас нет возможности послать широковещательное сообщение всем хостам в интернете.

Возможность широковещательных запросов есть как на канальном уровне, так и на сетевом. Пример широковещательного адреса на канальном уровне (MAC) -- ff:ff:ff:ff:ff:ff. Например, посылая широковещательный ARP-запрос, в качестве адресата указывается именно этот широковещательный MAC-адрес.

С широковещательными адресами в IP ситуация интереснее: во-первых, в IPv4 есть два вида broadcast-запросов, а во-вторых, в IPv6 была попытка отказаться от широковещательной адресации, поэтому формально его там нет (хотя по сути это не так).

#### Anycast

Сообщение будет доставлено какому-то конкретному хосту из группы, в отличие от multicast, где сообщение будет доставлено всем хостам.

Классический пример, где это может быть полезно -- кластер серверов с общим групповым адресом, которые взаимодействуют с клиентом. Клиент посылает запрос на обслуживание, и ему всё равно, с каким конкретно сервером он будет взаимодействовать -- поэтому его запрос посылается на групповой адрес всего кластера, но доставлен он будет только какому-то одному серверу.

#### Числовые идентификаторы

IP-адреса, MAC-адреса, номера портов и так далее. Их легко закодировать, они занимают мало места, с ними могут эффективно работать какие-то аппаратные системы.

#### Символьные идентификаторы

Доменные имена типа ya.ru. Более гибкие и легче воспринимаются человеком.

#### Плоская адресация

Когда все адреса равноценны, и по адресу мы не можем получить никакую дополнительную информацию о том, где потенциально расположен тот или иной хост. 

Например, MAC-адреса плоские, по ним нельзя построить никакую иерархию, и сам MAC-адрес ничего не говорит о том, где примерно находится тот или иной хост.

#### Иерархическая адресация


Когда из адресов строится некоторая иерархия, базируясь на которой, по адресу можно сказать, где потенциально расположен тот или иной хост.

Например, доменные имена (с национальными доменами) типа samos.dozen.mephi.ru могут рассматриваться как иерархические адреса: 
- .ru говорит о том, что это как-то относится к России
- mephi указывает на организацию
- dozen указывает на подразделение в этой организации
- samos указывает на конкретный сервер

Другой иерархический принцип -- выдача адресов IPv6. Адреса выдаются некоторыми блоками: блок национального регистратора, блок провайдера, адрес конкретной организации и так далее.

### По принципу коммутации

#### Коммутация каналов

<a href="https://ibb.co/4Vgk6Pb"><img src="https://i.ibb.co/6WJQ3gK/image.png" alt="image" border="0"></a>

У нас есть какие-то абоненты, которые хотят друг с другом взаимодействовать. Прежде чем эти абоненты смогут это сделать, надо настроить всё промежуточное оборудование в плане того, что этим абонентам будут выделены некоторые физические ресурсы для организации коммуникации между ними.

Таким образом, прежде чем абонент 1 пошлёт какое-то сообщение абоненту 4, в рамках промежуточных коммуникационных устройств надо установить соответствующий канал связи -- некоторую полосу пропускания, выделенную жёстко за ними. 

Классический пример -- старые телефонные сети с аналоговыми коммутаторами.

Два абонента, которые получили доступ к этому каналу связи, могут монопольно его использовать, потому что он предназначается только им. При этом общаться они могут достаточно эффективно, и с их точки зрения всё очень круто.

С другой стороны, другие абоненты, которым таких ресурсов не досталось, вынуждены ждать, пока эти ресурсы не освободятся.

#### Коммутация пакетов

<a href="https://ibb.co/JqvNJBD"><img src="https://i.ibb.co/cw6Png4/image.png" alt="image" border="0"></a>

Мы хотим послать некоторое сообщение, которое может быть достаточно объёмным: например, фильм в HD качестве в несколько гигабайт. Понятно, что такой массив данных одним куском мы передать не можем, поэтому если бы мы даже потенциально могли это сделать, то мы бы потенциально монополизировали какую-то линию связи на достаточно долгое время.

Поэтому на практике мы разбиваем большое сообщение на несколько частей --  *пакетов*. Естественно, когда мы их получаем на абоненте, их надо собрать воедино, и для этого надо как-то маркировать пакеты заголовками. В современных сетях эти пакеты могут приходить в разном порядке, поэтому их надо где-то буферизовать, потом слепить вместе и доставить приложению.

Плюс -- так как мы передаём данные маленькими порциями, мы можем использовать линию связи в режиме разделения времени между большим количеством абонентов -- все получают вроде как равный доступ к сетевой инфраструктуре и все вроде бы довольны.

При этом в современных сетях мы можем приоритезировать трафик:  для каких-то приложений и абонентов мы можем задать более высокий приоритет по обслуживанию трафика, я для каких-то меньше. Всякие QoS (Quality of Service) позволяют оптимизировать эти приоритеты, или, например, каким-то абонентам выделить отдельную полосу пропускания, которая,  если эти абоненты молчат, отдаётся другим, а как только они заговорят, все пакеты других приложений приостанавливаются, задерживаясь в какой-нибудь очереди, а более высокие приоритетные пакеты, для которых мы и зарезервировали полосу пропускания, будут обслужены в первую очередь.

<a href="https://ibb.co/FJSrf2N"><img src="https://i.ibb.co/rMCjLYT/image.png" alt="image" border="0"></a>

Например, так может работать коммутация пакетов на уровне коммутатора (switch). Это упрощённая схема.

У нас есть некоторая коммутационная фабрика или коммутационная матрица, реализованная по тому или иному принципу, и есть порты (interface), через которые можно с этой фабрикой взаимодействовать, и с этими интерфейсами связаны ещё некоторые очереди на вход и на выход.

Когда пакет приходит в некоторый интерфейс, он попадает в очередь на вход, которая обрабатывается в соответствии с некоторой идеологии облуживания (FIFO или очередь с приоритетом), будет передан через коммутационную матрицу в выходную очередь на некотором другом интерфейсе, и когда дойдёт его очередь, он будет выкинут и продвинут на следующее сетевое устройство.

При этом коммутационные фабрики могут быть построены по разным принципам. Например, в сетях есть понятие *блокирующие* и *неблокирующие* устройства.

Неблокирующее устройство может передавать пакеты одновременно между всеми парами абонентов, при этом коммутационных способностей матрицы будет хватать на то, чтобы пакеты, идущие в разные стороны, не блокировали друг друга.

Блокирующие устройства имеют некоторые ограничения, например, на количество абонентов, которые одновременно передают сообщения.

Продвижение пакетов может быть реализована в двух режимах -- store/forward и cut-through.

В **store/forward** мы сначала должны пакет полностью получить и складировать в соответствующую очередь. Мы не можем начать передавать его дальше, пока не получили его до конца -- то есть сначала получили и записали в буфер (store), а потом передали дальше (forward).

В режиме **cut-through**, как только мы получили заголовок сообщения -- первые несколько бит данных, мы уже можем понять адресата -- куда это сообщение передавать. Поэтому само сообщение можно уже начать передавать на соответствующий порт сообщение, которое ещё до конца не получено. Это организуется сложнее, но в ряде случаев позволяет сократить задержки передачи данных.

Классы устройства | Домен коллизий | Широковещательный домен | Уровень устройства | Примечание 
|--|--|--|--|--
Repeater/Hub|Да: одновременно нельзя передавать несколько сообщений | Да | Физический (L1)|Repeater (повторитель) просто усиливает сигнал и передаёт его дальше. Оно не использует хитрую высокоуровневую логику, поэтому классический повторитель -- двухпортовое устройство. Развивая идею, можно сделать *многопортовый* повторитель -- концентратор (hub). Он позволяет соединить несколько устройств, фактически усиливает сигнал, передаваемый через один какой-то порт, но сам hub формально представляет собой некоторую общую среду, то есть можно представить себе мнемонически, что эти порты соединены воедино, и это устройство представляет некоторую шинную топологию -- то же самое, что взять какой-то проводник и подключить к нему какие-то хосты. В данной среде может быть активным только одно устройство, посылающее сигнал. Этот сигнал, хоть он и предназначен конкретному получателю, поступает на все порты -- его получают все, кроме отправителя -- то же самое, что происходит и в шине. Если одновременно два отправителя начинают отправлять сигналы, эти сигналы сталкиваются -- возникает *коллизия*, и данные искажаются. Такие устройства небезопасные (любому устройству доступен весь трафик в сети) и медленные. 
Bridge / Switch (коммутатор) | Нет: устройства могут одновременно передавать данные в рамках существующей инфраструктуры. Любые абоненты общаются друг с другом, не отвлекаясь на другие устройства|Да |Канальный (L2) | Мост передаёт данные между сегментами сети только в случае, если есть получатель. У него есть таблица продвижения: мост знает, какие хосты с МАС-адресами находятся в одном сегменте по отношению к мосту, а какие в другом. При передаче сообщения между хостами в одном сегменте сети оно не попадёт в другие. Это устройство работает на канальном уровне. Эволюция моста -- коммутаторы -- "многопортовые мосты". Коммутатор знает, через какой порт с каким МАС адресом к нему обращаются хосты. Таблица FDB соответствия портов и МАС заполняется в динамике, поэтому есть несколько случаев, при которых сообщение попадает на все порты: broadcast, multicast (не сильно умные коммутаторы), destination location unknown (когда не знаем, куда доставлять). При этом внутренняя организация -- коммутационная матрица, а не шина, и эта матрица в динамике может позволять данные между портами в неблокируемом режиме.
Маршрутизатор (router)/ Switch L3 |Нет|Нет|Сетевой (L3)| Роутер соединяет сети друг с другом. Работает, опираясь на логику уровня выше -- в качестве адресов устройств работают сетевые адреса. На устройствах есть таблица маршрутизации (Routing Table), на основании которой маршрутизатор принимает решение, куда дальше передавать соответствующий пакет. Маршрутизатор, как правило, оповещён о соседних маршрутизирующих устройствах. Базируясь на этой таблице маршрутизации, которая заполняется как статически, так и динамически, есть понятие сети назначения, куда мы хотим передать данные и адрес соседнего маршрутизатора, на который мы это сообщение скидываем (спихивают задачу передачи данных на соседнее устройство, если это сообщение предназначено не в ту сеть, к которой мы непосредственно подключены). Соседа, на который мы спихиваем задачу, обычно называют шлюзом (Gateway). Есть метрика, которая говорит о том, насколько данный маршрут выгоден. Поэтому Routing Table состоит из столбцов Net, Gateway и Metric. При этом маршрутизаторы не передают через себя широковещательный трафик: broadcast сообщения блокируются. Сегодня почти нет отличий между маршрутизаторами и коммутаторами третьего уровня.
Шлюз (Gateway, NAT, NAPT) | -|- |Транспортный (L4) | Это устройства "для дома, для семьи", которые преобразуют номера портов
Gateway (proxy) |- |- | Прикладной (L4+) | Прокси-сервера, могут быть даже на прикладном уровне (в зависимости от конкретной сетевой модели это либо L5, либо L7)

### Топологии сетей

Раз сети связывают некоторые вычислительные системы друг с другом, используя какое-то промежуточное сетевое оборудование, то по сути сетевая инфраструктура представляет собой некоторый *граф*. Поэтому нам важно для обеспечения надёжного, быстрого и высокопроизводительного обмена данными между соответствующими устройствами сети используются различные конфигурации связи устройств.

При этом мы можем рассматривать как *физические* соединения между устройствами (первый уровень рассмотрения) или *логические* топологии, когда мы рассматриваем, какие устройства могут взаимодействовать непосредственно друг с другом.

- полносвязная
- ячеистая
- кольцевая
- звездообразная
- иерархическая
- шина

#### Метрики (характеристики топологий)
- **Диаметр $D$** -- расстояние между максимально удалёнными узлами
- **Связность** $C$ -- рёберная связность: сколько соединений нужно удалить, чтобы сеть развалилась
- **Ширина бинарного деления** $BW$: сколько связей нужно разорвать в сети, чтобы получилось две примерно равноценных топологии. Например, в суперкомпьютерных интерсетях эта метрика используется для того, чтобы определить, как можно сделать разбиение на несколько мини-вычислительных узлов для параллельного решения задачи
- **Стоимость** $Cst$ -- количество связей в графе: показывает затраты на оборудование.

### Характеристики некоторых топологий

#### Диаметр

Топология | Диаметр $D$ 
--|--
Полносвязная | $1$
Двоичное дерево | $2\log_2\frac{p-1}{2}$
1-мерная решётка | $p-1$
2-мерная решётка | $2\sqrt{p-1}$
2D-тор | $\sqrt{\frac p2}$
Гиперкуб | $\log_2 p$


#### Связность

Топология | Связность $C$
--|--
Полносвязная | $p-1$
Двоичное дерево | $1$
1-мерная решётка | $1$
2-мерная решётка | $2$
2D-тор | $4$
Гиперкуб | $\log_2 p$

#### Бисекция

Топология | Ширина бинарного деления $BW$
--|--
Полносвязная | $\frac{p^2}{4}$
Двоичное дерево | $1$
1-мерная решётка | $1$
2-мерная решётка | $\sqrt{p}$
2D-тор | $\sqrt{\frac p2}$
Гиперкуб | $\frac p2$

#### Стоимость

Топология | Стоимость $Cst$
--|--
Полносвязная | $\frac{p(p-1)}{2}$
Двоичное дерево | $p-1$
1-мерная решётка | $p-1$
2-мерная решётка | $2(p-\sqrt{p})$
2D-тор | $2p$
Гиперкуб | $\frac{p\log_2 p}{2}$

### Современные топологии локальных корпоративных сетей (иерархическая сетевая модель)

<a href="https://ibb.co/ZBhLzQc"><img src="https://i.ibb.co/StKswkV/image.png" alt="image" border="0"></a>

У нас имеется три класса устройств в сети:
- устройства **уровня доступа** (access): устройства, к которым подключаются конечные клиенты сети
- устройства **уровня распределения** (distribution)
- устройства **уровня ядра** (core)

#### Уровень доступа

Основная его цель -- обеспечение подключения конечных устройств. При этом надо предоставить большое количество портов для подключения абонентов. Здесь могут решаться иногда и задачи, связанные с безопасностью: например, идентификация пользователей или фильтрация трафика; или задачи, связанные с QoS (Quality of Service): например, приоритезировать трафик для некоторых устройств.

При этом эти устройства представляют собой обычные коммутаторы, просто предоставляющие возможность подключения к сети для конечных устройств.

#### Уровень распределения

Важный момент: устройства уровня доступа -- коммутаторы -- подключаются к устройствам уровня распределения как минимум **двумя** интерфейсами для обеспечения надёжности.

На этом уровне основная решаемая задача -- *Policy-Based Connectivity*: обеспечение соединений в рамках сетевой инфраструктуры, базируясь на некоторых правилах. Под этим мы понимаем всякий хитрый функционал, который у нас есть в сети: агрегирование каналов, применение каких-то правил, управление потоками данных и балансировки -- в том числе, здесь мы можем уже говорить и о задачах маршрутизации. 

Здесь мы обеспечиваем масштабируемость и наращиваемость инфраструктуры: навешивая на устройства уровня распределения дополнительные коммутаторы, мы можем сильно увеличивать масштаб сети, то есть количество потенциально возможных конечных устройств.

Ещё один важный момент -- быстрое восстановление сети в случае аварийных ситуаций. За счёт этого уровня возникновение какой-то аварии на некотором интерфейсе не приведёт к развалу сети, потому что на этом уровне обеспечиваются резервные пути передачи данных.

Устройства уровня распределения подключаются к устройствам уровня ядра несколькими интерфейсами к каждому. Здесь работает технология *агрегирования* каналов, когда несколько физических соединений мы воспринимаем как одно логическое для повышения надёжности и производительности.

#### Уровень ядра

Основная цель -- обеспечение высокоскоростного соединения. Так как через ядро идут очень большие объёмы трафика, этот трафик надо перекидывать на соответствующие устройства ниже по иерархии. Поэтому здесь почти не применяются какие-то хитрые технологии: нам нужны коммуникации с минимально возможной задержкой и максимально возможной пропускной способностью при сохранении высокой стабильности и надёжности.

### Взаимодействие сети организации с сетью Интернет

Существует несколько подходов к организации сети предприятия (интранет):
- интранет является частью интернета. Это плохо, потому что небезопасно
- интранет изолирован от интернета. Это для современных организаций плохо, хотя для каких-то критичных инфраструктур (военные или АЭС) это вполне используется
- часть хостов организации доступны в интранете, недоступном из сети напрямую. Однако при инициации соединения изнутри организации при использовании брандмауэра мы можем предоставить доступ к внешним ресурсам. При этом часть хостов организации находятся в *экстранете*, то есть извне, и являются частью интернета. Интранет отделён от экстранета брандмауэром -- корпоративным фаерволом.

### Основные понятия

**Интерфейс** -- формально определённая логическая и/или физическая граница между взаимодействующими независимыми объектами. Задаёт параметры, процедуры и характеристики взаимодействия объектов.

В сетях разделяют **физический** и **логический** интерфейсы.

**Физический интерфейс (порт)** определяется набором электрических связей и характеристиками сигналов. Представляется в виде совокупности разъёма и набора контактов с определённым назначением.

**Логический интерфейс (протокол)** -- набор информационных сообщений определённого формата, а также набор правил, определяющих логику работы с этими сообщениями.

### Предпосылки многоуровневой организации сетевого взаимодействия

Сетями решается множество задач:
- надёжная передача данных
- передача блоков данных произвольной длины
- разделение среды передачи данных между множеством пользователей
- пересылка данных с максимально возможной скоростью
- поиск пути для передачи данных
- разрыв и установление соединения при передаче данных
- обеспечение защиты данных в процессе передачи
- и так далее

Поэтому слишком накладно реализовывать набор данных функций для каждого сетевого приложения с нуля.

### Принцип сетевого взаимодействия двух узлов
1. Виртуально каждый экземпляр протокола взаимодействует с аналогичным экземпляром на удалённом узле.
2. Каждый экземпляр протокола использует сервисы непосредственно нижележащего протокола, и ничего не знает о протоколах на более глубоких уровнях

### Принцип инкапсуляции

Протоколы более низких уровней "оборачивают" более высокоуровневые протоколы, добавляя некоторую дополнительную информацию, которая обеспечивает некоторый сетевой функционал для доставки сообщения по сети.

### Достоинства многоуровневой организации
- Используется принцип "Разделяй и властвуй":
	- более простое решение конкретной задачи
	- простота отладки
	- надёжность решения
	- ...
- сокрытие деталей реализации механизмов от более высоких уровней
- повторное использование протоколов

### Недостатки многоуровневой организации

- Дополнительные затраты: увеличивается количество передаваемых данных, а, следовательно, и время их обработки
- Сокрытие некоторых механизмов не всегда оптимально для приложений

### SDN и SDDC

Программно определяемые сети и программно определяемый ЦОД.
- конфигурацию сети определяют потребности приложений
- динамическое изменение конфигурации
- разделение сети на Control plane и Forwarding plane

### Референсные сетевые модели

Предоставляют некоторый шаблон, описывающий функционал каждого уровня при многоуровневом сетевом взаимодействии.

Существуют две основных модели: 7-уровневая модель ISO/OSI и Internet Model (DoD) из 4 уровней

<a href="https://ibb.co/SxDtjQH"><img src="https://i.ibb.co/4fw8qsC/image.png" alt="image" border="0"></a>

### Единицы измерения передаваемых порций данных

Единица | Уровень 
--|--
Бит | Физический
Кадр | Канальный
Пакет / дейтаграмма | Сетевой
Сегмент / Пользовательская дейтаграмма | Транспортный
Сообщение | Прикладной

# Физический уровень

## Модуляция

**Цифровая модуляция** -- процесс преобразования цифровых данных в аналоговые сигналы, которые эти данные представляют.
### Виды кодирования
#### NRZ: Non-Return to Zero

Самая простая форма цифровой модуляции

![../_images/f02-04-9780123850591.png](https://book.systemsapproach.org/_images/f02-04-9780123850591.png)

Однако проблема такого сигнала заключается в том, что при большом количестве подряд идущих одинаковых бит теряется **синхронизация** между приёмником и передатчиком. 

#### NRZI: Non-Return to Zero Inverted

При таком способе модуляции 1 обозначается изменением состояния, а 0 -- отсутствием изменения. Это решает проблему подряд идущих единиц, но не решает проблему подряд идущих нулей.

#### Манчестерское кодирование

В данном способе бит данных складывается с часами по модулю два. Однако в таком случае требуется вдвое большая полоса пропускания, так как частота сигнала увеличивается в два раза.

![../_images/f02-05-9780123850591.png](https://book.systemsapproach.org/_images/f02-05-9780123850591.png)

#### 4B/5B

Каждая комбинация 4 бит кодируется специальной последовательностью 5 бит, в которой никогда не бывает больше одного лидирующего нуля и больше двух нулей в конце. Данная последовательность кодируется с помощью NRZI, так что решается проблема большого количества подряд идущих нулей и единиц.

Так как всего пятиразрядных кодов 32, а из них для кодирования 4-битных комбинаций используется 16 + есть несколько запрещённых комбинаций (например, 11111 или 00000), то оставшиеся коды могут использоваться для подачи служебных сигналов.

В таком случае эффективность кодирования равна 80% (4/5).

#### Скремблирование

В данном случае данные перед передачей объединяются с помощью исключающего ИЛИ с некоторой псевдослучайной числовой последовательностью. Это смешение делает данные столь же случайными, как и сама псевдослучайная последовательность, что также должно решить проблему последовательных нулей и единиц.

Приёмник проделывает аналогичные действия с поступающими данными. Для этого ему надо знать исходную псевдослучайную последовательность.

Однако можно специально подобрать такие данные, которые будут походи на эту последовательность, так что в результате применения XOR у нас получатся много нулей, и всё сломается.

### Виды модуляции

#### ASK: Amplitude Shift Keying

Чтобы представить 0 и 1, используются две различные амплитуды сигнала.

#### FSK: Frequency Shift Keying
Используются две или несколько различных частот.

#### BFSK: Binary Phase Shift Keying

Бинарная ("два символа") фазовая модуляция.

<a href="https://ibb.co/z4xwL3F"><img src="https://i.ibb.co/jrfFxCz/image.png" alt="image" border="0"></a>

Можно расширить идею и использовать большее количество сдвигов: например, с шагом в 90$\degree$, и получить **QPSK** -- Quadrature PSK -- квадратурную фазовую модуляцию.

#### Диаграммы созвездий

Все вышеперечисленные типы модуляций можно комбинировать и представлять их в виде диаграмм. Обычно комбинируются амплитудная и фазовая модуляция.

Точки на диаграммах представлены в полярных координатах. $(\rho, \varphi)$, где $\rho$ -- амплитуда, $\varphi$ -- фаза.

<a href="https://ibb.co/1Mj8KVW"><img src="https://i.ibb.co/W0jgF9J/image.png" alt="image" border="0"></a>

### Мультиплексирование

#### FDM: Frequency Division Multiplexing

Использует передачу в полосе пропускания, чтобы совместно использовать канал. Спектр делится на диапазоны частот, каждый пользователь получает исключительное владение некоторой полосой, в которой он может послать свой сигнал.

<a href="https://ibb.co/349dMTZ"><img src="https://i.ibb.co/hLJ9Zgz/image.png" alt="image" border="0"></a>

#### OFDM: Orthogonal FDM

Полоса канала разделена на многие поднесущие, которые независимо передают данные (например, с квадратурной амплитудной модуляцией). Поднесущие плотно упакованы вместе в частотной области. Таким образом, сигналы от каждой поднесущей простираются в смежные. Однако частотная характеристика каждой поднесущей разработана так, чтобы в центре смежных поднесущих это был ноль.

<a href="https://ibb.co/BfNtWDt"><img src="https://i.ibb.co/rQsm8Pm/image.png" alt="image" border="0"></a>

#### TDM: Time Division Multiplexing

<a href="https://imgbb.com/"><img src="https://i.ibb.co/dp34BL8/image.png" alt="image" border="0"></a>

#### STDM: Statistical TDM

Статистическое мультиплексирование

#### CDMA: Code Division Multiple Access

Каждый передатчик кодирует данные в виде прямого или инвертированного числового вектора. Все векторы, соответствующие каждым приёмникам, ортогональны и образуют базис.

<a href="https://ibb.co/mqK2Wdz"><img src="https://i.ibb.co/T8G73Jh/image.png" alt="image" border="0"></a>

Приёмник раскладывает полученную комбинацию сигналов по этому базису и находит, какое сообщение передаёт каждый из передатчиков.

## Защита от ошибок при передаче данных

Поскольку мы передаём данные через изначально неидеальную физическую среду, то возможно появление одиночных или множественных ошибок на уровне кадра. Эти ошибки необходимо уметь обнаруживать, и желательно исправлять. Для этого, понятное дело, необходимо применять специальные коды.

Будем считать, что ошибки носят случайный характер: от целенаправленного искажения данных при передаче защищают другие методы, например, криптографическое хеширование.

### Характеристики защитных кодов

- количество обнаруживаемых ошибок в защищаемой последовательности $d$ -- detection;
- количество исправляемых ошибок в защищаемой последовательности $c$ -- correction;
- минимальное количество ошибок, приводящих к отказу механизма защиты
- накладные расходы на реализацию механизма защиты

### Идея помехозащищённого кодирования

У нас есть отправитель, который отправляет исходные данные $D$ и добавляет к ним некоторый проверочный код $R$, который вычисляется применением некоторой функции $f$ к исходным данным: $$R = f(D)$$

Далее у нас есть некоторый ненадёжный канал $F$, который может исказить как исходные данные, так и проверочный код: $$F(D, R)=D', R'$$Получатель, в свою очередь, получает *потенциально искажённые* данные $D'$ и *потенциально искажённый* проверочный код $R'$. Он у себя вычисляет проверочный код: $$R''=f(D')$$И если $R' = R''$, то мы считаем данные верными.

Однако идеального решения нет. Существует вероятность того, что при $D\neq D'$ будет выполнено $R'=f(D')$, особенно, если искажение данных носит целенаправленный характер.

Однако при *случайном* характере изменений можно построить коды, определяющие и исправляющие искажение данных *с заданной вероятностью*.

### Базовые положения теории кодирования

**Расстояние** для последовательностей $a$ и $b$ равно количеству бит, которые нужно поменять, чтобы из $a$ получить $b$.

**Расстояние Хемминга** для кода -- минимальное расстояние между любой парой кодовых слов.

Известны следующие утверждения из теории кодирования:

**Утверждение 1**. *Для кода с расстоянием Хемминга $h$ всегда можно обнаружить $h-1$ ошибку:* $$c\geq h-1$$**Утверждение 2**. *Для кода с расстоянием Хемминга $h$ всегда можно исправить $\left[\frac{h-1}{2}\right]$ ошибок*: $$d\geq\left[\frac{h-1}{2}\right]$$


Например, для простого повтора: $$\begin{cases}0\to00\\1\to11\end{cases}:\begin{cases}h=2\\d=1\\c=0\end{cases}$$А для мажоритарного кода: $$\begin{cases}0\to000\\1\to111\end{cases}:\begin{cases}h=3\\d=2\\c=1\end{cases}$$

### Основные методы обнаружения ошибок (EDC: Error Detection and Correction)

#### Бит чётности

Сложение по модулю 2 всех битов исходной последовательности.  

|$h$|$d$|$c$|$e$
|--|--|--|--|
$2$ | $1$|$0$|$\frac{\vert D\vert}{\vert D\vert + 1}$

Позволяет обнаружить *нечётное* количество ошибок.

#### Контрольная сумма

Существует множество подходов к тому, как считать контрольную сумму. Основная идея -- сформировать проверочную последовательность *меньшей* длины, чем исходная, используя сравнительно простой набор операций.

При этом бит чётности по сути тоже контрольная сумма.

Контрольная сумма также применяется как общее понятие для всех EDC (Error Detection Codes) и ECC (Error Correction Codes)

Контрольная сумма применяется в протоколах IP, TCP, UDP и других.

Например, рассмотрим алгоритм контрольной суммы для заголовка IPv4:

**Генерация**

1. Разбиваем сообщение на блоки по 16 бит, при необходимости дополняем нулями
2. Блок контрольной суммы заполняем нулями
3. Выполняем суммирование 16-битных слов
4. Если получаем переполнение, то суммируем результат с переполнением
5. Инвертируем результат
6. Помещаем результат на место контрольной суммы в сообщении

**Проверка**

1. Разбиваем сообщение на блоки по 16 бит
2. Выполняем суммирование всех 16-битных слов сообщения, в том числе контрольной суммы
3. Если получаем переполнение, то суммируем результат с переполнением
4. Инвертируем результат
5. Если получили 0, то считаем, что получили корректное сообщение

|$h$|$d$|$c$|$e$
|--|--|--|--|
$2$ | $1$|$0$|$\frac{\vert D\vert}{\vert D\vert + 16}$


Контрольная сумма для заголовка IPv4 позволяет обнаруживать до 16 подряд идущих ошибок.

### CRC: Cyclic Redundancy Check: Циклический избыточный код

Использует вычисление в конечном поле, определяемом некоторым порождающим многочленом (генератором).

Это так называемый **полиномиальный код**. В основе полиномиальных кодов лежит представление битовых строк в виде многочленов с коэффициентами, равными только 0 или 1. Кадр из $k$ бит рассматривается как список коэффициентов многочлена степени $k-1$, состоящего из $k$ членов от $x^{k-1}$ до $x^0$. Старший (самый левый) бит кадра соответствует коэффициенту при $x^{k-1}$, следующий бит -- коэффициенту при $x^{k-2}$ и т.д.

С данными многочленами осуществляются арифметические действия по модулю 2 в соответствии с алгебраической теорией поля. При этом перенос при сложении и заём при вычитании не производится. И сложение, и вычитание эквивалентны исключающему ИЛИ (XOR).

Деление чисел осуществляется в точности так же, как и деление обычных двоичных чисел, с той разницей, что вычитание производится снова по модулю 2. 

При использовании циклического кода отправитель и получатель должны сначала договориться насчёт **образующего многочлена** $G(x)$. К этому многочлену предъявляются следующие требования по обнаружению ошибок:
- одиночные ошибки, поэтому $x^k$ и $x^0$ должны иметь ненулевые коэффициенты
- ошибки с двумя битами, поэтому многочлен должен быть как минимум степени 3
- нечётное количество ошибок, так что многочлен должен содержать множитель $(x+1)$
- "взрывные" (burst) ошибки -- ошибки в некоторой последовательности бит

Для вычисления CRC для некоторого кадра из $m$ юит, соответствующего полиному $M(x)$, необходимо, чтобы этот кадр был длиннее образующего многочлена. Идея состоит в добавлении CRC в конец кадра таким образом, чтобы получившийся многочлен белился на образующий многочлен $G(x)$ без остатка. Получатель, приняв кадр, содержащий контрольную сумму, пытается разделить его на $G(x)$. Ненулевой остаток от деления означает ошибку.

Алгоритм вычисления CRC при этом может быть следующим: 

1. Пусть $r$ --  степень многочлена $G(x)$. Добавим $r$ нулевых бит в конец кадра так, чтобы он содержал $m+r$ бит и соответствовал многочлену $x^r M(x)$.
2. Разделим по модулю 2 битовую строку, соответствующую многочлену $x^r M(x)$, на битовую строку, соответствующую образующему многочлену $G(x)$
3. Вычтен по модулю 2 остаток от деления (он должен быть не более $r$ бит) из битовой строки, соответствующей многочлену $x^r M(x)$. Результат и будет передаваемым кадром, который мы будем называть многочленом $T(x)$.

Должно быть очевидно, что многочлен $T(x)$ делится по модулю 2 на $G(x)$ без остатка.

# Ethernet


### Задачи 802-2001
- Определяются основные понятия (LAN, MAN и т.п.) и общие требования к ним
- Вводит понятие основных коммуникационных устройств: повторителей, коммутаторов и т.п.
- Референсная сетевая модель, использующаяся для описания в т.ч. Ethernet
- Задачи основных уровней
- Принципы управления сетевыми инфраструктурами
- Универсальная адресация -- MAC-адреса.
- ...

### Референсная модель


<a href="https://ibb.co/2NHPLhx"><img src="https://i.ibb.co/k1v0rBj/image.png" alt="image" border="0"></a>

Она, по сути, маппирует физический уровень и уровень Data Link из модели OSI, рассматривая их более подробно, а всё, что выше, в терминологии референсной модели, -- это протоколы более высокого уровня (Upper Layer Protocols).

В свою очередь, канальный уровень (Data Link) модели OSI в референсной сетевой модели распадается на два подуровня: LLC и MAC. Каждый из уровней взаимодействует со своими соседями через некоторые интерфейсы, которые мы называем точками доступа -- Service Access Point. У нас есть соответствующие SAP для физического уровня (PhSAP), для MAC (MSAP), LLC и так далее.

Комитет 802 как раз занимается именно этими уровнями. Всё, что выше, -- прерогатива RFC.

### SAP -- Service Access Point (точка доступа к сервису)

**LSAP** -- интерфейс для протоколов верхнего уровня к сервисам уровня LLC

**MSAP** -- доступ к сервисам уровня MAC для LLC, определяется 
- **одним** МАС-адресом для получения и передачи данных (один персональный unicast адрес у устройства)
- одним широковещательным адресом для получения данных (мы можем получать данные на широковещательный адрес, но **отправлять** с него нельзя)
- одним или несколькими групповыми адресами для получения данных (у конкретного абонента может быть ноль несколько multicast адресов для **получения** данных, отправлять с них нельзя)

### LLC -- Logic Link Control (управление логическим каналом)

Определяет три типа функционирования коммуникационной инфраструктуры, предоставляющей сервисы для протоколов верхнего уровня
- без установления соединения и подтверждений -- классический режим best efforts
- с установлением соединения (восстановление после ошибок и управление): прежде чем начать передать данные, устанавливаем соединение
- без установления соединения с подтверждением (восстановление после ошибок, очередность доставки, запрос данных)


В классическом Ethernet работает самый простой режим из возможных -- без установления и подтверждений. Поэтому если оборудование не может передать кадр дальше, то этот кадр отбрасывается и мы об этом ничего никому не сообщаем. Поэтому все механизмы надёжной передачи данных должны обеспечиваться за счёт протоколов более высокого уровня (Upper-layers protocols).

## MAC -- Medium Access Control

Управление доступом к среде. На этом уровне определяется некоторый функционал, связанный с тем, в каком виде передаются данные:

- разделение на кадры и обнаружение кадров
- адресация узлов получателей данных (как выглядит адрес)
- передача информации об отправителе данных
- прозрачная передача данных уровня LLC
- защита данных от ошибок в процессе передачи. Тут появляется понятия FCS --  frane check sequences -- проверочные последовательности или коды для кадра
- управление доступом к физической среде передачи данных

Сюда же потенциально относятся вопросы управления потоком данных между конечными и промежуточными устройствами.

### Физический уровень

Отвечает за способность получать и передавать биты данных между двумя сущностями. Отвечает за модуляцию сигнала.

На практике часто происходит агрегация более крупных информационных последовательностей (4, 5, 8 бит) в другие информационные последовательности, передаваемые через физический интерфейс.

### Универсальный адрес

Он представляет собой 6 октетов.

<a href="https://ibb.co/646KTFd"><img src="https://i.ibb.co/30txjcJ/image.png" alt="image" border="0"></a>

В рамках этих октетов определяется последовательность бит в зависимости от сетевой инфраструктуры и технологии: например, режимы передачи (LE и BE) в Ethernet и Token Ring отличаются.

Однако важно, что первые три октета позволяют узнать некоторую специфичную информацию о производителе устройства (OUI: Organizationally Unique Identifier) либо по нему мы можем понять, что этот кадр какой-то специфический с точки зрения функционала и используемых механизмов адресации. Например, для мультикаст аресов этот адрес OUI будет адресоваться специальным образом.

Плюс есть группы специальных адресов, которые говорят о том, что мы работаем с какими-то специальными пакетами со специальными режимами адресами.

Например, код 01-80-C2-... говорит о том, что это некоторый специализированный адрес.

Ещё один момент -- интерпретация двух младших разрядов в нулевом октете. По этим разрядам можно понять, к какому классу адресов относится адрес.

Первый признак -- I/G (универсальный или групповой адрес): 0 = I, 1 = G.

Второй признак -- универсальный или локальный адрес (U/L): 0 = U, 1 = L. Адрес был назначен при момощи какого-то механизма (не описывает конкретную индивидуальную систему и не назначен производителем -- это локальный адрес). Если адрес описывает конкретную систему и имеет контекст не только в конкретной сети, но и при переносе в другую инфраструктур этот адрес сохранится -- это универсальный адрес.

В Ethernet адреса передаются с младших разрядов (LSB: Less Significant Bits).

### Группа стандартов 802.1: BRIDGING & MANAGEMENT

Здесь существует довольно много стандартов, некоторые из них особенные:
- IEEE 802.1Ax-2008: ... Link aggregation: тут описаны механизмы агрегации каналов
- IEEE 802.1X: Port-based network-access controle: решаются вопросы аутентификации абонентов при подключении к сети, решение можно принять, например, на основании того, находится ли адрес устройства, которое хочет подключиться, в списке разрешённых, или а основании логина/пароля или цифрового сертификата.

## Базовый формат кадра Ethernet (Ethernet II  / Ethernet DIX)

<a href="https://ibb.co/1R4jJGK"><img src="https://i.ibb.co/xzrd8qG/image.png" alt="image" border="0"></a>

Стандартом предлагается выделить две сущности: более общую сущность **пакет** и более детальную сущность того, что происходит на канальном уровне, -- **кадр**.

Пакет состоит из нескольких частей: кадра, который несёт в себе сформированные на сетевом уровне данные и плюс служебные сигналы в начале и потенциально в конце пакета.

Сигнальная информация в начале состоит из **преамбулы** и **start frame delimiter**. Преамбула -- это просто последовательность единиц и нулей (10101010 ... 10101010), цель которой -- стабилизация и синхронизация передачи данных. Нарушение этой последовательности -- маркер начала кадра 10101011.

После них передаётся основной кадр, который состоит из нескольких частей. В нём есть заголовок из 3 частей и некоторые пользовательские данные, которые инкапсулированы внутрь ethernet кадра (MAC CLIENT DATA), а также некоторый трейлер из блоков FRAME CHECK SEQUENCE и опционально блока PADDING, который заполняет кадр до минимально допустимого размера.

В Ethernet данные передаются начиная с младших разрядов.

В заголовке у нас три поля -- адрес назначения, адрес источника (MAC-адреса), причём адрес получателя идёт первым, чтобы можно было применять технологию cut-through.

Последнее поле заголовка -- поле длины или типа.

### Поле EtherType

Значение этого поля интерпретируется в зависимости от того, в каком диапазоне оно лежит.
- если <= 1500 ⇒ воспринимается, как размер пользовательских данных (MAC Client Data)
- если > 1500 ⇒ определяет тип протокола верхнего уровня
	- 0x0800 -- IPv4
	- 0x0806 -- ARP
	- 0x8100 -- IEEE 802.1Q frame
	- 0x86DD -- IPv6
	- ...

### Максимальный размер пользовательских данных

В современном стандарте Ethernet размер поля MAC CLIENT DATA может сильно варьироваться. В старых версиях это было от 46 до 1500 октетов; в 802.1Q -- 1504 октета, а в некоторых технологиях, например, Jumbo Frames этот размер может быть ещё больше.

**Штатный размер** -- 1500 октет.

Расширенный формат пакета для упаковки дополнительных префиксов и суффиксов протоколов верхних уровней (например, MPLS) могут раздувать размер до 1982 октет.

### Поле выравнивания до минимального размера кадра

PAD = $\max(0, \mathtt{minFrameSize - clientDataSize + 2\times addressSize + 48})$, где $\tt minFrameSize = 512$

### Frame Check Sequence

Используется алгоритм CRC-32.

Дан полином $$G(x)=x^{32}+x^{26}+x^{23}+x^{22}+x^{16}+x^{12}+x^{11}+x^{10}+x^8+x^7+x^5+x^4+x^2+x$$

Берётся дополнение от первых 32 бит кадра. 

$n$ битов защищаемого поля принимаются за коэффициенты полинома $M(x)$ степенью $n-1$ (Первый бит поля адреса отправителя принимается за коэффициент при $x^{n-1}$, а последний бит поля пользовательских данных (или поля выравнивания) соответствует $x^0$).

$M(x)$ умножается на $x^32$ и делится на $G(x)$, в результате чего получаем остаток от деления $R(x)$ со степенью $\deg R \leq 31$. Коэффициенты $R(x)$ принимаются за 32 битную последовательность, дополнение от которой является CRC.

### Поле расширения (EXTENSION)

Применяется только в гигабитных сетях в полудуплексном режиме, чтобы кадр соответствовал минимальной длине уже для гигабитных скоростей (меньше 4096 бит, так что EXTENSION может содержать до 4096 - 512 = 3584 бит)

### Inter Frame Gap

Между кадрами есть некоторые пропуски: мы их отделяем друг от друга некоторыми пропусками, размер которых зависит от конкретной сетевой инфраструктуры.

|||
--|--
Стандартный 10М | 96 бит
1G | 64 бит
10G | 40 бит


## Алгоритм работы прозрачного моста 

Здесь уже речь идёт о связи инфраструктур через некоторое коммутирующее устройство, например, коммутатор, который по сути является мостом.

Этот алгоритм описывается стандартом IEE 802.1D-2004.

Любой порт на любом мосте в соответствии с этим алгоритмом имеет три базовых состояния:
- discarding -- порт не работает, все приходящие на него сообщения он откидывает
- learning -- промежуточное состояние: порт данные не продвигает, но может запоминать адреса абонентов, которые подключены к данному порту
- forwarding -- нормальное состояние передачи данных через порт


У любого коммутатора есть таблица продвижения (или FDB: Forwarding Database), которая ставит в соответствие номера портов и МАС-адреса клиентов, которые с этих портов доступны. Мост обучается конфигурации сети, постоянно обновляя эту таблицу.

<a href="https://ibb.co/jRR3qyV"><img src="https://i.ibb.co/JQQr8vx/image.png" alt="image" border="0"></a>

Всё начинается с того, что к нам приходит кадр, и мы должны решить, что с этим кадром делать дальше. Для начала надо посмотреть на то, кто является источником (Source) кадра и кому он адресован (Destination). Анализ этих признаков называется **применением активной топологии (Active Topology Enforcement)** -- это подпрограмма, которая принимает решение на основании Source и Destination о том, продвигать ли кадр дальше.

### Active Topology Enforcement
1. Порт, на который получен кадр, находится в состоянии продвижения (Forwarding) и
2. Порт, который рассматривается как порт назначения, находится в состоянии продвижения (Forwarding), и
3. Порт, который рассматривается как порт назначения, не является портом, на который получен кадр, и
4. Размер кадра (данных, передаваемых по сети / mac_service_data_unit) не превышает размер кадра, поддерживаемый сетью, подключённой к порту, рассматриваемому в качестве порта назначения: разные сегменты сети могут поддерживать разные размеры передаваемых данных. И в каком-то сегменте может быть поддержка гигантских кадров размерами до 9К, а в другом сегменте -- нет. 

> **Коммутаторы фрагментацией не занимаются, это дело сетевого уровня -- этим может заниматься маршрутизатор**


Если пришёл кадр, для которого в соответствии с FDB неизвестен порт назначения, его мы передадим на все порты в данном коммутаторе за исключением того порта, с которого он пришёл (аналог широковещательного сообщения).


---

Дальше мы смотрим на FDB, и там может быть фильтрация кадров (какие-то запреты или явные привязки к тому, что какой-то абонент должен быть обязательно на каком-то порту), и если мы этот кадр не отфильтровали, мы его помещаем в очередь на передачу.

При этом коммутатор может поддерживать несколько очередей: не все кадры могут быть равноправными, возможна их приоритизация, и в зависимости от приоритета кадр может быть помещён в ту или иную очередь.

Затем работает алгоритм выборки кадра из очереди по некоторой хитрой логике мы выбираем из наших очередей тот кадр, который должен быть передан в данный момент времени.

После этого мы по некоторым правилам можем изменить приоритет данного кадра по некоторым признакам (например, в 802.1Q). Следовательно, в кадре можно что-то поменять, и поэтому далее пересчитывается контрольная последовательность FCS и после этого мы передаём его в соответствующий порт.

### Алгоритм обучения коммутатора

Работает параллельно с алгоритмом прозрачного моста.

- Порт, получивший пакет, находится в состоянии обучения (Learning) или продвижения (Forwarding), и
- поле адреса источника кадра описывает конкретную конечную систему (то есть адрес не является групповым) **групповые адреса в FDB мы не сохраняем** и
- нет статических записей в таблице фильтрации, ассоциированной с этим МАС-адресом, в которой отображение портов определяет продвижение или фильтрации на данном порту, и
- результирующее количество записей в таблице фильтрации (FDB) не превышает максимально допустимого количества записей

При этом запись в FDB помещается не на постоянной основе: через некоторое время она удаляется, если она не подтверждается последующими кадрами.

При этом могут использоваться *теневые таблицы*: с какого-то моменты времени мы начинаем заполнять теневую таблицу (все новые записи будут помещаться и в старую, и в новую теневую таблицу), и в какой-то момент времени старая таблица просто заменится теневой, и заводится новая теневая таблица.

## Jumbo Frames

Начиная с некоторых современных стандартов сети, условно говоря, с гигабитного Ethernet, появилась возможность увеличить размер кадра 1.5К в несколько раз.

По сути, любой увеличенный размер кадра (то есть больше 1.5К) считается "гигантским". В классических стандартах Ethernet есть такие, которые модифицируют размер кадра, включая в него дополнительные поля, суффиксы и префиксы (например, 802.1Q), но мы не считаем их кадры гигантскими: это просто дополнения и расширения. Они всё равно не позволяют посылать пользовательские данные большего размера, поскольку MTU как был 1500 байт, так и остаётся -- на кадры просто навешивается дополнительная информация, не являющаяся пользовательской.

Когда мы говорим о современном Ethernet, и например, о сетевых технологиях, которые позволяют в рамках одной сети передавать данные с использованием разных технологий (например, **FCoE** -- Fibre Channel over Ethernet), то таким стандартом MTU (Maximum Transfer Unit) предполагается уже больше, равным 2500 октет, чтобы мы могли благополучно упаковать туда кадр Fibre Channel, который по размеру превышает 1500 октет.

Кроме того, **MPLS -- Multi Protocol Label Switching** тоже позволяет увеличить размер кадра до определённого количества бит, а именно 1518 + (n * 4) байт, где $n$ -- количество меток, но этот протокол мы в курсе не рассматриваем, а с точки зрения передаваемых пользовательских данных он их размер не увеличивает.

Здесь, за исключением FCoE, MTU не менялось. Однако при появлении сетей с большой пропускной способность появилось желание увеличить размер кадра: например, если увеличенный размер кадра понимает сетевая карта и на отправителе, и на получателе, и всё промежуточно сетевое оборудование тоже, то почему бы не отправлять больше? Соответствующая возможность появляется с помощью настроек соответствующих сетевых устройств.

### Целевые приложения для увеличенного размера кадра
- Server Clustering: чтобы не тратить полезный объём пропускной способности на дополнительные заголовки и между кластерами передаются большие объёмы данных
- Server Backups (larger MTUs permit faster backups): когда мы делаем копию состояния какого-то приложения, передаются большие объёмы данных
- high speed supercomputer interconnect (for data transfer, not messaging): это применимо именно для передачи данных. Когда мы используем сетевую инфраструктуру для обмена короткими сообщениями, например, для синхронизации каких-то переменных, в этом случае гигантский кадр ни к чему
- network file sevrer (NFS) protocol (9000 byte MTU to carry an 8192 NFS data bock): чтобы упаковать блок данных NFS размером в 8192 на канальном уровне, нам нужны гигантские кадры
- iSCSI SANs (9000 bytes to reduce the effect of TCP frame overhead): для сетей хранения данных, построенных поверх IP технологии
- FCoE SANs (2500 bytes to enclose an FC frame of 2000 bytes)

### Достоинства от увеличения размера кадра

Увеличив размер кадра, мы получаем больший эффект: у нас растёт пропускная способность сети и за счёт того, что мы посылаем меньшее количество кадров, а, следовательно, меньшее количество заголовков, нагрузка на обработку этих кадров снижается (снижается загрузка CPU на обработку этих сетевых заголовков).

<a href="https://ibb.co/cvYMQCL"><img src="https://i.ibb.co/n0PZjnC/image.png" alt="image" border="0"></a>

Несмотря на то, что все эти картинки довольно древние, всё это применимо и к современным сетям.

### Затраты на заголовок по отношению к полезным данным

<a href="https://ibb.co/XzTSbBM"><img src="https://i.ibb.co/dQyGr9x/image.png" alt="image" border="0"></a>

На примере протокола iSCSI, где идёт довольно глубокая инкапсуляция (идут заголовки для Ethernet, IPv4, TCP, iSCSI) и только потом идут полезные данные. Если мы используем стандартный размер кадра, то получается, что только порядка 8 процентов идёт именно на заголовки, а полезных данных всего лишь 91.81%. Если мы размер кадра увеличили, то эффективность использования полосы пропускания увеличивается, так как теперь эти заголовки занимают меньше 1.5% от объёма кадра.

### Недостатки использования гигантских кадров

На текущий момент часть недостатков, например, неэффективность коммутаторов из-за повышенных требований к буферной памяти или неэффективность сетевых стеков под большой MTU, уже не играют роли, потому что многие современные коммутаторы и реализации сетевых протоколов уже учитывают то, что размер кадра может быть больше, чем стандартный.

Однако потенциально мы можем столкнуться с некоторыми аномалиями, поэтому, прежде чем внедрять какое-то решение, использующее увеличенные размеры кадра, нужно это решение протестировать -- а не пойдёт ли что-то не так при увеличении загрузки на инфраструктуру?

Тем не менее, по-прежнему остаются две проблемы:
- увеличение задержек
- требуется автоматическое определение MTU

Понятно, что раз размер кадра увеличивается, то другим приложениям, которые конкурируют за доступ к сетевой инфраструктуре, требуется больше времени в ожидании доступа к этому ресурсу. 

Последний момент -- поддержка гигантских кадров должна быть на всём оборудовании, и максимальный размер этого кадра зависит от возможностей оборудования: какие-то сетевые карты поддерживают 4К, какие-то 9, и если попытаться послать кадр размером 9К тому, кто такие кадры не принимает, то данные кадр будет отброшен соответствующим сетевым адаптером как некорректный. Поэтому надо выбрать минимально возможный поддерживаемый объём кадра из устройств в конкретной сети.

## Управление потоком данных

Необходим механизм самосинхронизации сетевых устройств: например, если в сети есть какой-то медленный участок, либо целевое устройство не способно воспринимать данные на высоких скоростях, либо оно очень нагружено и не может обработать вовремя весь получаемый им поток данных. Таким образом, если получающее устройство не может обработать приходящий к нему поток данных, отправляющее устройство должно притормозить и передавать данные менее интенсивно.

Подобные механизмы могут работать на разных уровнях: например, в TCP, в новых версиях IP, но эту задачу можно попытаться решить и на канальном уровне. В современных реализациях Ethernet, который работает в ЦОД (со скоростями 10G и выше, его ещё называют Lossless internet) эти проблемы тоже решаются.

Этот механизм появился ещё в ранних версиях Ethernet (при переходы 10М -> 100М) и называется **PAUSE-кадрами**. Эти сообщения позволяют приостановить передачу данных.

Таким образом, референсная модель несколько обогатилась и в неё добавился опциональный подуровень **MAC Control**.

<a href="https://ibb.co/Ltfz4Gp"><img src="https://i.ibb.co/ts5MydC/image.png" alt="image" border="0"></a>

### Структура MAC Control кадра

У нас появилась возможность послать специальный пакетик -- MAC Control, в котором мы можем закодировать служебное сообщение нашему соседу о том, что мы чего-то от него особое хотим.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/4MLwJhL/image.png" alt="image" border="0"></a>

#### Содержимое PAUSE-кадра

- DA: unicast (можем послать конкретному получателю), broadcast (попросить замолчать всех), 01-80-c2-00-00-01 (этот адрес специально зарезервирован и указывает на соседнее устройство, дальше чем за соседа этот кадр распространяться не будет)
- SA: unicast
- Len/Type: 88-08
- MAC Control OpCode: 00-01
- Param: 512 / скорость интерфейса (этот параметр указывает, на сколько времени нам надо остановиться и замолчать, ничего не передавая)

На самом деле MAC-Control, который был придуман в 100-мегабитном Ethernet, ни для чего другого, кроме как посылки PAUSE-кадров, не использовался. Этот кадр -- обычный кадр Ethernet, в поле Len/Type которого указано число 88-08.

Посылая такие PAUSE-кадры один за другим, мы можем продлять время замалкивания, чтобы справиться с соответствующей нагрузкой.

Идея хорошая, однако получилось так, что этим механизмом в современных сетях практически не пользуются. Он есть, про него почти никто не знает, его даже можно включить, однако последствия посылки таких кадров непредсказуемы. 

#### Недостатки

Основной недостаток в том, что мы блокируем абсолютно *весь* трафик на некоторое время. Мы не можем выполнить приоритизацию трафика и выбрать, какой трафик блокировать: на конечном узле может работать большое количество разных приложений, и среди них могут быть такие, трафик от которых блокировать мы не имеем права, поскольку они критичные для нас, а есть, наоборот, такие, которые мы можем смело заблокировать без особенных последствий.

Ситуация усугубляется, если сеть сложная, и, например, один коммутатор начинает другому соседнему коммутатору посылать эти PAUSE-кадры. Поэтому такой механизм был первой попыткой реализации управления потоком данных на канальном уровне, но он был неудачным, потому что мы блокируем всё без возможности выбора.

### Решение

В современном Ethernet используются специальные механизмы:
- 802.1Qaz: Priority groups: разделение трафика по некоторым группам приоритетов
- 802.1Waz: DCB Exchange Control: обмен настройками между некоторыми устройствами
- 802.1Qau: Congestion Notification: оповещение о перегрузках
- 802.1Qbb: Priority-based Flow Control: приоритизация в управлении потоком передаче данных

Эти решения применимы в современных сетях уровня ЦОД (10Гбит/c и выше). За счёт этих механизмов теперь можно обеспечить **гранулярную** приостановку передачи данных: мы блокируем не всё, а только часть трафика из определённой группы.

### Приостановка трафика группы с определённым приоритетом

<a href="https://ibb.co/LtGKNp8"><img src="https://i.ibb.co/pzmqhXx/image.png" alt="image" border="0"></a>

Теперь у нас есть возможности выделить разные группы трафика -- очереди. Есть очереди с высоким приоритетом, а есть очереди с низким приоритетом. И трафик, который попадает в низкоприоритетную очередь, мы можем взять и заблокировать. В результате часть пропускной способности мы спасём, например, заглушив устройство, которое посылает много данных, но с низким приоритетом, но высокоприоритетный трафик по-прежнему будет проходить.

На уровне ЦОДов такие механизмы используются повсеместно, однако в локальных сетях они не применяются, и управление потоком передачи данных в обычных сетях реализуется не на уровне Ethernet, а протоколами более высокого уровня -- как правило, транспортного.


## Autonegotiation Link Parameters

Если в сети имеются устройства, которые могут работать на разных скоростях (одна и та же сетевая карта в принципе может работать на скоростях 10М, 100М и 1G и в полнодуплексном и даже полудуплексном режиме), то сетевые технологии позволяют им договориться о том, в каком режиме им работать: в зависимости от того, что может наше устройство, и что может соседнее устройство, мы переходим в максимально возможный режим работы. При этом различные режимы работы электрически несовместимы: так используются разные модуляции, разные способы кодирования сигналов и так далее, поэтому в начальный момент времени устройства должны договориться, в каком режиме они работают и только после этого непосредственно приступить к работе. Причём договариваться надо именно на физическом уровне.

Чтобы эти механизмы заработали, надо было добавить некоторые изменения в стандарт.

<a href="https://ibb.co/0MZMLSm"><img src="https://i.ibb.co/jMGMY2b/image.png" alt="image" border="0"></a>

На этой картинке показана эволюция стандартов с точки зрения референсной сетевой модели в сетях 10BaseT -- передача данных по витой паре на скоростях до 10Мбит/с, 100BaseT и 1000BaseT. Видно, что на физическом уровне появляются прямоугольнички *AutoNeg* (в 10М системах такой необходимости не было). В 100М сетях такой механизм был опционален (хотя на самом деле он есть везде), а в гигабитных он обязателен, без него сеть работать не будет. При этом в гигабитных сетях этот механизм стал чуть более высокоуровневым, но на самом деле функционал остался по сути тем же самым.

### NWay алгоритм

Механизм автосогласования работает за счёт NWay алгоритма. Он позволяет согласовать
- скорость соединения
- дуплексность соединения
- для гигабитных сетей выбор для конечных устройств режиме управляющий/управляемый (master/slave) для того, чтобы мы могли правильно кодировать данные: так как в таких сетях по кабелю данные передаются в обе стороны, схема модуляции чуть сложнее и включает в себя понятия ведущий/ведомый
- обратно совместим с механизмом проверки целостности канала **Link Integrity Test** 10М-сетей, если сеть не понимает, что такое автосогласование
- включает механизм получения, обработки и передачи NLP-сигналов (**Normal Link Pulse**).

### Fast Link Pulse vs Normal Link Pulse

Механизм NLP предназначен для того, чтобы проверять, что устройство не отвалилось, если оно не передаёт данные, а живо, но просто молчит. 

<a href="https://ibb.co/zh7cdXw"><img src="https://i.ibb.co/C5MdLbF/image.png" alt="image" border="0"></a>

С помощью этих импульсов можно как раз закодировать возможности автосогласования. Вместо одиночных импульсов передаются несколько импульсов подряд в течение 2мс, и эти импульсы образуют некоторое кодовое слово. Старые устройства, которые не понимают FLP, будут воспринимать такие сигналы как NLP, а новые -- как предложение о согласовании параметров.

### FLP Burst

<a href="https://ibb.co/tqWsR47"><img src="https://i.ibb.co/K23qnXM/image.png" alt="image" border="0"></a>

Эта кодовая последовательность состоит из 33 импульсов. Из них
- 17 нечётных используются для синхронизации
- 16 чётных передают управляющие данные. При этом 1 кодируется как наличие импульса, а 0 -- как его отсутствие.

### Base link code word

<a href="https://ibb.co/vZjw6Jh"><img src="https://i.ibb.co/SR3s4Kc/image.png" alt="image" border="0"></a>

Кодовое слово стоит из заголовка (selector field), в котором кодируется номер стандарта, по которому мы работаем, а дальше мы кодируем наши возможности, устанавливая единичку в соответствующем бите поля Technology ability field.

Плюс есть специальные дополнительные флажки, которые могут использоваться для подтверждения того, что мы увидели от соседа соответствующий с гнал (Ack), и то, что мы можем послать признак того, что после этого кодового слова может идти следующая страница с дополнительными возможностями (NP). Например, в следующей странице будет закодирована информация про гигабитные сети.


### Алгоритм работы NWay
1. Получение минимум 3 одинаковых сигналов FLP последовательностей
2. Выбор наиболее приоритетной технологии, поддерживаемой обоими устройствами
3. Передача FLP последовательности с установленным битом подтверждения 6-8 раз, чтобы сосед наверняка нас услышал
4. Перевод интерфейса в согласованный режим

### Проблемы с несоответствием параметров соединения

- Соединение не устанавливается при несовпадении скоростных режимов работа, так как используются отличные параметры сигналов на физическом уровне
- Соединение может установиться при статической конфигурации на одном/обоих концах при рассогласовании режимов дуплексности
	- потеря кадров от полнодуплексного абонента к полудуплексному при коллизиях
	- повторная передача в обратном направлении при коллизиях

Поэтому автосогласование полезно, так как нам не надо ничего настраивать руками.

# ARP: Address Resolution Protocol

Используется для того, чтобы связать IP-адреса с MAC-адресами. При этом при создании протокола предполагалось, что он сможет связать адреса канального уровня любого протокола с адресами сетевого уровня тоже любого протокола. Но сегодня мы используем ARP только для связи Ethernet адресов с адресами IPv4. В IPv6 будут работать несколько другие механизмы.

Основной стандарт -- **RFC 826**. Плюс есть стандарты **RARP -- Reverse ARP** (RFC 903) и **IARP -- Inverse ARP** (RFC 2390).

## Формат ARP-пакета

Цель: узнать адрес соседа. Если мы хотим узнать адрес соседа, то мы должны спросить его у всех устройств, так как в Ethernet нет какого-то централизованного регистратора (хотя, например в Fibre Channel он есть: там есть некий сервер имён, куда мы можем обратиться и узнать необходимые нам адреса). Поэтому обычно мы используем широковещание.

<a href="https://ibb.co/wydwPMK"><img src="https://i.ibb.co/WnHPMgc/image.png" alt="image" border="0"></a>

Мы посылаем запрос и ожидаем ответ от того устройства, чей IP -адрес мы спрашиваем. От имени владельца никто другой при штатной настройке отвечать не будет. 

Поэтому формат пакета простой: мы задаём интересующий нас адрес **THA -- Target Hardware Address** устройства с IP-адресом **TPA**, здесь же мы сообщаем IP-адрес отправителя **SPA**, свой МАС-адрес **SHA**. Раз мы спрашиваем THA, то обычно это поле не заполняется.

Остальные поля в заголовке дают потенциальную универсальность протокола. Например, в поле **HTYPE** указывается тип протокола, который работает на канальном уровне, а в **PTYPE** указываем тип протокола, который работает на сетевом уровне. В зависимости от этих типов потенциально могли использоваться ещё и адреса переменной длины, поэтому дополнительно указывается длина адресов канального и сетевого протоколов **HLEN** и **PLEN**. Оставшееся поле **OPTYPE** кодирует тип операции -- запрос или ответ.

В стандартном случае эти поля имеют следующие значения:
- HTYPE -- Ethernet 0x0001
- PTYPE -- IPv4 0x0800
- OPTYPE
	- Request 0x0001
	- Reply 0x0002


### ARP запрос

Здесь показан типовой ARP запрос

<a href="https://ibb.co/0smNqwR"><img src="https://i.ibb.co/nP62rWN/image.png" alt="image" border="0"></a>

Мы посылаем широковещательный запрос, посылаем свой МАС-адрес и тип протокола ARP в Ethernet-пакете, а дальше идёт сам ARP-запрос.

Wireshark добавляет свою аналитику в квадратных скобках: этот пакет не gratuitous.

Если у нас в сети есть хост, адрес которого мы запрашиваем, он нам ответит реплаем. Если такого хоста нет, нам никто не ответит, и, послав несколько таких запросов мы понимаем, что соседа у нас нет или он не хочет с нами общаться и пообщаться с ним не удастся.

### ARP ответ

Ответ адресный: тут уже нет никакого broadcast.

<a href="https://ibb.co/KGxprbs"><img src="https://i.ibb.co/DbfHRzM/image.png" alt="image" border="0"></a>

Интересующий нас ответ будет находиться в первом поле -- sender MAC address.

Получая ответ, мы заносим у себя в ARP-кеш связку IP-адрес:MAC-адрес на какое-то время.

### Gratuitous ARP

<a href="https://ibb.co/fYhTKhT"><img src="https://i.ibb.co/DDxj6xj/image.png" alt="image" border="0"></a>

В данном случае устройство запрашивает свой же IP-адрес. Этот механизм позволяет проверить, не занят ли наш IP-адрес каким-то другим устройством -- это нормальная ситуация, когда мы подключаемся к сети и в сетевых настройках у нас уже прописан какой-то IP и мы хотим начать его использовать. Но в сети IP-адреса не должны дублироваться -- они назначаются программно, и возможны ошибки конфигурирования. Если кто-то уже использует наш IP, то надо использовать другой IP.

Такая проблема возникает как при статической конфигурации, так и при использовании DHCP: там может быть конфликт при выдаче IP-адресов.

На самом деле в современных сетевых стеках мы не указываем Sender IP, и там будут все нули: то есть он может быть, а может и не быть. Это идеологически понятно: вроде как мы ещё не проверили, имеем ли мы право использовать этот IP-адрес, а мы уже используем его как Sender IP.

Обычно мы посылаем 2 или 3 таких сообщения. Если ни на одно из них ни пришёл ответ, мы можем использовать свой IP.


## Проблемы безопасности

Потенциальные атаки -- ARP-Spoofing/ARP-Poisoning^
- Заполнение FDB коммутаторов ложной информацией. 
	- возможен перевод коммутатора в режим концентратора при переполнении таблиц коммутации/продвижения (на современных устройствах всё лучше, потому что есть циклические буферы, или можно просто заблокировать порт, с которого приходит слишком много таких сообщений)
	- возможно перенаправление трафика на другой порт для его перехвата
	- DOS атака на конечные системы посредством коммутатора
- Заполнение ARP-кэша конечной системы ложной информацией
	- DOS атака на систему
	- перенаправление и перехват трафика от атакуемой системы

С этим можно бороться, просто не пуская в сеть какие-то левые устройства или мониторя сетевой трафик

### Защита от атак на уровне ARP протокола

- ротация таблиц коммутации в режиме циклического буфера
- ограничение на количество МАС адресов на клиентский порт
- отключение неиспользуемых портов коммутатора
- статические записи в FDB и ARP-кэше
- аутентификации при подключении к сети (802.1Х) + антивирусы и antimalware на конечных узлах.

При этом современные ОС не заносят данные в  ARP-кеш в пассивном режиме: если нам приходит ARP-ответ от хоста, о котором мы не спрашивали, то правильная ОС эти данные заносить не будет.


### ARP и IPv6

В IPv6 протокол ARP не используются. Там работает механизм **NDP** -- механизм обнаружения соседних узлов. При этом проблемы безопасности по сути остаются те же самые.

**SNDP** -- Secure Neighbor Discovery Protocol решает эти проблемы, но под него гораздо сложнее настраивать сетевые инфраструктуры.

# Дополнительные сервисы канального уровня для сетей Ethernet

## Простые сервисы

### Типы Ethernet-коммутаторов

#### По управляемости
- неуправляемые (unmanaged) -- мы не можем повлиять на функционирование устройства
- управляемые (managed) -- предоставляют какие-то хитрые сервисы, и позволяют их настройку и изменение

#### По типу поддерживаемых физических интерфейсов
- с фиксированной архитектурой
- с гибкой архитектурой (использование заменяемых трансиверов)


#### По предоставляемым сервисам
- L2 (Layer 2) -- сервисы канального уровня
- L3 (Layer 3) -- сервисы сетевого уровня. По сути являются маршрутизаторами
- L3+ (иногда обозначаются как L4 или L5). Предоставляют сервисы, работающие на транспортном  и даже прикладном уровне: например, NAT (NAPT), Firewall и так далее


### Способы управления коммуникационными устройствами
#### Командный интерфейс

Подключение через любой Ethernet-порт коммутатора или через специальный терминальный порт.

Используются протоколы Telnet (когда мы не беспокоимся о безопасности, Telnet ничего не шифрует) и SSH.

#### Веб-интерфейс

HTTP, HTTPS


#### SNMP: Simple Network Management Protocol

Это протокол прикладного уровня. Стандарт описывает сетевой протокол, схемы базы данных с конфигурациями, а также набор и структуру объектов данных, используемых при работе протокола.

Многие сетевые устройства его поддерживают и он является универсальным. Однако базовая версия протокола имеет проблемы с безопасностью, поэтому сегодня для управления его не используют, а используют в основном для мониторинга сетевого оборудования

#### Проприетарные приложения и протоколы

#### SDN (Software Defined Networks)

Там есть стандартные подходы для организации сетевых структур и управления ими.


### Зеркалирование трафика (Mirroring)

Мы можем настроить наше коммуникационное устройство таким образом, чтобы мы могли получить копию исходящего/приходящего трафика с заданного/на заданный порт или группу портов и переслать её на другой порт.

Например, если у нас есть проблемный хост, мы можем попросить пересылать весь трафик, который идёт на проблемный порт, на специальный назначенный для этих целей порт, на котором запущено какое-то приложение, которое этот трафик анализирует, например, Wireshark.

Типовые применения:
- troubleshooting
- отладка сетевых приложений в процессе разработки
- мониторинг трафика с целью обеспечения безопасности: например, системы обнаружения вторжений IDS Intrusion Detection System. Эта интеллектуальная система по определённым паттернам в трафике понимает, что например на веб-сервер идёт не стандартная типовая нагрузка, а его дудосят, или идёт сеанс перебора паролей, и может на это среагировать: например, заблокировать диапазон сетевых адресов, с которых идёт соответствующая атака.


Понятно, что эти IDS можно было бы поставить и на самом сервере, но анализ сетевого трафика может быть довольно затратным и сложным и сильно снизить производительность сервера и работы основного критичного приложения. Поэтому вместо этого мы настраиваем сетевое оборудование, предваряющее сервер, таким образом, чтобы весь трафик на сервер передавался ещё и на IDS, например, на другой машине.

### Фильтрация трафика

- отключение неиспользуемых портов -- это основное правило безопасности локальных сетей
- ограничение по МАС-адресам на то, какой МАС-адрес на каком порту может встречаться. Если мы видим какое-то новое сетевое устройство, и его адрес не соответствует тому, что мы ожидаем там увидеть, мы можем этот порт заблокировать
	- Эти правила могут быть статическими: администратор может внести соответствующие записи в таблицу фильтрации МАС-адресов на устройстве
	- либо можно динамически на портах, к которым подключаются клиентские системы, задать ограничение на то, что с заданного порта мы можем запомнить какое-то ограниченное число адресов, и никакие другие впоследствии не пускать.
	- когда мы видим не разрешённый МАС адрес, мы можем либо заблокировать весь порт, либо не пускать это сообщение дальше, либо послать специальное сообщение администратору
- Ограничение на количество пересылаемых кадров определённого типа -- защита от багов и вирусов, которые генерят широковещательные, групповые сообщения и сообщения с неизвестным адресом назначения -- а эти сообщения будут рассылаться по всем портам, кроме порта отправителя, что очень 
ресурсоёмко для коммутатора и для сети в целом. Поэтому может возникнуть желание количество таких кадров ограничивать
- Ограничение на пропускную способность порта, чтобы данный трафик не перегрузил сеть, потому что есть какие-то более важные по отношению к нему приложения

## VLAN

### Problem: flexible connectivity and hardware utilization

Типовая ситуация: в организации куча клиентов. Эти устройства можно разделить на несколько групп с условием, что устройство из одной группы может взаимодействовать с любым другим устройством из той же группы, но не могло взаимодействовать с устройствами из других групп. По сути, между устройствами надо организовать отдельные широковещательные домены -- отдельные изолированные сети. При это понятно, что при необходимости эти сети можно будет связать друг с другом при помощи маршрутизатора.

Классическое решение -- взять для каждой группы по отдельному коммуникационному устройству (коммутатору) и соединить каждое устройство с соответствующим коммутатором. Но если таких сетей много, то придётся закупать много коммутаторов. Более того, клиенты из одной группы могут располагаться в разных местах на довольно большом удалении драг от друга. 

Другое решение -- можно взять один большой физический коммутатор и сделать из него несколько логических коммутаторов. На уровне программного обеспечения этого коммутатора мы скажем, какие порты к какой группе принадлежат. Это сделать очень просто: понятно, что в таком случае у каждого логического коммутатора будут свои таблицы продвижения и какие-то управляющие структуры данных, но с точки зрения аппаратуры и логики самого коммутатора изменения будут минимальными. Такое решение называется **виртуальными локальными сетями**.

### Definition
- Logical, software defined subnetwork
- It allows similar devices on the network to be grouped together into one broadcast domain, irrespective of their physical location to the network

Естественно, что может возникнуть ситуация, когда мы в рамках одного коммутатора такую сетевую инфраструктуру с VLAN построить не сможем. Здесь возникает вопрос: как организовать связь клиентов из одной группы, но подключёнными к разным коммутатором?

Для этого можно соединить эти два коммутатора через свободный порт на каждом из них. Однако такое решение не масштабируемое, потому что чем больше коммутаторов, тем больше связей им будет необходимо, вплоть до того, что почти все порты на коммутаторах будут отданы под связи.

### Problem: can we do better?

Нам нужен признак того, что конкретный трафик принадлежит конкретной локальной сети. В таком случае надо менять формат кадра Ethernet на выходном порту коммутатора, который подключён к другому коммутатору, снабжая его некоторой меткой виртуальной сети. В свою очередь, коммутатор, на который приходит этот кадр, снимает эту метку и передаёт эту метку целевым устройствам в нужной подсети.

Такие метки называются **тегами**.

### VLAN: approaches

- in line with IEEE 802 standards... (единственный подход, который мы рассмотрим)
- some vendors can have proprietary technologies that solve same task or enhance standard approach

### Advantages

- move devices and people with minimal, or ever no, reconfiguration
- change device's broadcast domain and access to resources without physically moving the device
	- by software reconfiguration: a switch, a networks services (RADIUS etc)
	- by moving its cable from one switch port to another
- isolate parts of network from others by placing them in different VLANs 
- share devices and other network resources without losing data isolation and security
- direct broadcast traffic to only those devices which need to receive it to reduce traffic across the network
- connect 802.1Q-compatible switches together through one port on each switch

### IEEE 802.1Q

Virtual Bridged Local Area Networks
- define VLAN service: introduce some modifications in network devices behavioral (algos)
- define methods for traffic prioritization
- GARP VLAN registration protocol
- dynamic VLAN assignment
- interoperability VLAN and STP

### IEEE 802.1Q Tag

Изменяются кадры:

<a href="https://ibb.co/w7n89Rd"><img src="https://i.ibb.co/VxFb7tL/image.png" alt="image" border="0"></a>

Добавляется так называемый 802.1Q тег. Он вставляется в то место, где раньше было поле типа/длины. При этом фактически первые 16 битов в этом теге (**TPID**) как раз задают некоторый код, который раньше воспринимался как код типа-длины, и этот код всегда одинаковый (0х8100). С одной стороны, это очень неэкономно, а с другой -- это позволяет сделать такой механизм прозрачным для коммуникационных устройств, которые ничего про 802.1Q не знают и воспринимают этот TPID как некоторый хитрый тип вложения. После этого идут полезные 16 бит про VLAN, а затем те 16 бит, которые говорят о типе или длине того протокола, который был инкапсулирован в кадр Ethernet изначально.

Таким образом, размер пользовательских данных с точки зрения кадра Ethernet расширился с 1500 до 1504 октет. 

Кроме того, в этом же теге присутствуют **Tag Control Information**:
- **user priority** -- 3 bits, can be used by switch to determine QoS to apply to the frame
- **canonical format indicator** -- 1 bit, defines whether MAC addr is presented in the frame in canonical format (usually is 0 for the Ethernet)
- **VLAN Identifier (VID)** --  12 bits, uniquely identifies the VLAN  which the frame belongs to

### VID values

Value | Descr
--|--
0x000 | null-VLAN, there is no VLAN information in the tag, only user priority information is here
0x001 | Default VLAN, used for classifying frames on ingress through an untagged port
0x002 - 0xFFE | User defined VLANS
0xFFF | Reserved for future implementations

### Пример


<a href="https://ibb.co/bsskLqt"><img src="https://i.ibb.co/Byy9jdk/image.png" alt="image" border="0"></a>

При этом такой пакетик может быть виден не на всех системах: это зависит от ОС, сетевой карты, драйверов и так далее, которые могут удалять эти метки ниже, чем соответствующая библиотека перехвата трафика.

### VLAN tagging rules

- Except for mirror ports, each port must belong to at least one static VLAN. By default, a port is an untagged member of the default VLAN / By default, a port is not in any VLAN and do not forward any traffic
- A port can be untagged for zero or one VLAN. It transmits traffic for that VLAN without adding VLAN tag. Клиентские системы обычно находятся как раз за нетегированными портами
- A port can be tagged for zero or more VLANs. It transmits traffic for these VLANS with adding appropriate VLAN tag
- A port **cannot** be untagged and tagged for the same VLAN: если порт входит как нетегированный в VLAN 2, то он должен при передаче этого трафика этот тег снять. А если он тегированный, то наоборот, он должен передать трафик с установленным тегом.

### Problem: can we do even better?

Вся настройка этих тегов требует человеческого вмешательства. Хочется, чтобы коммутаторы сами договаривались о портах соединения двух коммутаторов, и когда клиент перемещается в другой порт, он динамически поменял своё членство в VLAN.

### VLAN types
- static: configurable "by hand"
- dynamic:
	- created by propagation VLAN configuration between switches (GVRP, MVRP etc)
	- created by propagation VLAN configurations due authentication / authorization process on the port (RADIUS etc)

#### non standard VLAN types

Can be defined by vendors as value added service.

Example AlliedTelesis:
- **Protected**: ports are unable to communicate with each other directly, however traffic from these ports can be routes to another VLANs
- **Private**: there are two kinds of ports: **private** and **uplink**. Private ports are unable to communicate with each other directly, if they are not in the same port group. However, they are able to communicatie with other devices in the network through uplink ports

### Dynamic VLAN information propagation: protocols
- GARP VLAN Registration Protocol
- Multiple VLAN Registration Protocol (заменил GARP в 2007 году)
- проприетарные протоколы от вендоров

При этом бывает такое, что и клиентские системы работают с тегированным трафиком, если им полезно быть одновременно в нескольких VLAN. Тогда клиентский порт можно тоже сконфигурировать как тегированный, и соответствующие теги сниматься на них не будут, следовательно, на конечное устройство будут приходить кадры с тегами. Сетевая карта на этом устройстве уже сама будет разбирать эти теги, определяя, из какого VLAN какой кадр пришёл и как с ним нужно взаимодействовать.

### Архитектура GARP (Generic Attribute Registration Protocol)

Это универсальный подход, который может использоваться для обмена некоторой информации (атрибутов) между устройствами. Поверх протокола GARP мы можем строить некоторые полезные нам сервисы, например, как в данном случае, VLAN Registration Protocol, но помимо этого может быть менее известный MRP -- GARP Multicast Registration Protocol, которая используется в инфраструктурах, где мы должны управлять процессом передачи Multicast сообщений.

У нас есть две базовых сущности -- 
- **GAP Participant**, то есть сущность, участвующая в обмене атрибутами. В данном случае GARP Participant'ом является отдельный порт на коммутаторе. 
- **GARP Application** -- мы можем развернуть приложение на порте Participant, и это приложение как раз и является, например, MRP. Это некоторая часть, которая содержит в себе атрибуты, которыми мы обмениваемся в рамках реализации какого-то полезного на механизма, например механизма обмена информацией о членстве в VLAN'ах.

<div align="center"><img src="https://i.ibb.co/fFTvNTj/image.png" alt="image" border="0"></div>

Взаимодействие между приложениями на разных участниках происходит при помощи механизмов **GIP: GARP Information Propagation**, а **GID - GARP Information Declaration** содержит в себе описания соответствующих атрибутов, и сами устройства, взаимодействуя через сетевую инфраструктуру протоколами ниже, обмениваются кадрами **GARP PDU**, в которые инкапсулируется вся управляющая информация.

### Архитектура GID

<div align="center"><img src="https://i.ibb.co/BnCszTd/image.png" alt="image" border="0"></div>

Он состоит из некоторого набора атрибутов и соответствующих им состояний.

### Структура GARP PDU
- Protocol ID (2 oct)
- Message
	- Attribute type (1 oct)
	- Attribute #1
		- attribute size
		- attribute event
		- attribute value
	-	...
	-	attribute #N
	-	end of message label


#### Attribute events
- JoinIn / JoinEmpty
- LeaveIn / LeaveEmpty / LeaveAll

При помощи Join сообщения мы регистрируем какую-то информацию на устройстве, при помощи LeaveIn эту регистрацию мы убираем.

Messaging is controlled by application state machine timers
- **Join Timer** -- control frequency of GARP PDU messaging
- **Leave Timer** -- control time for attribute registration
- **Leave All Timer** -- control frequency of the total reset event 

#### Recommendation for setting GVRP timers
- Leave time >= Join time * 3: если какое-то сообщение потерялось и мы его не получили, то мы не должны снимать регистрацию соответствующего атрибута прямо сразу, а дать возможность подтвердить эту регистрацию при помощи следующего полученного сообщения
- Leave All Time >= leave time * 8
- Join time should be between 0.4 and 6 seconds

#### Example of GVRP PDU Traffic

<div align="center"><img src="https://i.ibb.co/2gSLPgx/image.png" alt="image" border="0"></div>

#### Example of GVRP PDU Message

<div align="center"><img src="https://i.ibb.co/PtzVFDZ/image.png" alt="image" border="0" height="200"></div>



## Port Based Network Access Control

Идея в том, что у нас есть какая-то сетевая инфраструктура с коммутатором, к которому подключаются сетевые устройства. В зависимости от того, кто туда подключился, мы должны принимать решения
- пускать ли вообще в сеть это устройство
- если пускать это устройство в есть и у нас сконфигурированы VLAN'ы, в какой VLAN это устройство подключить.

Первый подход -- использовать MAC-адреса. Для этого на каждом коммутаторе должны быть табличка, какие МАС мы пускаем, а какие нет. Но это решение неудачное, потому что оно плохо масштабируется, да и МАС адрес можно подделать.

Второй более правильный подход - - **credential-based**: например, ввод логина-пароля. Для этого мы можем на каждом коммутаторе завести табличку с логинами и паролями, однако это не решает проблему масштабируемости.

В таком случае нам нужен **сервер аутентификации** -- единая база с логинами и паролями, к которой просто обращаются коммутаторы, спрашивая, можно ли дать доступ устройству с такими кредами и если да, то в какой VLAN его отправить.

<a href="https://ibb.co/QdhVGgS"><img src="https://i.ibb.co/KwBgHP4/image.png" alt="image" border="0"></a>


### Алгоритм аутентификации

1. Кандидат посылает пакет EAPOL-Start (опциональный шаг). Клиент может такой пакет и не посылать, потому что если на коммутаторе сконфигурирован порт-аутентификатор, он любой первый пакет от клиенты триггернёт на прохождение аутентификации
2. Аутентификатор посылает пакет EAP-Request/Identity, прося клиента представиться
3. Кандидат посылает пакет EAP-Response/Identity, который передаётся серверу аутентификации, представляясь.
4. Сервер аутентификации, выбрав алгоритм аутентификации, посылает пакет EAP-Request
5. Кандидат отвечает серверу пакетом EAP-Response, в котором содержится удостоверяющая его информация
6. Сервер подтверждает доступ клиента пакетом EAP-Success или отказывает в доступе EAP-Reject. Опционально на данном этапе коммутатору и клиенту сервером могут быть переданы различные сетевые настройки, такие как, например, членство во VLAN.
7. В случае успеха порт становится открытым для любого трафика (не обязательно от клиента), пока с ним ассоциирован МАС-адрес клиента в случае установки режиме piggybacking, либо только с МАС адреса клиента
8. Клиент может завершить сеанс связи, послав пакет EAPOL-Logoff, после чего порт перейдёт в состояние блокировки трафика до следующей удачной авторизации.

### Возможные конфигурации

Рассмотрим, кто у нас может выступать в качестве кандидата на доступ к сетевой инфраструктуре. 

#### Соискатель -- конечная система

В этом случае возможные конфигурации такие: во-первых, у нас есть один аутентификатор, к которому непосредственно подключено клиентское устройство. Этот случай как раз показан на рисунке выше.

С другой стороны, понятно, что в принципе возможна конфигурация, когда к одному аутентификатору посредством соответствующего сетевого оборудования подключается не один, а много соискателей (например, с помощью концентратора). Такая конфигурация потенциально возможна, но она не рекомендуется к использованию, потому что она небезопасна.

#### Соискатель -- коммуникационное устройство

Здесь аналогично, возможна конфигурация один аутентификатор - один соискатель; также возможна один аутентификатор - много соискателей (но она является небезопасной).

Кроме того, допускается и взаимная аутентификация устройства: например, когда два коммутатора подключены друг к другу и изначально друг другу не доверяют, то для того, чтобы открыть порты, соединяющие их, на передачу, они сначала должны друг друга аутентифицировать. В этом случае коммутаторы могут иметь каждый свой сервер аутентификации (ААА сервер), либо возможна какая-то хитрая сетевая топология, когда этот процес будет задействовать только один ААА сервер.

### AAA сервер

Это некоторый сервис, который позволяет проводить аутентификацию устройства (Authentication), авторизацию  (Authorization), то есть выдачу соответствующих прав доступа к той или иной сетевой инфраструктуре в том или ином варианте с подключением к тому или иному VLAN, и учёт (Accounting) -- ведение логов о том, кто подключается и отключается от сети, по этим логам можно проводить аудит сетевой инфраструктуры.

Один из самых популярных сервисов -- **RADIUS** -- Remote Authentication Dial In User Service. У него существует несколько стандартов: базовый работает с помощью UDP (2000), есть модификация от 2012 года, которая работает с помощью TCP, что повышает надёжность этого сервиса.

Есть и другие реализации ААА серверов:
- Diameter
	- RFC 6733, 4004-4006
	- Улучшенная обработка ошибок (TCP)
	- Возможность работы в мультидоменной инфраструктуре, когда сервис отвечает за аутентификацию устройств в нескольких независимых доменах (домен в даном случае -- это домен аутентификации: некоторая база данных, в которой написано, какие устройства есть в сети, и какие у них есть права)
- TACACS/TACACS+ -- Terminal Access Controller Access-Control System
	- Первая версия появилась в 1984 году
	- 3 отдельных протокола, сервисы могут быть расположены на отдельных серверах

### Основные сообщения протокола RADIUS
Код | Тип сообщения
--|--
1 | Access-Request
2 | Access-Accept
3 | Access-Reject
4 | Accounting-Request
5 | Accounting-Response
11 | Access-Challenge (специальное сообщение, с помощью которого мы запрашиваем у клиента некоторую аутентифицирующую информацию)

### Структура пакета протокола RADIUS

- Код сообщения
- Идентификатор сообщения
- Размер сообщения
- Аутентификатор (16 байт)
- Атрибуты
	- Тип атрибуты
	- Размер атрибута
	- Значение атрибута

### Некоторые атрибуты
Код | Назначение атрибута 
--|--
1 | User-Name
4 | NAS-IP-Address
5| NAS-Port
31 | Calling-Station-ID -- идентификатор клиента, тут может быть MAC адрес
61 | NAS-Port-Type
79 | EAP-Message -- аутентифицирующая информация

### EAP -- Extensible Authentication Protocol

RADUIS -- это протокол прикладного уровня. При помощи этого протокола взаимодействуют аутентифицирующее устройство (NAS сервер), в роли которого на рисунке выступает коммутатор, и сервер аутентификации (ААА-сервер). Понятно, что должно быть какое-то взаимодействие и на уровне клиента -- пока клиент не получил доступ к сети, он продолжает работать на канальном уровне. Поэтому здесь мы проводим взаимодействие с помощью протокола EAP канального уровня, который работает непосредственно поверх Ethernet.

При этом у RADUIS слоёный пирог протоколов под ним может включать Ethernet, IPv4 и UDP -- он гораздо выше.

При этом сообщения RADUIS и EAP довольно похожи.

EAP поддерживает более десятка методов аутентификации, среди которых **MD5** и **TLS**.

#### Инкапсуляция EAP

Инкапсуляция на канальном уровне обеспечивается по стандарту 802.1Х "EAP over LAN".
- 2001 -- базовый стандарт
- 2004 -- использование данных механизмов в беспроводных сетях
- 2010 --  современный стандарт включает расширенные методы аутентификации


## Агрегированные каналы

Если сервисы для организации VLAN и аутентификации мы относим к механизмам обеспечения безопасности в сетевых инфраструктурах, то следующие два сервисы -- агрегированные каналы и STP, предназначены для повышения надёжности сетевых инфраструктур, а агрегированные каналы к тому же в ряде случаев могут повысить и производительность.

Для агрегированных каналов часто используется термин **trunks**, но он не совсем удачный, потому что этот термин воспринимается по-разному различными вендорами и различными сообществами. Например, Cisco транком называют канал, по которому проходят пакеты, относящиеся к разным VLAN.

**Основная идея** -- объединение двух или более физических каналов (соединений) между двумя, как правило, соседними сетевыми устройствами в один логический, для улучшения характеристик канала, таких как пропускная способность, доступность (надёжность) и так далее. Применяется не только в Ethernet-сетях, но и, например, в FiberChannel.

Однако если мы дублируем соединения между двумя устройствами, возникает проблема: в этом случае любой широковещательный пакет, который придёт на какой-то коммутатор, будет ретранслирован по всем портам.

<div align="center"><img src="https://i.ibb.co/qMK76b1/image.png" alt="image" border="0"></div>

Поэтому в таком случае, как на рисунке, один широковещательный пакет превратится в четыре.

Более того, если мы просто оставим эти 4 физических соединения и никак не предупредим коммутаторы о том, что на самом деле это один логический канал, то этот широковещательный пакет размножится ещё и между самими коммутаторами, то есть пакет, пришедший по первому линку на SW B, будет перенаправлен на остальные три назад. Такая же история будет происходить и для остальных линков, так что эти пакеты троекратно вернутся назад на коммутатор А. По такой же логике на коммутатор В в ответ придут 9 пакетов, и всё это дело будет экспоненциально размножаться, пока в рамках сети не будут рассылаться только эти широковещательные сообщения.

Поэтому коммутаторы надо предупредить о том, что эти соединения на самом деле представляют собой один логический канал. Это мы должны в явном виде настроить либо статически, зайдя в консоль управления коммутатором и указав, что это не отдельные 4 соединения, а 1 логическое; либо коммутаторы должны сами как-то договориться о отм, что они подключены друг к другу четырьмя соединениями, которое нужно объединить в одно логическое.

Это нам даёт повышенную надёжность: если какой-то линк будет выходить из строя, у нас останутся резервные каналы для взаимодействия. Плюс, если мы будем использовать режимы балансировки трафика между этими линками, мы можем повысить
пропускную способность сетевой инфраструктуры: у канала, соединяющего коммутаторы А и В она возрастёт пропорционально количеству этих линков.

Важно, что этот механизм обычно работает только между *соседними* устройствами. Если мы попробуем создать такую конфигурацию (это можно сделать только статически, а динамические протоколы обычно не позволяют провернуть такие штуки)

<div align="center"><img src="https://i.ibb.co/pfLkLTB/image.png" alt="image" border="0"></div>

то если какой-то линк разорвётся, то с точки зрения одного коммутатора он всё ещё останется рабочим, и он продолжит пытаться посылать туда сообщения, что приведёт к потере данных. Так что такая сложная конфигурация не позволяет просто отследить целостность каналов.

Конфигурация агрегированных каналов может быть статическая (руками в консоли) и динамическая (с помощью протоколов), когда соседние устройствами сами договариваются (они видят, что на самом деле они несколькими портами подключены к одному и тому же соседу, и вырабатывают общую конфигурацию по объединению этих нескольких физических каналов в один логический.

Здесь есть стандартный протокол **802.1AX LACP**, и есть проприетарные протоколы от различных вендоров, которые позволяют получить несколько более гибкие и мощные сервисы по отношению к стандартной реализации. При этом что хорошо в стандартном протоколе, так это то, что все устройства обязаны его поддерживать, в отличие от проприетарного, который, как правило, поддерживается только устройством одного производителя.

### Изменение в референсной модели

<div align="center"><img src="https://i.ibb.co/sgtrBhD/image.png" alt="image" border="0"></div>

Чтобы это всё реализовать, потребуется внести изменения в референсную сетевую модель. Раньше мы рассматривали всё, что происходит, в рамках **одного** физического соединения, и у нас был один столбик. Теперь, раз мы можем рассматривать несколько физических соединений как одно логическое, некоторый функционал у нас остаётся за физическим каналом (Physical layer, MAC, MAC Control, -- это для каждого линка своё), но поверх этого, с точки зрения протоколов более высоких уровней, этот канал должен восприниматься как единый сервис передачи данных. Поэтому уровень LLC для них уже будет общий, посему у нас добавляется опциональный уровень агрегации (**Link Aggregation Sublayer**), который уже будет общим для всех физических соединений, включаемых в этот канал, и на этом уровне как раз и будут реализовываться какие-то хитрые структуры данных, алгоритмы и посылка каких-тто управляющих сообщения для того, чтобы этот агрегированный канал мог функционировать.

### Балансировка нагрузки между подканалами в рамказ составного канала

Остаётся одна нерешённая проблема: как мы будем распределять трафик, который приходит коммутатор, по линкам в рамках одного канала, то есть какие сообщения мы будем передавать по какому из физических каналов?

Здесь может быть несколько подходов:

#### На уровне кадров

Это самый простой подход, который можно было бы предложить. Пусть на наше устройство приходит некоторый поток кадров, и первый пришедший кадр мы посылаем на первый линк, второй кадр -- на второй линк, третий -- на третий, четвёртый -- снова на первый (то есть в режиме некоторой циклической очереди), и так далее. 

**Достоинство**: мы получаем близкое к равномерному распределение кадров между подканалами (хотя количество передаваемых данных не обязательно, нам может так не повезти, что в один линк будут постоянно попадать гигантские кадры, а в другой только небольшие, правда тогда можно изменить логику балансировки, и использовать не счётчик кадров, а основываться на объёме переданных данных)

**Недостаток** потенциально ряд протоколов более высоких уровней более чувствительны к порядку прихода кадров, что трудно гарантировать при использовании нескольких подканалов. Причём даже если в протоколе реализован механизм переупорядочивания кадров в нужном порядке, мы всё равно потратим ресурсы на реализацию этого механизма: в буферной памяти на уровне данного протокола будут задерживаться сообщения, полученные вне очереди, что может быть не совсем желательно, если система находится под нагрузкой и обрабатывает большое количество сообщений.

#### На уровне взаимодействующих абонентов

В зависимости от реализации весь трафик от конкретного отправителя или весь трафик, предназначенный конкретному получателю, либо трафик между конкретной парой абонентов, будем направлять всегда в один и тот же канал. Таким образом, мы ориентируемся на адреса отправителя и получателя и на их основании будем выбирать, в какой линк отправлять тот или иной кадр. 

**Достоинство**: весь трафик между двумя абонентами в рамках конкретного протокола будет строго упорядоченным.

**Недостаток**: мы не можем гарантировать даже статистически равномерность использования каналов. В результате для конкретных приложений и конкретных абонентов пропускная способность канала будет равна скорости одного линка. Поэтому, используя такой механизм, мы не можем повысить скорость сети для конкретных абонентов.

Второй вопрос -- а какие адреса мы можем использовать для выбора балансировки. Здесь могут использоваться адреса **канального** уровня -- в этом случае коммутатор должен посмотреть только на кадр Ethernet, который он и так анализирует, поэтому здесь получается сравнительно простая реализация, однако этот механизм может не обладать необходимой гибкостью и опять же не гарантирует равномерную загрузку каналов.

С другой стороны, мы можем залезать на протоколы более высоких уровней и смотреть, например, IP адреса. НО этот механизм уже сложнее -- наше устройство должно будет понимать протоколы сетевого уровня и потенциально даже выше. Поэтому это будет требовать от коммуникационного устройства более глубокого анализа трафика, так что это целесообразно делать, если это устройство уже априори имеет соответствующий функционал, например, маршрутизатора, и используется на уровне L3 и даже выше.

#### С учётом количества переданных данных

**Достоинство**: наиболее равномерная загрузка подканалов

**Недостатки**:
- высокая сложность управления ⇒ затраты на аппаратную реализацию
- недостатки балансировки на уровне кадров

#### В не Ethernet сетях

Могут использоваться другие режимы балансировки: например, в FiberChannel абоненты обмениваются кадрами, из кадров составляются последовательности -- цепочки кадров, передаваемых в одну сторону в рамках обмена данными, и есть понятие Exchange -- несколько последовательностей, объединённых в рамках решения одной задачи. Поэтому весь трафик в рамках одного обмена мы можем запихивать в один канал, а другой обмен -- в другой канал.

### Алгоритмы балансировки

Режим балансировки на уровне абонентов и их адресов самый простой и реализуется всеми устройствами. Здесь можно реализовать несколько подходов способа назначения абонентов на соответствующий канал

#### **Round Robin** 

Циклический буфер абонентов, назначаемых на канал + должны быть алгоритмы старения информации: если абонент долго не общается, то мы должны снять с него привязку к соответствующему каналу.

Такой подход в принципе реализуем, но он достаточно сложен, и он того не стоит.


#### Хеширование

На практике используется как раз совсем простой подход, когда мы вычисляем номер канала как функцию от адреса абонента. Самый простой пример -- взять в качестве номера остаток от деления последнего октета МАС-адреса на количество подканалов в агрегированном канале. Либо, если мы базируемся на адресах и отправителя, и получателя, мы их каким-то образом комбинируем, например, с помощью XOR, берём какое-то подмножество бит и по вычисленному значению мы всегда и направляем в один и тот же канал. 

Здесь могут получиться и некоторые аномалии: если адреса абонентов не сильно удачные, может получиться так, что все эти абоненты будут направлены на один физический канал. Но статистически распределение между подканалами будет равномерное. Так что прежде чем разворачивать подобное решение, нужно посмотреть на то, какие адреса у нас есть, какие режимы обмена и на основании этого уже выбирать конкретный алгоритм балансировки.

### Типичные примеры использования подхода

#### Пример 1

<div align="center"><img src="https://i.ibb.co/LPvvLgs/image.png" alt="image" border="0"></div>

Абоненты общаются каждый с каждым, и нам не принципиально, какой режим балансировки мы будем использовать -- только по адресу отправителя или получателя, или всё вместе. Всё равно статистически получится более или мерное равномерное распределение данных в рамках агрегированного канала.

При этом у нас нет смысла лезть на уровень выше. Не нужно использовать балансировку, например, по IP адресам -- МАС адресов будет вполне достаточно.

#### Пример 2

<div align="center"><img src="https://i.ibb.co/Wk2BPVL/image.png" alt="image" border="0"></div>

У нас есть какой-то хост, с которым хотят активно общаться большое количество абонентов на другом конце агрегированного канала. Сам этот хост представлен одним МАС-адресом, поэтому очевидно, что здесь выбор режима балансировки должен быть похитрее.

С точки зрения Switch 1, на котором находятся абоненты, целесообразно делать балансировку от отправителя к серверу: у нас МАС адреса отправителей разные, а МАС получателя один и тот же, поэтому если мы наоборот, будем делать балансировку по МАС получателя, то весь трафик пойдёт по одному и тому же линку.

А в обратную сторону, когда мы получаем ответ от сервера, мы уже балансируем по получателю.

#### Пример 3

<div align="center"><img src="https://i.ibb.co/zrfRHzH/image.png" alt="image" border="0"></div>


В таком случае, чтобы реализовать алгоритм балансировки, надо смотреть на приложения, которые работают на взаимодействующих друг с другом системах. Если каждая система описывается одним МАС адресом (хотя на самом деле их может быть несколько, если работает система виртуализации и виртуальные машины), то для балансировки нам потребуется адресация из протоколов более высоких уровней.э

#### Пример 4

<div align="center"><img src="https://i.ibb.co/WW3R1YM/image.png" alt="image" border="0"></div>

У нас есть несколько локальных сетей. В этом случае понятно, что так как мы находимся за маршрутизатором, то каждый клиент видится внутри сервера под МАС-адресом маршрутизатора, поэтому балансировка трафика на уровне МАС-адресов работать никак не будет. Так что здесь должен работать режим балансировки на уровне сетевых адресов.

### Перебалансировка абонентов

Перебалансировка абонентов в общем случае производится только при изменении конфигурации агрегированного канала. Например, если агрегированный канал замечает, что изменилась доступность одного из его подканалов, то он исключает его из агрегированного канала, и поэтому меняется выбор подканала, по которому идёт тот или иной трафик. 

По аналогии, при добавлении или исключении подканала в агрегированном канале самим администратором тоже происходит перебалансировка -- причины ты же самые, что и при изменении доступности.

Системы, использующие интеллектуальные алгоритмы балансировки, могут принять решение о перебалансировке абонентов при изменении внешних условий (без изменения доступности каналов, например, загрузки канала). Но, как правило, это даёт слишком большую нагрузку на сетевое оборудование, поэтому такие решения на практике при стандартной реализации агрегированных каналов не используются, а используется что-то более простое, что можно реализовать условно аппаратным способом.

При использовании IP-адресов и логических (TCP/UDP) портов для балансировки соответствующие поля в пакетах выбираются просто по смещению (как раз из-за того, что используются простые алгоритмы), и это приводит к тому, что попытка балансировки трафика по протоколу, который инкапсулирует что-то другое (например, VPN) может быть неожиданной, так как по заданному смещению будут находиться не IP-адреса, а какая-то другая информация, возможно, константная.

### Проблема размножения кадров

- **Агрегированный канал -- логический порт**: условно -- 1 запись на МАС в таблице продвижения ⇒ широковещательный и т.п. трафик идёт по одному из подканалов. Тут нет неуправляемого размножения кадров
- **Двусторонний агрегированный канал** (оба коммутатора в курсе того, что физические порты включены в один агрегированный канал и передают трафик как между двумя логическими соединениями) -- тут тоже проблем не возникает
- **Односторонний агрегированный канал**, когда один из коммутаторов агрегирует подканалы в рамках одного канала, а второй коммутатор этого не делает -- специфичная ситуация, которая бывает, если второе устройство просто не поддерживает агрегированные каналы. В таком случае возникает проблема размножения кадров, но она управляемая. Также из-за этого возможна блокировка трафика из-за того, что кадры будут уходить из агрегированного канала не на тот порт, который указан в таблице продвижения.

Допустим у нас есть два коммутатора, которые соединены несколькими параллельными соединениями, но агрегации каналов в них нет.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/BNQSwpt/image.png" alt="image" border="0"></a>

Пусть с некоторого хоста отправляется трафик на неизвестный адрес. По правилам первый коммутатор должен переслать этот кадр на все порты, кроме того, с которого он получил этот кадр. Если на втором коммутаторе в таблице продвижения также нет МАС-адреса получателя, он сделает то же самое -- и каждый из кадров ещё трижды придёт на первый коммутатор. Такая ситуация называется петлёй, и эти пакеты будут бродить между коммутаторами условно бесконечно.

Аналогичная история и с широковещательными пакетами, только в случае с unicast, если в таблице продвижения всё-таки появится соответствующая запись, есть вероятность того, что размноженные пакеты всё-таки будут направлены в нужный порт и исчезнут из оборота, то broadcast пакеты безнадёжно будут путешествовать между коммутаторами до тех пор, пока между ними не останется только одно физическое соединение -- то есть пока правило пересылки кадра на все порты, кроме того, с которого он пришёл, не перестанет порождать новые пакеты.

Если агрегированный канал настроен с одной стороны, то пакет в обоих случаях (unicast и broadcast) будет передан по одной линии.

<a href="https://ibb.co/sFHDSVZ"><img src="https://i.ibb.co/64BphWk/image.png" alt="image" border="0"></a>

Если на втором коммутаторе агрегации каналов нет, то по правилам полученный кадр будет переслан на все другие порты. В зависимости от конфигурации первый свитч, получив дубликаты этих сообщений, может переслать их обратно на второй коммутатор, до тех пор, пока тот не обучит свою таблицу продвижения и не начнёт продвигать эти кадры туда, куда надо. В случае с broadcast ситуация похожая. Агрегированный канал иногда может определять, когда он получает дубликат того, что он отправил, и нивелировать подобную ситуацию.

### Проблемы статических агрегированных каналов
- **Проблема ошибок конфигурирования**:
	- то, что мы настроили агрегированный канал статически, ещё не означает, что со временем это не приведёт к наличию петель
	- нет STP ⇒ получаем кольцо
	- есть STP ⇒ получаем канал с характеристиками, меньшими, чем предполагаемые (+ нестабильность и непредсказуемость в работе). Сеть не упадёт, но смысла от агрегированных каналов уже не будет
	- в обоих случаях ошибка конфигурирования может привести к тому, что часть абонентов могут стать недоступными
- **Использование пассивных медиаконвертеров (для старых сетей)**
	- Если для агрегирования канала используется прозрачный радиомост -- то есть если каждая линия, соединяющая два коммутатора, составная и соединяется с помощью некоторого активного оборудования, которое весь трафик прозрачно перегоняет в радиоканал и обратно передаёт его по проводным сетям.
	<a href="https://imgbb.com/"><img src="https://i.ibb.co/zRB3jhb/image.png" alt="image" border="0"></a> 
	Если связь между этими мостами прерывается:
	<a href="https://imgbb.com/"><img src="https://i.ibb.co/tCMQGWq/image.png" alt="image" border="0"></a>
	То коммутаторы не знают о том, что произошёл разрыв, и думают, что данный подканал активен -- сами связи, идущие к коммутаторам, остались и работают. Это приводит к тому, что часть абонентов, которые используют этот подканал, остаются без связи.

### Динамические каналы

Снимают проблемы статических каналов за счёт использования специальных протоколов, работающих, как правило, между соседними устройствами, и позволяющими обнаруживать множественные соединения соседних устройств и объединять их в один логический канал.

#### Подходы к построению

- **Link Aggregation Control Protocol** -- работает между соседними устройствами различных производителей
- **Проприетарные протоколы** -- работают между устройствами одного производителя, как правило, соседними, но могут использоваться и топологии с промежуточными звеньями

#### Цели LACP

- Линейное увеличение пропускной способности
- увеличение доступности
- совместное использование ресурсов
- автоматические конфигурирование
- быстрое конфигурирование и реконфигурирование
- определенность поведения
- низкая вероятность дублирования пакетов и нарушения порядка их передачи
- поддержка всех существующих протоколов более высокого уровня (полностью прозрачный механизм)
- совместимость с устройствами, не поддерживающими агрегирование
- поддержка оборудования с разными возможностями и ограничениями
- неизменность формата кадра
- **поддержка управления сети** -- коммутатор должен уметь разделять трафик сети и трафик, который используется для управления

#### Ограничения LACP

- нет поддержки агрегирования более чем между двумя системами -- LACP не позволяет агрегировать сложные опосредованные соединения типа моста из двух коммутаторов, и если такое соединение появится в сети, то это будет кольцо, и для разрешения этой ситуации понадобятся уже другие протоколы 
- агрегирование только МАС уровня IEEE 802.3
- только соединения точка-точка в режиме полный дуплекс -- через LACP нельзя создать однонаправленные соединения
- все соединения в рамках канала должны работать на одной и той же скорости передачи данных. Поэтому если скорость соединения одного из подканалов падает, все другие подканалы также будут вынуждены работать на этой скорости, поэтому иногда такое медленное соединение может просто исключаться из группы

### Состав Link Aggregation Sublayer
<a href="https://ibb.co/VYYkvnb"><img src="https://i.ibb.co/jkkjL0q/image.png" alt="image" border="0"></a>

- **Frame Collector / Сборщик кадров**
	- Отвечает за получение входящих кадров и передачи их МАС-клиенту
	- не решает задачу переупорядочивания кадров -- кадры поступают клиенту в порядке их прихода на сборщик кадров
- **Frame Distributor / Распределитель кадров**
	- Отвечает за получение кадров от МАС-клиента и передачу их через каналы, входящие в LAG
	- реализует алгоритм(ы) распределения кадров по каналам LAG
		- не должен менять порядок кадров в рамках одного обмена
		- не должен допускать дублирования кадров
- **Aggregator / Агрегатор**
	- Объединяет сборщик и распределитель кадров и один или более агрегирующий парсер/мультиплексор, соответствующий физическому каналу, в единый МАС сервис
	- создаётся для каждой LAG
	- с каждым агрегатором ассоциируется один МАС-адрес.
		- может использоваться МАС одного из физических каналов или новый уникальный адрес
- **Control Parser/Multiplexer -- парсер/мультиплексор управления**
	- прозрачно пропускает сообщения управления каналов и сообщения от МАС-клиента в физический канал (нижележащий сервис)
	- разделяет входящие пакеты на пакеты управления каналом (передаёт сервису управления каналом) и все остальные (передаёт на агрегатор)
- **Link Aggregation Control / управление агрегированным каналом**
	- управляет уровнем агрегирования, используя
		- статическую информацию, заданную при конфигурировании устройства
		- динамическую информацию, полученную от LACP
	- **Задачи**
		- Для каждого порта
			- поддержание конфигурационной информации для реализации агрегации
			- обмен информацией с другими системами для включения канала в LAG
			- присоединение/отсоединение порта к соответствующему агрегатору
			- управление агрегатором, используя информацию от соседней системы
		- проверка, что канал действительно входит в LAG
		- добавление канала в LAG или создание LAG при необходимости
		- мониторинг состояния LAG
		- удаление канала из LAG или удаление LAG при необходимости
	- **Свойства**
		- автоматичность
		- непрерывность
		- определенность
		- контролируемость
		- совместимость
		- быстрота конфигурирования
		- низкий ризк недоставки кадров, дублирования или изменения порядка кадров
		- низкие затраты на протокол управления

### Принцип обмена данными по LACP

- обмен не командами, а состояниями. Это позволяет исключить несогласованность из-за разных конфигураций, ошибок или обрывов соединения
- партнёры могут взаимодействовать в пассивном и активном режимах
	- пассивный отвечает, только если приходят соответствующие запросы от активного
- 2 режима работы: быстрый и медленный, которые определяют периодичность посылки пакетов (1 и 30 секунд)
- сложная структура пакета

#### Формат пакета

<a href="https://ibb.co/Mn09HrX"><img src="https://i.ibb.co/0qbQLTw/image.png" alt="image" border="0"></a>

#### Принципы объединения в один агрегированный канал
- подканалы начинаются и заканчиваются на одних и тех же устройствах
- включены в одни и те же VLAN
- параметры соединения совпадают (скорость), полнодуплексный режим (!): оба коммутатора должны передавать свои состояния
- совпадение ключей, назначенных на портах (опциально, административные ключи могут не совпадать)

### Конфигурируемые параметры

- **Приоритет системы**
	 - выбор управляющей каналом системы
	- пара {приоритет системы, МАС системы}: чем меньше, тем выше приоритет
- **Приоритет порта**
	- Выбор порта, который будет включен в LAG, если их количество больше, чем поддерживает система
	- пара {приоритет порта, номер порта}: чем меньше, тем выше приоритет

#### Проблема выбора портов для включения в LAG

Так как у каждой системы своё распределение приоритетов, решения о включении порта в группу принимаются партнёрами независимо. Поэтому существует проблема согласования выбора портов в группе.

Для решения этой проблемы одних приоритетов мало, и был введён алгоритм динамического распределения ключей -- как раз эти ключи должны совпадать на портах для включения их в одну группу. Именно эти ключи передаются в LACPDU. Если ключ порта не совпадает ни с одним ключом из другого порта, это значит, что он не соединён ни с каким другим портом.


### Упрощённый алгоритм динамического управления ключами

Вводятся два типа ключа:
- **административный** -- 16-разрядное число, которое задаётся при конфигурировании устройства. Опциальный
- **операционный** -- меняется динамически управляюще системой при формировании LAG в рамках этого алгоритма

<u>Управляющая</u> система **может** принять во внимание приоритет портов на партнёре, если того хочет.

<u>Управляемая</u> система **всегда** учитывает приоритет порта управляющей системы. Он складывается из
- приоритета системы
- идентификатора сситемы
- приоритета порта на управляющей системе
- номера порта на управляющей системе

#### Идея алгоритма

Выстраиваем на управляющей системе порты в порядке убывания приоритет.

Берём очередной порт:
- если его нет, то алгоритм завершается
- если порт может быть включен в LAG, добавляем его туда
- если порт не может быть включён в LAG, модифицируем операционный ключ для LAG

### Множество LAG между двумя соседними устройствами

Алгоритм динамического управления ключами может сформировать несколько LAG (зависит от программного обеспечения коммутатора).

Обычно на практике
- если у портов совпадают административные ключи, то формируется одна LAG, остальные переходят в режим ожидания (standby)
- если у портов не совпадают административные ключи, то может сформироваться столько LAG, сколько есть различных комбинаций ключей (ключ на управляющей системе, ключ на подчиненной системе) на активных соединениях

#### Временные параметры LACP

- период
	- быстрый: 1 сек
	- медленный: 30 сек
- таймаут: 3 * период
- время ожидания агрегации -- 2 сек
- время обнаружения отключения -- 60 сек для медленного режима

### Маркерный протокол (Marker Protocol)

Опциональный протокол стандарта 802.1AX.
- может применяться распределителем кадров, например, для организации балансировки с учётом таймаутов на канале или с учётом нагрузки
- удалённая система должна уметь отвечать на маркерные сообщения
- в стандарте описан формат и реакция на получение запроса с маркером, но не прописаны сценарии применения такого механизма

### Агрегированные каналы и VLANы

Конфигурации VLAN на каналах, входящих в агрегированные каналы, должны совпадать.
- иначе непредсказуемость работы
- контролируется ПО коммутатора
- в нормальном коммутаторе ПО не позволит создать агрегированный канал на портах с разной конфигурацией VLANов

## STP: Spanning Tree Protocol

Определяет протокол построения покрывающего (остовного) дерева для обеспечения отсутствия петель коммутации в сетях.

### Отключение неиспользуемых соединений

### Служебные сообщения

Используются при создании покрывающего дерева и для его поддержания, потому что возможны некоторые аварийные ситуации, когда активный линк отключается, и эти ситуации надо отслеживать. Поэтому STP работает постоянно, тестируя сетевую инфраструктуру на то, что линки, которые мы используем, действительно живы, и если они не живы, будет происходит перестроение топологии.

Configuration BPDU (Bridge Protocol Data Unit) -- это сообщения протокола. 

Кроме этого, есть особые специальные сообщения примерно такого же формата, но в них скрыт некоторый доп смысл. Например, **Topology Change Notification BDPU** -- посылает тот мост, который увидел, что в сети что-то поменялось, например, отрубился активный интерфейс -- либо умер линк, либо умер партнёр на другом конце провода, и эти изменения, которые нашёл этот мост, он при помощи TCN оповещает в базовой версии протокола, посылая их корневому коммутатору. Но подобные сообщения в более новых версиях рассылаются всем соседям. 

Корневой коммутатор инициирует конфигурационные BDPU и все коммутаторы их просто пересылают. Сами по своей инициативе, когда коммутаторы не считают себя корнем, такие сообщения не посылают в базовой версии протокола. 

Коммутатор в ответ на получение TCN посылает TCA. Это сообщение дойдёт до корневого моста, и он понимает, что что-то в сети поменялось, и он должен оповестить всю сеть о том, что что-то поменялось. В формате пакета есть флаг ТС, которые устанавливает корневой, это сообщение пересылается в течение некоторого временного промежутка, сконфигурированного исходя из предполагаемого диаметра сети (их можно поменять при необходимости). Это сообщение будет продавливаться через всю сеть, и се коммутаторы в результате узнают, что топология изменилась. Раз она изменилась, то изменится доступность определённых МАС адресов по портам. И значит появятся какие-то некорректные записи в таблицах продвижения коммутаторов. Поэтому каждый коммутатор, получив это оповещение об изменении топологии, очищает всю таблицу продвижения. Плюс идёт пересчёт топологии, то мы заново рассчитываем маршруты, поэтому в течение некоторого времени сетка будет простаивать.

 В каждом состоянии порт по умолчанию находится 15 секунд в изначальной версии протокола (это можно поменять) (discarding --> forwarding), поэтому сетевая инфраструктура некоторое время будет недоступна. Порядка минуты сеть не работает. Поэтому базовая версия STP нам не подходит по текущим меркам.

При изменении топологии получается фактически происходит сброс всей сетевой инфраструктуры, и в течение какого-то времени эта инфраструктура будет недоступна.

## RSTP: модификация STP

Проблема того, что сетевая инфраструктура реагирует на изменение доступности портов довольно долго, нам не нравится. Плюс есть состояния listening/learning портов, которые избыточны: сегодня состояние listening по большому счёту не нужно.

Появился Rapid STP протокол, в котором избавились от состояния Listening. Также появились краевые порты egde ports -- это порты, на котором мы гарантированно знаем, что за ним нет кольца. Например, если на порт коммутатора повешен хост, на нём уже никаких колец возникнуть не может. Поэтому этот порт не нужно включать в STP так, чтобы изменения этого SP влекли события на нём.

Или если на какой-то порт повешен только один коммутатор, на который повешены одни хосты -- тут тоже не будет колец, поэтому тут нет смысла включать полноценную поддержку STP.

В таких случаях можно назначить порт как краевой -- то есть за такими портами есть либо хост, либо кусок сети, за которым нет колец.

Потенциально там на самом деле может получиться некоторая кольцевая инфраструктура, но по умолчанию edge port не учитывает изменения топологии только до тех, пока на него не пришёл BDPU. В этом случае порт тут же теряет статус краевого и становится обычным портом -- это защита от того, что вдруг когда-то кто-то всё-таки закольцует сеть за этим портом.

Кроме того, теперь все коммутаторы генерируют BDPU, а не только корневой. Это решает проблему, если у нас умирает корневой коммутатор или падает путь к нему. Теперь каждый играет активную роль, а не только пассивного ретранслятора сообщения от корневого. Поэтому реакция на события будет быстрее.

Кроме того, изменились тайминги перевыбора корневого коммутатора, режим выбора соседних устройств, формат DBPU (новые флаги и т.п.).

Теперь флаг ТС об изменении топологии могут рассылать все коммутаторы: мы не ждём сообщение от корня. Поэтому мы моментально удаляем запись из таблицы продвижения.

Изменились роли портов. Порт, который ведёт от коммутатора в сегмент сети (от корня в низлежащие сегменты), он был выделенным (Non-designated), а все порты, которые не являются этими выделенными (назначенными) имели статус неназначенных. Если происходила авария на неназначенном порте, мы должны были по изменениям топологии переключиться на какой-то из неназначенных портов. Теперь появилось два дополнительных состояния -- неназначенный порт может быть альтернативным или резервным. 


### STP и агрегированные каналы

С точки зрения STP агрегированный канал это одно логическое соединение. Эти два механизма могут работать совместно.

<a href="https://imgbb.com/"><img src="https://i.ibb.co/2jk5Knr/image.png" alt="image" border="0"></a>

Если мы в такой сетке включим LACP, но без STP, будет закольцовывание -- сетка всё равно работать не будет.

Если убрать LACP и включить только STP, сеть работать будет. Но все лишние соединения будут заблокированы. В результате во всей сетке останется всего три линка. Сеть будет работоспособной; если на одном из назначенном линков произойдёт авария, мы переключимся на резервный, и всё будет хорошо -- надёжность будет высокая, но производительность будет низкая, потому что вместо 2-3 линков на каждом сегменте будет использоваться только один.

Поэтому хочется использовать оба механизма сразу, и STP, и LACP. Сначала включаем LACP -- так каналы сагрегируются в логические линки, и поверх этих логических линков должен будет сработать STP.

В таком случае, если работают оба протокола, получится и повышенная надёжность, и повышенная производительность.


### STP и VLANы

Вопрос, как это реализовать.

Есть несколько подходов.

Первый -- одно общее дерево на все VLAN. Это просто, но могут быть и неоптимальные маршруты.

 Пусть у нас есть куча коммутаторов, соединённых в кольцо, и к каждому коммутатору подсоединены хосты. В этой сетке есть VLANы. Поэтому линки между коммутаторами передают тегированный трафик.

<a href="https://ibb.co/xM0pS1X"><img src="https://i.ibb.co/9qLF9bc/image.png" alt="image" border="0"></a>

Как сделать так, чтобы трафик в сети передавался оптимально межу хостами?

У нас есть кольцо. STP это кольцо где-нибудь разомкнёт, но можем ли мы повлиять на то, в каком месте он разомкнёт это кольцо? Радикальное решение -- снизить скорость на каком-нибудь линке. Не радикальное решение -- изменить приоритет (то же самое что было в LACP) -- некоторое число, которые занимает 2 октета, и если они равны, то дальше сравнивается МАС-адрес. Если мы задаём поле Priority в явном виде, можно перевесить любой МАС-адрес, поставив максимальный приоритет. Тем самым можно сдвинуть в сети корень.

Если обрубить связь внутри одного VLAN, то хосты в рамках этого vlan будет вынужден гонять трафик через всю сетку ==> большие задержки + зафлуживание всей сети пакетами из VLN (например, если сделать размыкание вести в самом нижнем сегменте, то 30 VLAN будет страдать).

Но картинка такая, что как бы мы не разомкнули, то какой-то из VLAN всё равно будет обиженным -- то есть хосты этого VLAN будут находиться на разных концах сети. Поэтому решение в виде общего дерева для всей сети не очень хорошее.


Второй подход -- каждому VLANу по дереву. Для каждого VLAN будет выбран свой корень, своё покрывающее дерево. Но проблема в том, что таких VLAN будет много, покрывающих деревьев будет много ⇒ очень много служебных сообщений + очень много вычислительных ресурсов сетевого оборудования на поддержание этих деревьев.

Третий подход -- промежуточное решение. Исследуя топологию сети, распределение хостов по VLAN и тд,  можно построить несколько оптимальных деревьев. В нашем случае хотя бы два дерева достаточно, чтобы не было такого, чтобы хосты из одного VLAN не оказывались на разных концах сети -- например, к одному дереву привязать 42 и 8, а к другому -- VLAN 12 и 30. Деревьев меньше, чем VLAN ⇒ будут несколько деревьев, на которые некоторым оптимальным образом лягут VLAN.

Эта идея используется в MSTP. Мы можем создать несколько vlan-независимых деревьев и привязать деревья к ним + обмен данными между деревьями инкапсулируется в один пакет, поэтому нет взрывного роста количества управляющих пакетов, хотя сами пакеты чуть увеличатся.

### MSTP

Совместим с RSTP.

Вводится понятие экземпляра покрывающего дерева. Их ограниченное количество, но для совсем больших сетей вводятся уровни иерархии -- появляется понятие региона -- некоторое выделение коммутаторов, имеющих общий взгляд на топологию. В регионе используется один и тот же набор деревьев. Но сеть может быть такой большой, что в другом регионе может быть оптимальным другой набор деревьев.

Внутри регионов связываются коммутаторы, внутри регионов еть ещё куча VLAN, несколько экземпляров деревьев.

Регионы обмениваются через общее дерево CIST. Весь обмен сообщениями в рамках сетевой инфраструктуры происходит через общее дерево между регионами + внутри каждого из регионов есть общее дерево, которое как раз и будет совместимо с RSTP, в рамках которого будут рассылаться все управляющие сообщения. Однако дополнительные сущности MSTI независимы от этого общего дерева.

Структура конфигурационного пакета

- заголовок
- параметры CIST (это соответствует тому что будет в RSTP -- если коммутаор не знает что такое MSTP, дальше в пакете он не смотрит)
- параметры msti1
- ...
- параметры msti n


Пакетики распространяются в рамках CIST.

Этот протокол довольно сложный, иногда нужна ручная конфигурация.

### Shortest Path Bridging и TRILL

В STP было плохо то, что какие-то линки в нём отключаются. Да, если использовать хитрую конфигурацию VLAN, можно получить интересные эффекты,, всё равно какие-то линки отключаются -- это не очень хорошо и слишком накладно. Использовать все возможные пути коммуникации -- современная идея

<a href="https://ibb.co/S0BKp3f"><img src="https://i.ibb.co/P4g586D/image.png" alt="image" border="0"></a>

Аналогичное решение, но сделанное несколько по другому и являющееся стандартом не IEEE а ETF (RFC) -- TRILL: Transparent Interconnection of Lots of Links. Мы прозрачно дл конечных приложений используем все возможные пути доступа.

# IPv4

### Задачи

Данный протокол работает в сетях с коммутацией пакетов. Большинство решений в IPv4 появились из-за того, что посылаемые данные мы вынуждены дробить на пакеты.

Также этот протокол обеспечивает передачу блоков данных (дейтаграмм) от отправителя к получателю, определяемых адресом фиксированного размера. Адрес на самом деле занимает не так много места -- 32 бит, на 1981 год этого казалось много. Из-за этого возникло много проблем ⇒  разные схемы адресации, диапазоны адресов, хитрые схемы преобразования адресов и так далее.

В этом протоколе реализован механизм фрагментации данных. При помощи IP через сетевую инфраструктуру канального уровня, которая имеет ограничение на размер кадра (1500 для MTU в стандартном Ethernet) надо дробить блоки данных (в IP максимум 65К), чтобы запихнуть в канальный уровень + обратно восстанавливать раздробленные данные.


### Ограничения протокола

Что протокол не может:
- нет механизмов обеспечения надёжности доставки данных. На самом деле есть некоторые рудиментарные механизмы, которые совместно с ICMP кое-что могут дать, но это настолько рудиментарно, что как будто их и нет. Более того, эти механизмы могут быть недоступны, если кто-то заблокирует ICMP. Для решения этих задач используются протоколы транспортного уровня.
- нет механизмов управления потоком данных в базовой версии. Есть ECN (Explicit Congestion Notification) (RFC3168), но эти механизмы добавлены потом и работают не совсем самостоятельно, и полноценного механизма управления потоком всё равно не выходит. Если нам это нужно, то используются хитрые протоколы транспортного уровня
- Нет механизмов гарантии передачи дейтаграмм в определённой последовательности. Мы взаимодействуем через маршрутизирующие устройства между локальными сетями, не обязательно построенных при помощи Ethernet. В межсетевых коммуникациях могут быть различные пути доставки сообщений: данные могут теряться и задерживаться, поэтому отосланные одним хостом данные другому хосту могут пойти по разным путям, и если первый пошёл по длинному пути, а второй по короткому, то второй пакет может прийти быстрее. Но если мы разбили дейтаграмму на фрагменты, то для фрагментов мы нужный порядок обеспечиваем. Но для отдельных дейтаграмм такой порядок не гарантируется. То есть сбор дейтаграмм из фрагментов есть, но восстановление потока из множества дейтаграмм не работает.







<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExNTgwODQxODksMTgzNDEwMjQ5MSwtMj
A3NTg1NjIzNywxMDY3NzE0MzYsLTIwMjg5NzcxMjQsLTc2NTc4
MzYxMSw0NDIwMTI1MjAsLTEwMjIxMzM5OTYsMTQwODU4NTEwNi
wyMDQ0ODI5ODc4LDEyOTkwNzA0NjIsMTQ5MTc2ODM1NiwtMTU0
NDExMDMyOSw4MDE0MTk5NDZdfQ==
-->